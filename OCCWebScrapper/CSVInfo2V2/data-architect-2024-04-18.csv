Job_Title,Job_Description,Job_Url
Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18402108,"Descripción
Únete a nuestro equipo como Data Architect

Requisitos:
Lic./Ing. en Sistemas Computacionales o afín
Experiencia laboral en Banco o Fintech

Experiencia de al menos 3 años realizando las siguientes actividades:
Diseño de base de datos (creación de índices, relaciones, definición de tablas, campos,
normalización, etc.)
Mantenimiento de las bases de datos
Seguridad en la base de datos, gestión de usuarios, asignación de permiso, control de acceso a la información sensible
Copias de seguridad, respaldos, réplicas
Monitoreo y optimización
Migración de Datos
Documentación de tablas, store procedures, db, scripts, políticas de seguridad etc.

Experiencia de al menos 3 años en algunas de siguientes tecnologías:
Bases de datos relacionales (MySQL, SQLServer, PostgrSQL)
Bases de datos no relacionales (Aws Dynamo, MongoDB)
Python, SQL
Manejo de herramientas de versionado (Git)
Aws (Dynamo, Redshift, RDS)

Ofrecemos:
45,000 Netos
Prestaciones de ley
Horario Hibrido

Interesados postularse por este medio"
Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18405316,"Descripción
¡En Lumina Software tenemos una oportunidad laboral para ti!

Envíanos tu CV actualizado y te contactaremos de inmediato.

PERFIL: Data Architect

• 5+ años de experiencia en diseño e implementación de Datawarehouse
• 5+ años de experiencia el en uso de herramientas de Integración de Datos
• 5+ años de experiencia con Power BI
• Experiencia con estrategias, tecnología y herramientas de modelado de datos, perfilamiento, administración de la calidad (QA), performance y entrega.
• Experiencia colaborando con equipos de Gobierno de Datos, Arquitectura de aplicaciones y Arquitectura de Integración de Datos.
• Habilidad para conectar las necesidades del negocio con los requerimientos de información.
• Deseable conocimiento de la metodología de DAMA (DMBOK)"
DATA ARCHITECT,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=17378230,"Descripción
Desarrolla tu carrera en Zurich
 Zurich, aseguradora líder a nivel internacional te invita a ser parte de su equipo: 
  Data Architect
  Tus habilidades y experiencia:
Escolaridad: Licenciatura o ingeniería en Sistemas o afín
Experiencia mínima de 2 años en Data Analysis, Data Science y/o Data Architecture, Lenguajes de programación. Big data en Azure, 
Experiencia lidereando y gestionando soluciones de Big Data en Azure, con un enfoque específico en Delta Lake. Familiaridad con tecnologías como Hadoop Core, Hive, Spark, Kafka, Sqoop, Ambari, Zeppelin y Databricks es esencial.
Experiencia en el diseño y gestión de bases de datos, incluyendo PostgreSQL, DB2, Redis, Cassandra y Neo4j.
Familiaridad con herramientas de orquestación como Apache Airflow y plataformas de seguimiento y gestión de modelos como MLflow.
Experiencia y conocimiento del sector financiero y/o Seguros
Inglés: Intermedio
  Conocimientos técnicos:
    Más de 4 años de experiencia en roles relacionados con ingeniería de datos, big data, ciencia de datos y analítica.
1 a 2 mínimo como gerente o responsable de proyecto interdisciplinarios y multidisciplinarios para la creación de productos de datos.
Experiencia en arquitecturas distribuidas y en entornos cloud, con un enfoque particular en Azure.
Experiencia en gestión de protección y calidad de datos.
Conocimiento de la arquitectura de datos y soluciones tecnológicas.
Conocimiento de las prácticas de gobierno de datos, cuestiones comerciales y tecnológicas relacionadas con la gestión de activos de información empresarial y enfoques relacionados con la protección de datos.
Conocimiento de los requisitos regulatorios gubernamentales relacionados con los datos y las tendencias y problemas emergentes
  Objetivo de la posición:
  Experto digital enfocado en ejecutar la estrategia de datos de la empresa, basado en estándares de calidad, el tratamiento del flujo de datos y la seguridad de los mismos.
Extraer información que pueda transformar el negocio, desarrollo e implementación de estrategias de datos, diseños de modelos de datos, estándares de desarrollo de bases, así como implementación y gestión de almacenes de datos
  Responsabilidades clave
  Liderar la implementación y gestión de soluciones de Big Data en Azure, con un enfoque específico en Delta Lake. Familiaridad con tecnologías como Hadoop Core, Hive, Spark, Kafka, Sqoop, Ambari, Zeppelin y Databricks es esencial.
Supervisar el ciclo completo de desarrollo de proyectos, desde la concepción hasta la implementación, garantizando la eficiencia y calidad en todas las fases.
Desarrollar e implementar estrategias de gobernanza de datos, asegurando la calidad y seguridad de los datos en todo momento.
Establecer y gestionar una hoja de ruta para la implementación del gobierno de datos empresariales que incluya prioridades estratégicas para el desarrollo de capacidades basadas en información.
Implementar un marco de gobierno de datos en toda la empresa, con un enfoque en la mejora de la calidad de los datos y la protección de datos confidenciales mediante modificaciones a las políticas y estándares de comportamiento de la organización, principios, métricas de gobierno, procesos, herramientas relacionadas y arquitectura de datos.
Definir roles y responsabilidades relacionados con el gobierno de datos y garantizar una responsabilidad clara para la administración de los principales activos de información de la empresa.
Servir como enlace entre las áreas comerciales y funcionales y la tecnología para garantizar que los requisitos comerciales relacionados con los datos para proteger los datos confidenciales estén claramente definidos, comunicados y bien comprendidos y considerados como parte de la priorización y planificación operativa.
Liderar equipos ágiles, fomentando la colaboración y la entrega continua. Experiencia en NodeJS (Express), C# y Python (Pandas, Scikit-learn, Seaborn, Flask, Fast-API, Django) es fundamental.
Experiencia en el diseño y gestión de bases de datos, incluyendo PostgreSQL, DB2, Redis, Cassandra y Neo4j.
Familiaridad con herramientas de orquestación como Apache Airflow y plataformas de seguimiento y gestión de modelos como MLflow.
Experiencia práctica con Databricks para la implementación y optimización de flujos de trabajo de big data y análisis.
  Ofertamos:
  Para los internos CEO de tu carrera
Plataforma de beneficios flexibles, MYPDC
Esquema de ayudas
        Zurich reconoce la diversidad de nuestra fuerza laboral como una fortaleza, por lo que contamos con políticas y programas de diversidad e inclusión, donde buscamos igualdad de oportunidades sin importar la edad, etnia, sexo, orientación sexual, identidad o expresión de género, discapacidades, etc. Como empleador inclusivo, queremos asegurarnos de que todos los candidatos se sientan cómodos y puedan rendir al máximo durante la entrevista.
    Por qué elegir Zurich
  En Zurich, nos gusta pensar con originalidad y desafiar el statu quo. Adoptamos un enfoque optimista centrándonos en los aspectos positivos y preguntándonos constantemente ¿Qué puede salir bien?
Somos un empleador que ofrece igualdad de oportunidades y que sabe que cada colaborador es único ¡lo que hace que nuestro equipo sea el mejor! 
Colabora con nosotros mientras exploramos constantemente nuevas formas de proteger a nuestros clientes y al planeta.
 "
Arquitecto de Datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18396853,"Descripción
¿Has escuchado sobre Axity?

Somos una de las principales consultorías de TI especializadas en brindar soluciones en tecnologías de la información, ciberseguridad, telecomunicación y automatización. Contamos con un portafolio integral de servicios para ayudar a nuestros clientes a afrontar sus retos de Transformación Digital, también siendo Partner de Cisco, SAP Microsoft y BMC. Actualmente nos enfocamos a Transformar tecnologías de información en valor.

Intégrate a nuestro equipo como: *Arquitecto de Datos*

Perfil:
Arquitecto de datos responsable de diseñar, construir y gestionar la arquitectura de datos que soportará la transformación digital de la organización.
Liderazgo y diseño de la arquitectura de datos: Define la visión y la estrategia de la arquitectura de datos para la transformación digital.
Desarrollo de la hoja de ruta de datos: Define las etapas y los proyectos necesarios para implementar la arquitectura de datos.
Selección de tecnologías de datos: Evalúa y selecciona las tecnologías y herramientas adecuadas para la gestión de datos, análisis de datos e inteligencia de negocios.
Diseño e implementación de la arquitectura de datos: Diseña e implementa una arquitectura de datos que sea escalable, segura y flexible.
Gestión de la calidad y seguridad de los datos: Implementa procesos para asegurar la calidad, seguridad y accesibilidad de los datos.
Gobierno de datos: Define e implementa políticas y procesos para el gobierno de datos.
Experiencia en arquitectura de datos: Conocimiento de principios, patrones y mejores prácticas de arquitectura de datos.
Experiencia en tecnologías de datos: Conocimiento de tecnologías como big data, data lakes, data warehouses, data mining, machine learning, etc.
Habilidades de análisis de datos: Capacidad para analizar datos y extraer información útil.
Certificaciones: CDDA, CDAI.

¿Qué te ofrecemos en Axity?
Plan de vida-carrera
Capacitación
Certificaciones
Sueldo acorde a experiencia y conocimientos
Contratación 100% nómina
Prestaciones de ley
Vales de despensa

¡TE ESPERAMOS, VEN A SER PARTE DEL HOGAR DEL MEJOR TALENTO!"
Data Engineer JR,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18405405,"Descripción
Contribute to the continued development of Data Engineering as a capability - training, tooling, ways of working, and operating model to optimise output and value.
Client Details
A global, science-led, patient-focused pharmaceutical company.
Description
2 - 3 years of work experience as a Data Engineer
Python language knowledge.
Exposure to Data Pipelines.
AWS, SQL and PySpark experience.
Advanced English
Profile
Working with peers, data architects, and, data analysts in the delivery of data capabilities.
Working with Scrum leaders in daily updates on delivery estimations and issues management.
Job Offer
$35,000 - $40,000 gross salary + benefits above the law
Full Home Office."
Snowflake Technical Lead,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18396412,"Descripción
We're hiring!  
 At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place to Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! 
We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Snowflake Technical Lead

What you'll do: 
·       Take the responsibility of the Snowflake delivery from Mexico in all aspects. Collaborate with U.S and offshore teams to deliver high quality output.
·       Developing data management solutions using Snowflake.
·       Snowflake concepts like setting up Resource monitors, RBAC controls, scalable virtual warehouse, SQL performance tuning, zero copy clone, time travel and automating them.
·       Migration processes to Snowflake from on-premises database environment.
·       Handling semi-structured data (JSON, XML), columnar PARQUET using the VARIANT attribute in Snowflake.
·       DesSnowflake using combination of Python, PySpark, Bash with SnowSQL.
Minimum Qualifications:
·       Experience in Cloud technologies such as AWS – S3, SQS, EC2, Lambda, Redshift, RDS
·       SnowSQL Experience in developing stored Procedures writing Queries to analyze and transform data.
·       Certified Snowflake cloud data warehouse Architect (Desirable).
·       Top Skills: Snowflake (Mandatory), Cloud Data Quality/Informatica Data Quality (Desirable)
·       8+ years of experience implementing data management solutions 
·       6+ years of experience in Snowflake
·       Experience in designing and building manual or auto ingestion data pipeline using Snowpipe.
·       Experience in in re-clustering of the data in Snowflake with good understanding on Micro Partitions.

Why Cognizant? 
 Improve your career in one of the largest and fastest growing IT services providers worldwide 
Receive ongoing support and funding with training and development plans 
Have a highly competitive benefits and salary package 
Get the opportunity to work for leading global companies 
We are committed to respecting human rights and build a better future by helping your minds and the environment  
We invest in people and their wellbeing.   We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered.  
 At Cognizant we believe than our culture makes us stronger!  
Join us now! 
#BeCognizant #IntuitionEngineered  "
Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18348333,"Descripción
Data Architect

Acerca de la Empresa 

Somos la primera plataforma digital en México que se especializa en diseñar productos y soluciones financieras a la medida de las necesidades de cada uno de nuestros clientes.

Requisitos para el puesto:

Escolaridad: Licenciatura concluida en: Ingeniería en computación, Sistemas, Ciencia de datos, Matemáticas o afín.

Experiencia:
Base de datos (SQL y NoSQL)
Arquitectura en la nube (AWS)
Ecosistemas de Big Data
Hadoop {HIVE, Sqoop, Kafka}
SPARK (Scala, Java, Python)
Python / R / JSON / Git


Años de experiencia: 3 años
Idioma: Inglés intermedio
Otros cursos de formación: AWS Cloud Practitioner / Developing on AWS / Architecting on AWS


Principales funciones: 

Desarrollar la infraestructura de datos para respaldar los objetivos estratégicos y operativos del negocio.
Gestionar soluciones de datos que mejoren la toma de decisiones, impulsen la eficiencia operativa y garanticen la integridad y seguridad de los datos. 
Desarrollar soluciones de bases de datos para almacenar y recuperar información de la empresa.
Evaluar, recomendar herramientas y plataformas relacionadas con datos.
Planificar y gestionar proyectos de datos en colaboración con otros equipos de la empresa.
Documentar los diseños de arquitectura de datos.
Evaluar tecnologías y arquitecturas de datos emergentes.


Prestaciones y beneficios adicionales: 
100% Nomina 
Sueldo competitivo 
Paquete de incentivos variable"
Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18265428,"Descripción
Posición: Data Architect
Ubicación: CDMX (híbrido)
Industria: Banking

Conocimientos y experiencia necesaria:
Conocimientos en tecnología cloud: DataFlow, Cloud Composer, Python(manejo de archivos y APIs), SQL ANSI, BigQuery
Conocimientos las siguientes herramientas y/o prácticas: DevSecOps, Git, Modelado de datos, Data Warehouse, Herramientas y técnicas de ETL, Stored procedures y funciones, Conocimientos de industria bancaria
Conocimiento de procesos bancarios, Normas ISO, Análisis riesgo control (deseable): Conocimientos en SAP Hana, Conocimientos en IPC, Experiencia en metodologías Agiles

Habilidades:
Trabajo bajo presión, calidad en el trabajo y orientado a resultados

Tu carrera en Capgemini
Al trabajar en un ambiente de equipo, nuestros consultores se enfocan en el análisis, diseño y desarrollo de soluciones basadas en tecnología para los clientes de Capgemini.
Trabajarás en conjunto con especialistas funcionales, técnicos y del negocio para ayudar a desarrollar la implementación e integración de soluciones y sistemas innovadores incluyendo metodologías, técnicas y herramientas.
Contribuirás de una manera responsable y oportuna con la satisfacción del cliente proporcionando servicios y productos que generan valor agregado.
Capgemini ofrece una compensación competitiva y beneficios superiores a los de Ley.
Nuestras oficinas centrales están en París, Francia y tenemos presencia en más de 50 países. Somos más de 340 mil profesionales en México, ubicados en Ciudad de México, Aguascalientes y Monterrey.
Capgemini ha desarrollado metodologías propias a nivel global: Collaborative Business Experience y Rightshore.

Te encantará trabajar en Capgemini porque:
Ofrecemos una experiencia única de reclutamiento y onboarding, y te ayudamos a construir las bases de tu carrera y habilidades profesionales.
Proveemos un ambiente de trabajo colaborativo basado en nuestros 7 valores: Honestidad, Audacia, Confianza, Libertad, Espíritu de Equipo, Modestia y Diversión.
Promovemos un ambiente que te permite planear y desarrollar tu carrera.

“En Capgemini México, el objetivo es atraer al mejor talento y lograr un ambiente laboral diverso e inclusivo por lo que no se discrimina por motivo de raza, sexo, orientación sexual, identidad o expresión de género o cualquier otra característica propia de la persona. Todas las solicitudes son bienvenidas y serán consideradas para concurso con base en el mérito del candidato contra el trabajo y/o la experiencia para el puesto”"
Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18201224,"Descripción
Únete a nuestro equipo como Data Architect

Requisitos:
Lic./Ing. en Sistemas Computacionales o afín
Experiencia laboral en Banco o Fintech

Experiencia de al menos 3 años realizando las siguientes actividades:
Diseño de base de datos (creación de índices, relaciones, definición de tablas, campos,
normalización, etc.)
Mantenimiento de las bases de datos
Seguridad en la base de datos, gestión de usuarios, asignación de permiso, control de acceso a la información sensible
Copias de seguridad, respaldos, réplicas
Monitoreo y optimización
Migración de Datos
Documentación de tablas, store procedures, db, scripts, políticas de seguridad etc.

Experiencia de al menos 3 años en algunas de siguientes tecnologías:
Bases de datos relacionales (MySQL, SQLServer, PostgrSQL)
Bases de datos no relacionales (Aws Dynamo, MongoDB)
Python, SQL
Manejo de herramientas de versionado (Git)
Aws (Dynamo, Redshift, RDS)

Ofrecemos:
35,000 Netos
Prestaciones de ley
Horario Hibrido

Interesados postularse por este medio"
Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18264847,"Descripción
Capgemini es líder mundial en servicios de consultoría, transformación digital, tecnología e ingeniería. El Grupo está a la vanguardia de la innovación para abordar todas las oportunidades de los clientes en el cambiante mundo de la nube, lo digital y las plataformas. Basándose en su sólida herencia de más de 50 años y su profunda experiencia específica en la industria, Capgemini permite a las organizaciones hacer realidad sus ambiciones empresariales a través de una gama de servicios que van desde la estrategia hasta las operaciones. Capgemini está impulsada por la convicción de que el valor empresarial de la tecnología proviene de y a través de las personas. En la actualidad, es una empresa multicultural con 350.000 miembros en 50 países. En 2021, los ingresos combinados del Grupo ascendieron a 18.000 millones de euros.
 Contamos con 10 posiciones:
4 Jr con 2 años de experiencia
2 Mid con 3.5 años de experiencia
4 Sr con 5 años de experiencia
(El rango salarial depende de los años de experiencia)

Responsabilidades, aptitudes y experiencia:
 Análisis, diseño e implementación de soluciones de ingeniería de datos sobre la platagorma GCP
Arquitectura de datos sobre plataforma GCP

Conocimientos (ideales) en tecnología cloud: 
DataFlow
Cloud Composer
Python(manejo de archivos y APIs)
SQL ANSI
BigQuery

Conocimientos (idales) las siguientes herramientas y/o prácticas: 
DevSecOps
Git
Modelado de datos
Data Warehouse
Herramientas y técnicas de ETL
Stored procedures y funciones
Conocimientos de industria bancaria

Conocimiento de procesos bancarios, Normas ISO, Análisis riesgo control:
Deseable conocimientos en SAP Hana
Deseable conocimientos en IPC
Deseable experiencia en metodologías Agiles

 Tecnologías:
 GCP
Python
SQL
BigQuery

 Contamos con esquema 100% nómina, prestaciones de ley, prestaciones superiores a las de la ley, etc. Además tenemos un plan de carrera profesional diseñado en base a tus expectativas y un programa de medición y mejora continuo, beneficios adicionales y convenios.
 Si te interesa unirte a Capgemini y trabajar con nosotros, te estamos esperando.
 “En Capgemini México, el objetivo es atraer al mejor talento y lograr un ambiente laboral diverso e inclusivo por lo que no se discrimina por motivo de raza, sexo, orientación sexual, identidad o expresión de género o cualquier otra característica propia de la persona. Todas las solicitudes son bienvenidas y serán consideradas para concurso con base en el mérito del candidato contra el trabajo y/o la experiencia para el puesto”"
Data Architect/ Data Engineer,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18119383,"Descripción
Data Architect/Data Engineer
Modalidad: Hibrido con ubicación en Monterrey
Inglés conversacional avanzado
Contrato tiempo indefinido
 Co-diseñar, preparar y entregar KPIs, ayudando a las áreas a medir su desempeño e implementar la solución. Informes de datos de premezclado a nivel mundial: inglés fluido
 Requisitos
Ingles fluido
Formación Académica: Licenciatura en Informática, o Analítica o similar
Áreas de especialización: Cadena de Suministro, Comercial, Producción, Procesos y TI, Análisis, Herramientas digitales
Habilidades técnicas requeridas por rol: SQL, Power BI, Snowflake, Habilidades de software para recopilación y presentación de datos, Conocimiento de programación estadística, Capacidad para articular decisiones basadas en datos, capacidad para resumir y presentar datos, bien versado en las últimas innovaciones y tendencias en el sector. mercado relacionado con productos y servicios de manipulación de datos. SQL/Snowflake es imprescindible
Soft Skills: Automotivado, altamente comprometido, resolución de problemas, motivado por la tecnología digital, gestión de la incertidumbre, pensamiento crítico, gestión del tiempo de proyectos y relaciones.
 Responsabilidades
Gestionar y coordinar varios equipos de diferentes países, culturas, orígenes y expectativas.
Mantener un modelo en constante evolución con toda la información del proyecto.
Diseñar y desarrollar KPI solicitados de diferentes áreas/países.
Definir e implementar iniciativas para mejorar la homologación y estandarización de la información.
Proponer e implementar nuevas oportunidades para obtener información valiosa que pueda mejorar la experiencia del cliente."
Mid Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18263810,"Descripción
Description:

In our continued expansion, we are seeking a Mid Data Architect with strategic vision and proven experience. This position is key to leading the management, design, and implementation of data solutions. If you have a passion for technology and an innovative approach to data architecture, we are waiting for you!

Responsibilities:

Design and implement efficient and scalable data models.
Collaborate with development teams to ensure the integration and alignment of data solutions.
Manage the data lifecycle, including storage, migration, and security.
Develop standards and protocols for data management and quality.
Perform analysis of large volumes of data to identify trends and opportunities.
Experience working in the integration of data and building a data lake for the company.

Requirements:

Minimum experience of 3 years in Data Architecture.
Knowledge of database management systems (SQL, NoSQL).
Strong skills in programming with Python for data modeling, and also with other languages such as R, SQL.
Knowledge of any cloud technology, preferable AWS (AWS, Azure, Google Cloud).
Conversational English is essential for this project, which is USA-based.
Experience working with Data Bricks
Knowledge about Apache Spark
Desirable experience working with Jupiter for Data Projects

Benefits:

Learning bonus for you to continue growing professionally.
Home Office support (only for cases that apply).
Professional and personal development with our life coaching.
Access to software engineering talks.
Opportunity to become certified as an Engineering Warrior Towa.
Towa Flex Paid Time Off
Certifications with our partners"
Data Architect -Hibrido,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18256516,"Descripción
Matersys Group empresa mexicana con 20 años en el mercado. Líder en ofrecer servicios, soluciones, capacitaciones y desarrollo de software a la medida.

SOLICITA

DATA ARCHITECT

SQL
Análisis y Modelado de datos (Relacional y dimensional)
Manejo de SAP Hana versión 2.x
Creación / Modificación de Stored Procedures, Calculation Views, Table Functions
Conocimiento de DWH y Datamarts
Desarrollo en IPC (Ver. 10.x.x) Nivel Medio Avanzado
Experiencia en UNIX y creación de SHELL (Nivel medio)
Módulo SDI
Trabajar bajo Metodologías: Agile (SCRUM) y WATERFALL
SAP HANA

Trabajo Híbrido en CDMX (Insurgentes y Churubusco)

Ofrecemos sueldo 100% nomina, prestaciones de ley y vales de despensa

Interesados postularse por este medio"
Sr Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18200581,"Descripción
Empresa internacional, líder en servicios financieros, de apoyo a empleados y servicios de movilidad está en búsqueda de Arquitectos de Datos para elaborar y mantener las definiciones y estándares de uso de datos interno en la región de México.

REQUISITOS

Carrera afín a TI completa (Ciencias de la computación, Sistemas, Desarrollo de Software, etc.)
5 o más años de experiencia en arquitectura de datos o análisis de datos en diversas plataformas de almacenamiento esparcido en un ecosistema de datos complejo, establecido de forma internacional y en varias regiones geográficas.
Experiencia en optimización de infraestructura (on-prem vs nube).
Experiencia de almacenamiento e infraestructura de Azure.y la suite de Microsoft
Conocimiento de migración y proyectos de renovación tecnológica
Conocimiento de legislaciones que afecten la transferencia, recepción, tratamiento y/o almacenamiento de datos en ciertas regiones geográficas (GDPR, por ejemplo).
Familiaridad y conocimiento del ciclo de desarrollo.
Conocimiento con Python, C# para resolver problemas en arquitectura de aplicaciones.
Inglés B2 (Avanzado) -  experiencia con equipos internacionales

BENEFICIOS
Contrato tiempo indeterminado 100% bajo nómina
Vales de despensa y restaurante
Seguro de Gastos Médicos Mayores (Familar)
Apoyo Desarrollo Profesional"
Data Architect Jr.,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18154892,"Descripción
Importante consultaría líder dentro del mercado retail, con 27 años de experiencia dentro de México y una empresa 100% Mexicana solicita profesionales que cubran con el siguiente perfil:


DATA ARCHIITECT JR.


REQUISITOS:

Ing. Computación. Ciencias de la computación. Matemáticas o Estadística.
Experiencia mínima de 1 a 2 años en puesto o funciones similares.
Inglés (Intermedio – Avanzado)


CONOCIMIENTOS:
?
Excel (Macros, VBA, Tablas dinámicas)
POWER BI
Diseño, despliegue y gestión de plataformas Cloud. (Azure SQL Server, Databricks, Data Lake, Synapse, Power BI)
Lenguajes de programación: SQL y Python
Conocimiento en ETL. Integración y transformación de datos
Desarrollo de integraciones entre sistemas con estructuras de almacenamiento
Conocimientos de procesamiento de datos, matemáticas y estadística


ACTIVIDADES:

Gestión de las estructuras de datos (Diseño, creación, supervisión administración e implementación).
Diseño y desarrollo de estrategias de arquitectura de base de datos.
Mapeo de Procesos (Organización de información y datos a nivel Micro y Macro)
Definición de modelos de lógica de datos y estándares como fuente de información única.
Gobernanza de datos


HABILIDADES:

Pensamiento Lógico
Autodidacta
Resolución de problemas
Trabajo Individual y en equipo
Creatividad e Innovación


OFRECEMOS:
?
Sueldo Competitivo. ($20,000 - $25,000 brutos mensuales de acuerdo a experiencia)
Prestaciones de Ley desde el primer día. (Aguinaldo, Prima Vacacional, IMSS)
Excelente ambiente laboral
Horario: Lunes a Viernes de 9:00 a 18:00
Estabilidad Laboral
Oportunidad de Crecimiento
Modalidad Hibrida (80% Home Office, 20% Oficina)

Si cumples 100% con el perfil y nuestra vacante es de tu interés, postúlate por este medio o envíanos tu CV al correo de contacto"
Data Architect SR - Hibrido,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18256195,"Descripción
Matersys Group empresa mexicana con 20 años en el mercado. Líder en ofrecer servicios, soluciones, capacitaciones y desarrollo de software a la medida.

SOLICITA

DATA ARCHITECT SR

Conocimientos en tecnología cloud:
DataFlow
Cloud Composer
Python(manejo de archivos y APIs)
SQL ANSI
BigQuery

Conocimientos las siguientes herramientas y/o prácticas:
DevSecOps
Git
Modelado de datos
Data Warehouse
Herramientas y técnicas de ETL
Stored procedures y funciones
Conocimientos de industria bancaria

Deseable:
Conocimiento de procesos bancarios, Normas ISO, Análisis riesgo control ,
Deseable conocimientos en SAP Hana
Deseable conocimientos en IPC
Deseable experiencia en metodologías Agiles

Vacante Híbrida en CDMX (Insurgentes y Churubusco)

Ofrecemos sueldo 100% nomina, prestaciones de ley y vales de despensa

Interesados postularse por este medio"
Data Architect (PowerBi / SnowFlake),https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18225685,"Descripción
¡Oportunidad Imperdible! ¡Únete a nuestro Equipo como Ingeniero de Datos!

¿Buscas un nuevo desafío que te permita desplegar todo tu potencial? ¿Te apasiona el mundo de la tecnología y la gestión de datos? ¡Esta es tu oportunidad!

Descripción del Recurso
Ingeniero de Datos
¿Te emociona la idea de colaborar en la creación y entrega de KPIs que transformarán las operaciones de Supply Chain y Ready Mix a nivel global? ¿Tienes un dominio fluido del inglés y estás preparado para trabajar en un entorno híbrido o en sitio?

Requisitos
Habilidades Técnicas:
Experiencia sólida en SQL y Snowflake.
Competencia en Power BI y otras herramientas de análisis de datos.
SQL / Snowflake is a must
Conocimientos en programación estadística.
Capacidad para articular decisiones basadas en datos y presentar información de manera efectiva.
Familiarizado con las últimas innovaciones y tendencias en el mercado relacionadas con la manipulación de datos.
Formación Académica y Experiencia:
Título universitario en Informática, Ciencias de la Computación, Análisis de Datos o áreas afines.
Al menos 2 años de experiencia en áreas de adopción digital o similares.
Experiencia previa en entornos de Supply Chain, Comercialización, Producción, Procesos y Tecnología de la Información.
Habilidades Personales:
Inglés Avanzado
Autonomía y motivación intrínseca.
Capacidad para resolver problemas de manera proactiva.
Orientado a la tecnología digital y al aprendizaje continuo.
Excelentes habilidades de gestión del tiempo y proyectos.
Pensamiento crítico y habilidades para gestionar la incertidumbre.
Responsabilidades
Coordinar equipos multidisciplinarios en entornos internacionales.
Mantener un modelo de trabajo flexible y adaptable a las necesidades del proyecto.
Diseñar y desarrollar KPIs adaptados a las distintas áreas y países.
Implementar iniciativas para mejorar la homologación y estandarización de la información.
Proponer e implementar nuevas estrategias para obtener datos valiosos que mejoren la experiencia del cliente.

¿Por qué unirte a nosotros?
Ofrecemos un entorno dinámico y desafiante donde podrás desarrollarte profesionalmente y contribuir al éxito de proyectos globales de alto impacto. Te brindamos la oportunidad de trabajar con tecnologías de vanguardia y un equipo apasionado por la innovación.

Si estás listo para asumir este emocionante desafío y ser parte de nuestro equipo, ¡esperamos tu postulación! ¡No pierdas la oportunidad de impulsar tu carrera y marcar la diferencia en el mundo de los datos!"
Data Engineer / Architect (Remoto),https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18206760,"Descripción
A Staff Data Engineer/Architect is responsible for designing, implementing, and maintaining an organization's databases, data warehousing systems, and data processing architectures. They play a crucial role in managing and safeguarding the company's data, developing strategies for data acquisitions, and optimizing data retrieval, ensuring all data systems meet company and client needs.


Responsibilities:
A Staff Data Engineer/Architect meticulously designs, constructs, and manages large-scale, robust data architectures. They are responsible for overseeing the development of comprehensive databases, data lakes, and data warehouses.
They frequently evaluate and enhance the performance of data management systems, ensuring they meet both technical and business requirements.
With a strategic approach, they consistently develop and implement data governance policies and procedures to ensure the integrity, confidentiality, and availability of enterprise data.
They are regularly in coordination with cross-functional teams, such as software developers, data scientists, and IT staff, to ensure data solutions are optimized and aligned with company goals.
They efficiently liaise with globally based business teams and local project management teams to understand their data needs and provide suitable solutions.
A Staff Data Engineer/Architect is accountable for leading the data architecture vision and strategy for the organization, often presenting to stakeholders and executive teams.
They frequently review existing systems and processes, identifying areas for improvement and implementing changes in a timely and effective manner.
They actively stay abreast of the latest industry developments, technologies, and best practices in data management, participating in professional development opportunities as needed.
A Staff Data Engineer/Architect operates with a high degree of independence but also collaborates extensively with various teams and stakeholders within the organization to ensure the effectiveness of data systems and strategies.
They are responsible for mentoring and guiding junior data engineers and other technical staff, promoting a culture of continuous learning and improvement within the team.

Requirements:
Proficiency in designing, implementing, and maintaining scalable and robust data architectures. This includes understanding of data warehousing, data lakes, and databases.
Understanding Architecture Tradeoffs: Ability to evaluate and articulate the tradeoffs of different architectural solutions. This includes considerations of cost, performance, scalability, reliability, and security.
Machine Learning Pipelining: Expertise in designing and implementing data pipelines for Machine Learning. This involves understanding of data extraction, transformation, and loading (ETL) processes, as well as feature engineering and model deployment. Understanding of how data quality impacts the performance of these algorithms.
Data Modeling and Design: Expertise in logical and physical data modeling, with the ability to design optimized data structures for Machine Learning applications.
Technical Skills: Proficiency in tools and technologies used for managing big data (like Hadoop, Spark) and developing Machine Learning models (like Python, R, TensorFlow).
Analytical and Problem-Solving Skills: Ability to analyze complex data, identify patterns, and solve problems. This includes troubleshooting issues in data pipelines and optimizing them for better performance.
Communication Skills: Ability to clearly articulate complex data architecture concepts and tradeoffs to both technical and non-technical stakeholders.
Project Management Skills: Ability to manage and prioritize multiple projects, often with tight deadlines.
Continuous Learning: Keeping up-to-date with the latest trends and advancements in data architecture and Machine Learning, and applying this knowledge to improve existing systems and processes.
Minimum 8 years as a Senior data engineer or higher in a professional environment."
Arquitecto de Datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18317676,"Descripción
¡En Lumina Software tenemos una oportunidad laboral para ti!

Envíanos tu CV actualizado y te contactaremos de inmediato.

Perfil: Arquitecto de Datos

Requerido:
• 3+ años de experiencia como arquitecto/integrador de datos, diseñando e implementando arquitecturas de datos escalables y de alto rendimiento.
• 7+ años de experiencia en el uso de herramientas de Integración de Datos.
• Amplia experiencia orquestando y gestionando flujos de datos en entornos de nube y on-premise.
• Amplia experiencia en la creación de pipelines, su configuración y optimización, integrando APIs, WebServices y Bases de datos.
• 3+ años de experiencia con Azure Data Factory, Azure Synapse, Azure Data Lake, SQL Server.
• Habilidad para conectar las necesidades del negocio con los requerimientos de información.

Deseable:
• Experiencia con Azure Analysis Services."
ARQUITECTO DE DATOS,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=1&jobid=18303259,"Descripción
Neta Systems es una importante empresa en el sector de Tecnologías de la Información, es la fusión de los sueños, la tecnología y la pasión de nuestro equipo de trabajo y hoy estamos buscando tu talento para que nos ayudes a cumplirlo en el puesto:

Arquitecto de Datos :

Con experiencia de 4 años en:

-Arquitectura de Datos
-Manejo de AWS, GCP,Terraform
-Modelado de Datos


Lugar de trabajo: Venustiano Carranza, modalidad : híbrida

Interesados postularse por este medio, o enviar CV actualizado al correo mencionado"
ARQUITECTO DE DATOS,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18277089,"Descripción
Importante empresa financiera, busca sumar a su equipo de Sistemas, un Arquitecto de Datos.

Para
trabajar en Corporativo en CDMX o bien en Monterrey
Modalidad: Presencial
Contrato directo por la financiera
Contrato Indefinido
Prestaciones Superiores


Requisitos:

Indispensable estar titulado de Licenciatura en Sistemas, Informática, Computación o afín
Experiencia en diseño y creación de arquitectura tecnológica del marco de gestión de datos de una organización.
Indispensable conocimientos en: modelado de datos, análisis predictivo, visualización de datos.
Manejo de DWH, ETL, OLAP,SQL, Hadoop, Spark, Python, Oracle, Anaconda"
Arquitecto de Datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18303354,"Descripción
AZKAIT es una empresa Mexicana que busca y conecta el mejor talento IT con empresas Latinoamericanas y de Estados Unidos.

Estamos en la búsqueda de tu talento como Arquitecto de Datos.

Objetivo principal: Buscamos un Arquitecto de Datos altamente calificado para unirse a nuestro equipo de consultori´a. El candidato ideal sera´ responsable de disen~ar, implementar y mantener arquitecturas de datos robustas y escalables para nuestros clientes. Este rol tiene un enfoque fuerte en la entrega de resultados y en la mejora continua.

Responsabilidades:

Diseñar y construir arquitecturas de datos escalables y sostenibles.
Consultar con los clientes para entender sus necesidades y traducirlas en requisitos técnicos.
Implementar y optimizar pipelines de datos.
Colaborar con analistas de datos y científicos de datos para optimizar las soluciones para el análisis de datos.
Mantener la documentación técnica actualizada y accesible.
Trabajar en estrecha colaboración con otros consultores y equipos de proyecto.
Requerimientos
Mi´nimo de 5 an~os de experiencia en arquitectura de datos.
Experiencia comprobada en consultoría es una ventaja.

Habilidades Técnicas:

Conocimiento profundo de bases de datos SQL y NoSQL.
Experiencia en data lake, lakehouse y/o data warehouse modernos.
Experiencia en lenguajes de programación como Python, Java o Scala.
Experiencia en algunas de estas nubes: AWS, Azure, GCP.
Familiaridad con metodologías ágiles y frameworks de desarrollo.
Conocimiento en DataOps es una ventaja."
Arquitecto de Datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18331866,"Descripción
AIT, empresa mexicana con 10 años de experiencia en reclutamiento y administración de profesionales de tecnologías de la información, busca el mejor talento con el siguiente perfil:

Arquitecto de Datos

Experiencia solicitada:
Contar con alrededor de 5 años de experiencia profesional en el diseño e implementación de arquitectura de datos.

Conocimientos técnicos:
Fundamentos en Gobierno de Datos, Big Data, Data Lake
Metodologías de Desarrollo para DWH y Data Lake
Manejo de modelado de datos
Procesamiento y almacenamiento de datos (Hadoop, Cloudera, Spark, Hive, Impala)
Manejo de tecnologías de datos Cloud (Azure preferentemente)
Desarrollo de procesos ETL con ODI, SSIS e IBM
Uso de Base de Datos SQL (Oracle) y NoSQL (MongoDB)

Condiciones laborales:
Modalidad de trabajo híbrida de 3 a 4 días de forma presencial, el resto home office
Zona de trabajo Reforma, Montes Urales
Horario de lunes a viernes de 9:00 am a 6:00 pm
Esquema de pago mixto con PL y PSL
Proyecto por 6 meses con altas posibilidades de que se extienda a contrato indeterminado

Dentro de los procesos de Reclutamiento y Selección de personal en AIT , se respeta plenamente la dignidad humana del trabajador; no existe discriminación por origen étnico o nacional, género, edad, discapacidad, condición social, condiciones de salud, religión, condición migratoria, opiniones, preferencias sexuales o estado civil; se tiene acceso a la seguridad social y se percibe un salario remunerador; se recibe capacitación continua para el incremento de la productividad con beneficios."
Arquitecto de Datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18362969,"Descripción
Experiencia con Azure Data Factory, Azure Synapse, Azure Data Lake, SQL Server.
3+ años de experiencia como arquitecto/integrador de datos, diseñando e implementando arquitecturas de datos escalables y de alto rendimiento.
Comprensión de patrones de diseño de almacenamiento y procesamiento de datos.
Conocimientos de Base de datos en general y especialmente con SQL Server, Sql Pools, Azure Synapse, deseable Azure Analysis Services.
Sólidos conocimientos en Data Factory, orquestando y gestionando flujos de datos en entornos de nube y on-premise.
Sólidos conocimientos en la creación de pipelines, su configuración y optimización, integrando APIs, WebServices y Bases de datos. 
Habilidades de resolución de problemas, de comunicación y orientado en los resultados."
Arquitecto de Datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18336269,"Descripción
Si tienes experiencia en Arquitectura de Datos ¡Te estamos buscando! Únete al equipo de una de las empresas más importantes en la creación de materiales y adhesivos para proyectos de construcción a nivel nacional e Internacional.
Funciones a Desempeñar:
Planificar, diseñar y definir los lineamientos para implementar arquitecturas modernas que logren cumplir de forma eficiente los proyectos de datos solicitados por Grupo Lamosa; logrando maximizarel aprovechamiento de las plataformas establecidas a través de su correcta administración, gestión y gobernanza.
Entender problemas y procesos de negocio para definir la solución de arquitectura tecnológica y de datos que mejor responda al requerimiento planteado.
Diseñar flujos de información y mapas conceptuales de los datos de la organización. Documentar diseños de solución y arquitectura; así como procedimientos de gobierno de las plataformas.
Analizar, comprender y evaluar arquitecturas tecnológicas. Administración y gestión de las plataformas.
 Diseñar y desarrollar modelos de datos, tanto físicos como lógicos. Definir lineamientos para
Participar en la definición de lineamientos para gobierno, calidad, seguridad, gestión, trazabilidad e integridad de datos. Definir estrategias de implementación para Data Lake y diseñar arquitecturas Cloud.
Establecer estándares sobre los procesos de recopilación de datos y metadata para repositorios; definición y administración de catálogos de datos
. Elaboración documentación técnica

Requisitos
 Herramientas de integración y flujos de datos (Alteryx)
• Conocimientos en arquitecturas cloud y nubes públicas (AWS)
• Conocimientos en ERP (SAP ECC, S4HANA)
• Conocimientos en Bases Datos y Datawarehouse (Snowflake, BW, BW4HANA) • Cursos y entrenamiento de:
• Arquitectura de datos
• Gobierno de datos
• Calidad de datos.
• Deseable Certified Data Management Professional (DAMA)
Años de experiencia: 8-10 años
• Industria: Indistinta
• Experiencia diseñando proyectos de solución de arquitecturas de datos.
• Experiencia en proyectos de gobierno de datos.
Prestaciones
Prestaciones de ley, prestaciones superiores incluyendo Seguro de Gastos Médicos Mayores después del sexto mes."
Arquitecto de datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18277831,"Descripción
Tú próximo paso en Crediclub!
Creemos que toda persona tiene el potencial y el derecho a vivir una vida digna y construir algo mejor para sus familias. La inclusión financiera es fundamental para mejorar la movilidad ascendente y hemos hecho nuestro el propósito de empoderar a las personas y las empresas para que cultiven mejores oportunidades económicas.

Postúlate a la vacante si cumples con:
Licenciatura en informática, ingeniería informática o campo relacionado; certificaciones relacionadas a las áreas de bases de datos
Conocimientos: Fuerte conocimiento de los sistemas de estructura de bases de datos y minería de datos. Bases de datos con SQL; Posgress.
Habilidades: Excelentes habilidades organizativas y analíticas.; Excelente capacidad para solucionar de problemas, sentido de lógica y razonamiento crítico. Buenas habilidades en comunicación oral y escrita.

Principales actividades:
Diseñar e implementar soluciones y modelos de bases de datos efectivos para almacenar y recuperar datos de la empresa.
Evaluar los procedimientos de implementación de la base de datos para garantizar que cumplan con las normas internas y externas.
Instalar y organizar sistemas de información para garantizar la funcionalidad de la empresa.
Supervisar la migración de información de sistemas actuales a nuevas tecnología.
Entre otras

Actitudinal:
Pensamiento innovador: que se atreva a pensar fuera de la caja y a proponer soluciones.
Alinear siempre lo mejor para el cliente y para el equipo.
Mentalidad de crecimiento.
Hambre de aprender y hacer cosas nuevas. Autodidacta.
Pasión por impactar positivamente en la vida de las personas.

Beneficios de trabajar en Crediclub:
Unirse a un equipo apasionado y decidido
Formar parte de una empresa reconocida, en crecimiento y con el respaldo de inversionistas internacionales
Ser parte de una empresa innovadora enfocada en la transformación financiera tecnológica
Prestaciones de Ley desde tu primer día de ingreso
Seguro de Gastos Médicos Mayores
Seguro de Vida
Tasa preferencial para colaboradores en Supertasas
Crecimiento en la empresa en una ruta de vida y carrera
Beneficio de salud en aplicación Betterfly
Programa de asistencia de 24 horas con PAE
Trabajo de manera Híbrido

Postúlate por este medio y forma parte de nuestro equipo."
Ingeniero de datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18271699,"Descripción
IMPORTANTE EMPRESA EN SU GIRO REQUIERE:
Arquitecto de datos/Ingeniero de Datos

Arquitecto de datos (requiere de 8 a 10 años en puesto similar)
Ingeniero de datos 4 a 5 años

Modalidad: Hibrido - San Pedro Garza García, N.L.
Contrato : Posición temporal de 4 meses
Horario: Lunes a Viernes de 8am a 6:30pm
Inglés : Intermedio

Habilidades:
                                                                      Planeación de proyectos
Administracion de proyectos
Análisis
Diseño
Desarrollo
Implementación
Admon. B.D.
Testing
Prestaciones:
20 días de aguinaldo
SGMM
Seguro de Vida
Vales de despensa
12 días de vacaciones por ley + 2 adicionales
IMSS
Infonavit"
Data Scientist Sr. Bilingüe,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18148726,"Descripción
Somos una gran empresa mexicana que brinda soluciones TI ,2 veces ganadores como mejores partners de google a nivel internacional. Nos interesa tu desarrollo y crecimiento dentro de la empresa. Te estamos buscando:

?Data Scientist Sr. Bilingüe

Perfil: 
A partir de 7 años de experiencia en puesto similar 
Licenciatura concluida 
3 proyectos de gobierno de datos implementados exitosamente
Inglés conversacional

Funciones:
Implementar Estrategia de gobierno de datos en empresas de distintos giros
Ayudar a definir algoritmos matemáticos para solución de problemas específicos
Revisar, validar, corregir, código implementado por un ingeniero de datos
Proporcionar información al arquitecto de datos, sobre los modelos a implementar
Apoyar a las áreas de venta y preventa a identificar oportunidades y soluciones con clientes

Conocimientos:
Estrategia de gobierno de datos
Herramientas de Machine learning 
Herramientas de análisis de datos
Extractores de datos (ETL al menos una herramienta)
Lenguajes de programación tradicional Python, R, SQL 
Conocimientos profundos sobre base de datos
Gestión de datos, incluyendo calidad de datos, integración, privacidad y seguridad.
Suite GCP
Suite Azure (Microsoft)

Ofrecemos
- Sueldo negociable de acuerdo a conocimientos y experiencia
- Esquema 100% nominal
- Prestaciones de Ley y superiores
- Vales de despensa
- Clases de inglés
- Fondo de Ahorro
- SGMM
- Bono mensual
- Plataformas de aprendizaje y plan de desarrollo
- Esquema de trabajo híbrido "
Ingeniero de datos / Científico de datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18353349,"Descripción

INGENIERO DE DATOS / CIENTIFICO DE DATOS
   Educación: licenciatura o mayor -Carreras a fines (Científico de Datos / Big Data / Actuaria / Ciencia de Datos / Arquitecto de Datos / Ingeniero de Datos / Analista de Datos).

Experiencia: de 3 a 5 años, reciente y continua.
 Conocimientos indispensables:

Analizando datos

Definiendo estrategia de Modelado de información, uso de herramientas.
Definición de criterios clave de evaluación y calidad de la información.
 -Gestión de información, análisis e interpretación con aplicabilidad al negocio

-Uso y aplicación de los modelos matemáticos principalmente para Predictiva

-En proyectos de inicio a fin, en el uso de herramientas y determinación de eventos / actividades predictivas

-Inteligencia Artificial

-Programación y Algoritmos de Bases de Datos y estadística (SQL y Python)
  Funciones generales:
 Se encargará de diseñar algoritmos de aprendizaje automático específicos que aumenten la automatización del mantenimiento y minimicen la intervención humana para optimizar la contención de costos y la experiencia del cliente a largo plazo."
INGENIERO DE DATOS SR,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18344241,"Descripción
DESCRIPCIÓN:
Coordinar al equipo asignado para proveer de información adecuada y oportuna a los diferentes niveles de la empresa, mediante el diseño, desarrollo y evaluación de las tecnologías para almacenamiento, gestión y análisis de información que facilitan la democratización de datos críticos como indicadores y métricas corporativas.


RESPONSABILIDADES:
Coordinar al equipo asignado para proveer de información adecuada y oportuna a los diferentes niveles de la empresa, mediante el diseño, desarrollo y evaluación de las tecnologías para almacenamiento, gestión y análisis de información que facilitan la democratización de datos críticos como indicadores y métricas corporativas.
Asegura el buen funcionamiento de las herramientas para gestión de datos de la empresa
Supervisa y valida las soluciones técnicas propuestas por los equipos de ingeniería de datos e ingeniería de BI
?Definir las actividades y responsables de cada requerimiento.
Comunicar los avances de cada requerimiento
Anticipa la obsolescencia o necesidades de tecnología de acuerdo a la dinámica del negocio


REQUERIMOS:
Ing. en Sistemas Computacionales, Lic. en Informática (Titulado)
Ingles Intermedio
Conocimiento de herramientas de analítica de datos
Conocimientos del negocio de logística y/o mensajería, uso de tecnologías de Big Data y analítica.
Manejo de Microsoft Office (Word, Excel, PowerPoint)
Deseable Story Telling o experiencia comunicando a foros executivos
Metodologías de gestión de proyectos ágiles
Gestión de Datos y análisis de datos (Pentaho, SAP Business Objects, SAP BI/ BW, Microsoft Power BI, Cloudera, DB2, Postgresql, JavaScript, SQL Server , Tableau
CONOCIMIENTO INDISPENSABLE DE SAP

EXPERIENCIA:
SAP HANA INDISPENSABLE
DBA 3 años
Responsable de DWH 3 años
Arquitecto de Datos 1 año
Ingeniero de Datos o Ingeniero de BI 5 años


Interesados, favor de compartirme su curriculum:"
Especialista Identidad Digital,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18230599,"Descripción
La disrupción es la nueva normalidad, y en el Tecnológico de Monterrey, cada mañana, nos despertamos con la responsabilidad de transformar nuestro entorno. Nuestros procesos están centrados en las personas, asegurando experiencias extraordinarias junto con nuestro talento y el nuevo Modelo Educativo Tec21. ¡Aquí encontrarás tu propósito! aprovecharás oportunidades innovadoras, formando parte de una cultura colaborativa basada en la inclusión, la meritocracia y el respeto.


¿Te consideras una persona con mucha pasión por nuevos retos, inquietud por aportar ideas innovadoras y sobre todo comprometido a transformar México a través de la educación?
¡Esta oportunidad es para ti!


¿Qué harás?
Siendo Arquitecto de Identidad Digital el reto principal es diseñar, implementar y optimizar la soluciones de gestión de identidad dentro de los sistemas de tecnología con el nuevo ecosistema digital, para el aseguramiento, protección y aprovechamiento de los datos de identificación y acceso de los usuario

¿Cómo lo harás?
Tus principales retos serán:
Diseño del modelo de identidad del nuevo ecosistema tecnológico
Exitosa implementación de la arquitectura de datos, que permita cumplir con los requerimientos funcionales, técnicos y de negocio de corto, mediano y largo plazo
Establecer los principios de gobernanza de las datos de identidad en el ecosistema
Implementación de políticas y procesos para el aseguramiento de la calidad e integridad de los datos de identidad y el perfil único del ecosistema
Enlace con el arquitecto de técnico y arquitecto de datos para el desarrollo de soluciones que satisfagan las necesidades de los públicos
Exitosa integración y flujo de los datos de identidad con tecnologías third-party en el ecosistema

¿Qué buscamos? 
Si tienes formación en Tecnología de la información, has tenido la experiencia de trabajar en Access Management, single sign-on (SSO), federated identities, multi-factor authentication (MFA) and privileged account management y entre tus habilidades se encuentran IAM,MDM y AD. ¡Te estamos buscando, postúlate ya!

¿Por qué trabajar con nosotros?
Nuestro talento es la fuerza que impulsa nuestro éxito. Su talento, dedicación y pasión son los pilares fundamentales de nuestra organización. Por ello, nos enfocamos en ofrecer beneficios de calidad que promuevan su equilibrio emocional, su bienestar financiero y su desarrollo profesional.


En el Tec de Monterrey actuamos bajo un principio de igualdad de oportunidades. Por ello no discriminamos por edad, origen étnico, nacionalidad, género, orientación sexual, estado civil, condición social, estado de salud, creencias religiosas, doctrina política o discapacidad.
** Agradecemos tu interés en participar en nuestras vacantes. En caso de no ser contactado/a por el equipo de Atracción de Talento, te invitamos a continuar revisando nuevas oportunidades en el portal de Oportunidades de Crecimiento, si eres colaborador del TEC. .



La disrupción es la nueva normalidad, y en el Tecnológico de Monterrey, cada mañana, nos despertamos con la responsabilidad de transformar nuestro entorno. Nuestros procesos están centrados en las personas, asegurando experiencias extraordinarias junto con nuestro talento y el nuevo Modelo Educativo Tec21. ¡Aquí encontrarás tu propósito! aprovecharás oportunidades innovadoras, formando parte de una cultura colaborativa basada en la inclusión, la meritocracia y el respeto.


¿Te consideras una persona con mucha pasión por nuevos retos, inquietud por aportar ideas innovadoras y sobre todo comprometido a transformar México a través de la educación?
¡Esta oportunidad es para ti!"
Data Modeler,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18359165,"Descripción
We're hiring!  
 At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide.?A Great Place to Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! 
We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Data Modeler

What you'll do: 
•    Demonstrate ability to write new code i.e., well-documented and stored in a version control system (we use GitHub & Bitbucket)
•    Good to have experience with Cloud Platforms such as AWS, Azure, GCP and Snowflake
•    Good to have strong programming/ scripting skills (Python, PowerShell, etc.)
•    Good to know about developing financial models and forecasting to support financial planning and decision-making processes.
•    Experience around responsibility for analyzing and interpreting financial data to provide valuable insights and support strategic decision-making.
•    Collaborating with product owners to identify requirements, define desired outcomes and deliver trusted results.
•    Building processes supporting data transformation, data structures, metadata,
dependency and workload management.
•    In this role, SQL is heavily focused. An ideal candidate must have hands-on experience with SQL database design. Plus, Python.
•    Demonstrably deep understanding of SQL (level: advanced) and analytical data warehouses (Snowflake preferred).
•    Demonstrated ability to write new code i.e., well-documented and stored in a version control system (we use GitHub & Bitbucket)
•    Familiar with JIRA & Confluence.
•    Must have exposure to technologies such as dbt, Apache airflow and Snowflake.
•    Desire to continually keep up with advancements in data engineering practices.
•    Knowledge on AWS cloud, Python is a plus.""

Minimum Qualifications:
•    5+ years of IT experience with major focus on data warehouse/database related projects
•    As user, must have exposure to technologies such as dbt, Apache Airflow, Snowflake (para hacer dashboards).
•    Experience in data platforms: Snowflake, Oracle, SQL Server, MDM etc
•    Expertise in writing SQL and database objects - Stored procedures, functions, views. Hands on experience in ETL/ELT and data security, SQL performance optimization and job orchestration tools and technologies e.g., dbt, Attunity, Golden Gate, APIs, Apache Airflow, etc.
•    Experience in data modeling and relational database design
 Experience working with agile methodologies (Scrum, Kanban) and Meta Scrum with cross-functional teams (Product Owners, Scrum Master, Architects, and data SMEs)
•    Well-versed in applying SCD, CDC, and DQ/DV framework – NICE TO HAVE.
Why Cognizant? 
 Improve your career in one of the largest and fastest growing IT services providers worldwide 
Receive ongoing support and funding with training and development plans 
Have a highly competitive benefits and salary package 
Get the opportunity to work for leading global companies 
We are committed to respecting human rights and build a better future by helping your minds and the environment  
We invest in people and their wellbeing.  We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered.  
 At Cognizant we believe than our culture makes us stronger!? 
Join us now! 
#BeCognizant #IntuitionEngineered "
Administrador de bases de datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18345705,"Descripción
Escolaridad: Licenciatura/Ingeniería en Sistemas Computacionales, informática o carrera afín a tecnologías de la Información
Funciones Generales:
Responsable de la Gestión de las Infraestructuras de almacenamiento y procesamiento de la información.
Responsable del diseño de soluciones de almacenamiento y procesamiento de la información.
Implementación y cumplimiento de KPIs, para la medición de calidad de servicio en los recursos tecnológicos de información.
Optimización y estandarización de procesos y recursos tecnológicos de información.
Generación de soluciones tecnológicas de información, innovadoras y vanguardistas.
Funciones Especificas:
Diseño de arquitectura de solución para las bases de datos
Diseño de infraestructura para procesamiento de las bases de datos
Diseño de estructuras de las bases de datos
Implementación de reglas y buenas prácticas en el diseño de estructuras de bases de datos.
Implementación de índices, esquemas, normalización, restricciones, transacciones.
Implementación de metodología ACID.
Atomicidad, coherencia, aislamiento, durabilidad.
Administrar el rendimiento de las infraestructura, arquitectura y estructura de las bases de datos.
Administrar la integración de las bases de datos con las aplicaciones.
Custodiar las infraestructuras y estructuras de bases de datos mediante la implementación de capas de seguridad.
Análisis de la información de las bases de datos para transformar los datos sin procesar en información de inteligencia empresarial real.
Gestión de bases de datos relacionales, no relacionales y estructuras de Big Data.
Responsable de la integridad de la información mediante procesos que garanticen la no perdida de información, o la transformación o calculo erróneo da los datos.
Gestión de manejadores de bases de datos como Oracle, Microsoft SQL, Postgres, MySQL, BD2, MongoDB, Casandra, DocumentDB.
Seguimiento a proyectos tecnológicos de base de datos.
Evaluación del análisis de requerimientos para el procesamiento de información.
Definición y mejora en la calidad de los servicios de procesamiento de la información por la empresa.
Validación técnica de servicios de outsourcing, freelance, proveedores y terceros.
Definir herramientas y capacitaciones para mantener vigentes los conocimientos técnicos relacionados al procesamiento de información.
Certificaciones:·Database administrator, AWS o Azure Architect, Data Science, Big Data"
Remote Cloud Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18333453,"Descripción
Remote cloud Architect
 NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a remote Cloud Architect.
  In these roles you will be responsible for:
 ·      Lead design, build and migration projects for with Azure cloud solutions
·      Architect and design solutions to meet functional and non-functional requirements in Azure
·      Create and review architecture and solution design artifacts
·      Recommend solution to internal/external stakeholders (director level and above) clearly articulating the pros and cons of various solutions
·      Provide guidance and mentoring for team members and review their deliverables for quality and thoroughness
·      Proactively communicate the Program/project managers by Identifying, mitigate Risks, Assumptions, Issues, assumptions throughout full lifecycle
 Technical requirements for this role include:
 ·      Experience in architecting and designing technical solutions based on industry standards using Azure IaaS, PaaS and SaaS capabilities.
·      Hands-on experience in customization and implementation of modern cloud architecture for maximum flexibility, extensibility, and maintainability using Microsoft Azure.
·      Hands on experience migrating on-premises applications into Azure Cloud
·      Virtualization platforms: IBM PowerVM, Linux KVM/Xen, OracleVM, containers: LXD, docker
·      Programming languages and dev tools: perl, python, shell scripting/unix tools, Ansible, Git/RCS
   Nice to have:
·      Hands on experience in creating Devops pipeline using Azure DevOps tools
·      Hands on experience in two or more of Azure Analytics such as Data Lake, Data Factory, Synapse, Power BI
·      Hands on experience in two or more of Azure Computation products such as API Apps, Azure Functions, Azure Kubernetes Services (AKS)
·      Hands on experience in two or more of Azure Databases such as Azure API for FHIR, Cosmos DB, Azure SQL, MySQL
·      Hans on Experience with Azure Storage (Azure Blob API and Azure Table API), Azure SQL, Azure Cosmos DB and APIs (e.g. Core SQL, Azure Table, Gremlin) in the architecture and development of cloud applications.
·      Hands on experience in MySQL, Oracle
·      Hands on with Operating systems: Linux and Unix
  Preferences: 
 ·      Undergraduate degree and 15+ years relevant experience
·      Deep domain experience with 4+ year's work experience in Services, cloud computing or technical project delivery
·      Experience interacting with or managing technical and executive level relationships (IT manager and director level)
·      Comfortable operating in global, distributed teams that deliver quality services.
·      Cloud Certification (Azure/AWS/GCP) is highly desirable.

Benefits:
·      Competitive salary (negotiable)
·      Grocery Tickets - 12% of base salary
·      30 days of Christmas bonus
·      12 days of vacations
·      50% Vacation bonus
·      5 personal days per year
·      Medical insurance (You and your family)
·      Life insurance
·      Opportunity to grow in the company.
 Lic. Salvador Velasco"
Remote Cloud Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18333452,"Descripción
Remote cloud Architect
 NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a remote Cloud Architect.
  In these roles you will be responsible for:
 ·      Lead design, build and migration projects for with Azure cloud solutions
·      Architect and design solutions to meet functional and non-functional requirements in Azure
·      Create and review architecture and solution design artifacts
·      Recommend solution to internal/external stakeholders (director level and above) clearly articulating the pros and cons of various solutions
·      Provide guidance and mentoring for team members and review their deliverables for quality and thoroughness
·      Proactively communicate the Program/project managers by Identifying, mitigate Risks, Assumptions, Issues, assumptions throughout full lifecycle
 Technical requirements for this role include:
 ·      Experience in architecting and designing technical solutions based on industry standards using Azure IaaS, PaaS and SaaS capabilities.
·      Hands-on experience in customization and implementation of modern cloud architecture for maximum flexibility, extensibility, and maintainability using Microsoft Azure.
·      Hands on experience migrating on-premises applications into Azure Cloud
·      Virtualization platforms: IBM PowerVM, Linux KVM/Xen, OracleVM, containers: LXD, docker
·      Programming languages and dev tools: perl, python, shell scripting/unix tools, Ansible, Git/RCS
   Nice to have:
·      Hands on experience in creating Devops pipeline using Azure DevOps tools
·      Hands on experience in two or more of Azure Analytics such as Data Lake, Data Factory, Synapse, Power BI
·      Hands on experience in two or more of Azure Computation products such as API Apps, Azure Functions, Azure Kubernetes Services (AKS)
·      Hands on experience in two or more of Azure Databases such as Azure API for FHIR, Cosmos DB, Azure SQL, MySQL
·      Hans on Experience with Azure Storage (Azure Blob API and Azure Table API), Azure SQL, Azure Cosmos DB and APIs (e.g. Core SQL, Azure Table, Gremlin) in the architecture and development of cloud applications.
·      Hands on experience in MySQL, Oracle
·      Hands on with Operating systems: Linux and Unix
  Preferences: 
 ·      Undergraduate degree and 15+ years relevant experience
·      Deep domain experience with 4+ year's work experience in Services, cloud computing or technical project delivery
·      Experience interacting with or managing technical and executive level relationships (IT manager and director level)
·      Comfortable operating in global, distributed teams that deliver quality services.
·      Cloud Certification (Azure/AWS/GCP) is highly desirable.

Benefits:
·      Competitive salary (negotiable)
·      Grocery Tickets - 12% of base salary
·      30 days of Christmas bonus
·      12 days of vacations
·      50% Vacation bonus
·      5 personal days per year
·      Medical insurance (You and your family)
·      Life insurance
·      Opportunity to grow in the company.
 Lic. Salvador Velasco"
Remote Cloud Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18333449,"Descripción
Remote cloud Architect
 NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now. We are currently seeking a remote Cloud Architect.
  In these roles you will be responsible for:
 ·      Lead design, build and migration projects for with Azure cloud solutions
·      Architect and design solutions to meet functional and non-functional requirements in Azure
·      Create and review architecture and solution design artifacts
·      Recommend solution to internal/external stakeholders (director level and above) clearly articulating the pros and cons of various solutions
·      Provide guidance and mentoring for team members and review their deliverables for quality and thoroughness
·      Proactively communicate the Program/project managers by Identifying, mitigate Risks, Assumptions, Issues, assumptions throughout full lifecycle
 Technical requirements for this role include:
 ·      Experience in architecting and designing technical solutions based on industry standards using Azure IaaS, PaaS and SaaS capabilities.
·      Hands-on experience in customization and implementation of modern cloud architecture for maximum flexibility, extensibility, and maintainability using Microsoft Azure.
·      Hands on experience migrating on-premises applications into Azure Cloud
·      Virtualization platforms: IBM PowerVM, Linux KVM/Xen, OracleVM, containers: LXD, docker
·      Programming languages and dev tools: perl, python, shell scripting/unix tools, Ansible, Git/RCS
   Nice to have:
·      Hands on experience in creating Devops pipeline using Azure DevOps tools
·      Hands on experience in two or more of Azure Analytics such as Data Lake, Data Factory, Synapse, Power BI
·      Hands on experience in two or more of Azure Computation products such as API Apps, Azure Functions, Azure Kubernetes Services (AKS)
·      Hands on experience in two or more of Azure Databases such as Azure API for FHIR, Cosmos DB, Azure SQL, MySQL
·      Hans on Experience with Azure Storage (Azure Blob API and Azure Table API), Azure SQL, Azure Cosmos DB and APIs (e.g. Core SQL, Azure Table, Gremlin) in the architecture and development of cloud applications.
·      Hands on experience in MySQL, Oracle
·      Hands on with Operating systems: Linux and Unix
  Preferences: 
 ·      Undergraduate degree and 15+ years relevant experience
·      Deep domain experience with 4+ year's work experience in Services, cloud computing or technical project delivery
·      Experience interacting with or managing technical and executive level relationships (IT manager and director level)
·      Comfortable operating in global, distributed teams that deliver quality services.
·      Cloud Certification (Azure/AWS/GCP) is highly desirable.

Benefits:
·      Competitive salary (negotiable)
·      Grocery Tickets - 12% of base salary
·      30 days of Christmas bonus
·      12 days of vacations
·      50% Vacation bonus
·      5 personal days per year
·      Medical insurance (You and your family)
·      Life insurance
·      Opportunity to grow in the company.
 Lic. Salvador Velasco"
Data Analyst - English prificiency - BI and CRM,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18261374,"Descripción
Gates is a leading manufacturer of application-specific fluid power and power transmission solutions. We push the boundaries of material science to engineer solutions that continually exceed customer expectations.
 Let's simplify it, think belts and hoses. Found in motorcycles, conveyer belts, cars, tractors, blenders, vacuum cleaners, bicycles, & 3D printers just to name a few. Because why not do it all? 
 WHAT TO EXPECT
As an innovation leader, we look for ambitious, forward thinking, open-minded and well-rounded individuals to join our global team. Located in our Santa Fe office, you will play a critical role within our Americas Commercial organization, helping to drive sales effectiveness and productivity across the demand, lead, and revenue generation sales process. This role requires a candidate who is highly analytical with the ability to deliver key sales and customer insights while prescribing wide-ranging business recommendations to our Commercial team sales leaders. The right candidate should be a curious intellect, detail-oriented, and possess excellent written and verbal communication skills. 
 RESPONSIBILITIES: 
 Champion CRM, partner with our field sales management teams to streamline business processes and train/promote the use of CRM to drive overall sales effectiveness (demand generation) and sales velocity (revenue generation). 
Develop and promote the use of our Sales Enablement playbook and digital transformation tools (i.e. CRM, BI Cognos, Tableau, SQL, etc.). Assist with training to support user compliance and adoption of our sales enablement toolkit.
Advance new sales effectiveness strategies designed to improve sales performance and utilize knowledge of statistical modeling and predictive AI models to prescribe recommendation using quantitative and qualitative data analysis.
Develop enterprise strategic dashboards and consult on data visualization techniques and storytelling to deliver self-service data exploration and actionable insights.
Analyze, develop, and execute all recurring reporting (daily, weekly, monthly) and ensure the information is accurate and readily accessible to business partners.
Unleash commercial pipeline and funnel strength reporting and analysis to increase lead generation conversion rates and ultimately, sales velocity. Identify white space opportunities and provide prescribed recommendations to increase share of shelf.
Perform project based and ad-hoc business analysis; formulate senior management presentations, data mining, and storytelling.
Analyze complex data requirements and architect effective data models/reporting solutions using SQL, Tableau Prep.
Create a continuous improvement culture by documenting current state processes and implement business process improvement solutions to automate, where possible, and improve BI reporting business processes and infrastructure.
Works closely with business unit leaders and support annual growth initiatives and Commercial strategic projects.
Works closely with business unit leaders and supports annual growth initiatives and special Commercial projects.


QUALIFICATIONS: 
A curious intellect with strong analytical and business process management skills.
2-4 years in Sales Enablement/Operations or related work experience. 
High degree of proficiency using BI and CRM applications such as Tableau, SQL, Cognos, and Oracle Sales Cloud (CX) a plus.
Strong data skills and ability to use them to understand the dataset to provide business reporting and analytic solutions
Strong analytical and problem-solving skills: experience using data to tell a story
Advanced Skills in MS Office (Excel, Power Point) 
Track record of continuously seeking out and improving business processes (i.e. lean six sigma)
Project management with strong organizational and problem-solving skills. 
Self-starter that is comfortable working in matrix, project-oriented environment.
Ability to work effectively with Commercial Sales teams and senior-level executives.
English proficiency - strong verbal and written communication skills.
BS/BA in related field

WHY GATES?
Founded in 1911 in Denver, Colorado, Gates is publicly traded on the NYSE. While we might operate in a vast amount of time zones we operate as 'One Gates' and have a common goal of pushing the boundaries of materials science. We invest in our people, bringing real-world experience that enables us to solve our customers' diverse challenges of today and anticipate those of tomorrow. 
 While we expect the best we also want to give you the best. That's why at Gates we provide an environment where people can succeed from our policy of 'Dress for your Day' (yes - that means you can wear jeans), health club reimbursement, to our ownership of your work/life balance and more. Visit gates .com/careers to learn more.
 WORK ENVIROMENT
While performing the duties of this job, the employee is frequently required to sit; use hands to finger, handle, or feel objects, tools, or controls; and talk or hear. The employee is occasionally required to stand, walk, and reach with hands and arms. The employee must frequently lift and/or move up to 10 pounds. Specific vision abilities required by this job include close vision.
 Gates is an Equal Opportunity and Affirmative Action Employer and is committed to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of race, sex, color, religion, age, disability, pregnancy, citizenship, sexual orientation, gender identity, national origin, protected veteran status, genetic information, marital status, or any other consideration defined by law. 
 ARE YOU DRIVEN BY POSSIBLITY?"
DESARROLLADOR SQL Sr.,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18245404,"Descripción
Experiencia: 
1. +3 años en diseño de modelos de datos 
2. +3 años en lenguaje SQL(Avanzado)
3. +3 años en alguna Herramienta ETL/ELT (ODI, IPC, DBT, Matillion, Data Services, Etc...) 
4. +2 años trabajando en metodología Agile
5. +3 años en análisis e interpretación de la información

Descripción:
Esta rol diseña, desarrolla e implementa procesos efectivos y eficientes para los flujos de datos, incluido cómo se adquieren, procesan y almacenan.

Responsabilidades:
1. Desarrollar soluciones escalables que se adapten a nuestro entorno actual teniendo en cuenta los requisitos de crecimiento futuro.
2. Demuestra liderazgo y capacidad técnica al enseñar y capacitar a otros.
3. colaborar con pares(Data Engineers / Data Architects) en diseño de soluciones de información y técnicas de codificación.
4. Análisis de requerimientos entrantes, planeacion y plan de liberacion de los mismos.
5. Colaborar con equipos de negocio y de sistemas para la definición correcta de los modelos de información y/o métricas

ZONA A LABORAR EN SANTA FE"
Ingeniero/a ciberseguridad en protección de datos BBVA,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18231758,"Descripción
En BBVA llevamos más de 80 años trabajando para nuestros clientes.
Nuestro propósito es poner al alcance de todos las oportunidades de esta nueva era.
Este propósito refleja nuestro papel facilitador para ofrecer a nuestros clientes las mejores soluciones bancarias, ayudarles a tomar las mejores decisiones financieras e impactar positivamente en su vida.

La Dirección General de Engineering es pieza fundamental dentro de la organización del Grupo BBVA México. Participamos como un solo equipo con las demás direcciones generales, aportando valor en la transformación de nuestro banco y de nuestro grupo, nuestra principal responsabilidad reside en desarrollar y operar soluciones tecnológicas y procesos seguros para mejorar la experiencia de nuestros clientes, ofrecer mejores productos y servicios y garantizar la continuidad operativa de nuestro banco.
Principales funciones
- Definir, planear y dirigir la implementación y ejecución de proyectos para la protección de la información, controlando las demandas de alcance, tiempo, costo, calidad, recursos y riesgos.
- Facilitar el cumplimiento de requerimientos normativos internos y externos (i.e. regulatorios) de protección de datos, para reducir la exposición a incidentes de exfiltración, a través de sesiones o correos explicativos.
- Colaborar mediante sesiones de trabajo, con equipos locales y regionales, de distintas funciones (e.g. Data Privacy Officer, Solutions Architect, Legal, Security Operations) para proporcionar soporte a las unidades de negocio en materia de protección de la información.
- Evaluar y gestionar vulnerabilidades e incidentes de protección de datos, mediante el análisis de información para determinar el impacto a la organización.
- Desarrollar casos de negocio, recopilando y analizando información para determinar su alcance, entregables y parámetros de medición, a fin de cumplir con los objetivos del proyecto/iniciativa.


Responsabilidades
Gestionar los objetivos de integridad, confidencialidad y disponibilidad de la Seguridad de la Información del Grupo Financiero BBVA a través de la entrega de servicios como:
- Monitorear indicadores de riesgo e indicadores de desempeño para incrementar el índice de madurez de ciberseguridad, mediante la implementación de iniciativas asociadas a la protección de información críticamente confidencial


Retos del puesto
Ser una persona que se pueda cuestionar para saber si su aportación es de ayuda para el área

Si te interesa formar parte de un equipo cuya principal responsabilidad reside en gestionar soluciones tecnológicas y procesos seguros para mejorar la experiencia de nuestros clientes, ofrecer mejores productos y servicios y garantizar la continuidad operativa de nuestro banco, ¡esta oportunidad es para ti!
La vacante tiene un esquema laboral de asistencia presencial híbrida, con sede en el Corporativo Parques Polanco, Ciudad de México.
Buscamos a personas que cumplan los siguientes requisitos:
Conocimientos: 
Deseables
- Protección de datos personales
- Seguridad y Riesgo Tecnológico
- Cybersecurity (i.e. Strong understanding of technical/security concepts such as network architecture design, logical access controls, vulnerability management, encryption, and cloud computing.)
- Modelo de Gobierno de Datos
- Conocimiento de los frameworks NIST-CSF; serie ISO 27000; PCI-DSS; COBIT; CIS; OWASP Top 10
- Certificaciones: ISO/IEC 27001 - Information Security Management

Escolaridad:
 Licenciatura en ingeniería de ciencia de datos, actuaría, matemáticas aplicada o afín (Titulados o en trámite)
Experiencia:
Mínima de de 1 a 3 años en ciberseguridad de protección de datos

Competencias: 
Toma de decisiones basada en datos.
Capacidad de análisis para plantear soluciones.
Trabajo en equipo.
Proactividad.
Adaptación al cambio.
Trabajo bajo presión.
Aprendizaje continuo."
Snowflake Technical Lead,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=2&jobid=18237231,"Descripción
We're hiring!  
 At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide.?A Great Place to Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! 
We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Technical Lead.
What you'll do: 
·      Take the responsibility of the Snowflake delivery from Mexico in all aspects. Collaborate with U.S and offshore teams to deliver high quality output.
·      Developing data management solutions using Snowflake.
·      Snowflake concepts like setting up Resource monitors, RBAC controls, scalable virtual warehouse, SQL performance tuning, zero copy clone, time travel and automating them.
·      Migration processes to Snowflake from on-premises database environment.
·      Handling semi-structured data (JSON, XML), columnar PARQUET using the VARIANT attribute in Snowflake.
·      DesSnowflake using combination of Python, PySpark, Bash with SnowSQL.
Minimum Qualifications:
·      Experience in Cloud technologies such as AWS – S3, SQS, EC2, Lambda, Redshift, RDS
·      Snow SQL Experience in developing stored Procedures writing Queries to analyze and transform data.
·      Certified Snowflake cloud data warehouse Architect (Desirable).
·      Top Skills: Snowflake (Mandatory), Cloud Data Quality/Informatica Data Quality (Desirable)
·      8+ years of experience implementing data management solutions 
·      6+ years of experience in Snowflake
·      Experience in designing and building manual or auto ingestion data pipeline using Snowpipe.
·      Experience in in re-clustering of the data in Snowflake with good understanding on Micro-Partitions.
Why Cognizant? 
 Improve your career in one of the largest and fastest growing IT services providers worldwide 
Receive ongoing support and funding with training and development plans 
Have a highly competitive benefits and salary package 
Get the opportunity to work for leading global companies 
We are committed to respecting human rights and build a better future by helping your minds and the environment  
We invest in people and their wellbeing.  We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered.  
 At Cognizant we believe than our culture makes us stronger!? 
Join us now! 
#BeCognizant #IntuitionEngineered "
Data Engineer - Azure/AWS,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18197898,"Descripción
EY-GDS-DnA Consulting – Data Engineer

As part of our EY-GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 1-5 years of experience, Data Engineering, AZURE Cloud, Advanced SQL, Advanced Phyton programming, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. 

The opportunity 
 We are looking for a Senior Data Engineer with expertise in developing and managing data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. 

Your key responsibilities 

Design and Develop batch and streaming data processing. 
Build data systems and pipelines.
Evaluate business needs and objectives. 
Prepare data for prescriptive and predictive modeling. 
Build prototypes. 
Combine raw information from different sources. 
Explore ways to enhance data quality and reliability. 
Identify opportunities for data acquisition. 
Monitor and optimize data storage and data processing.
Design and implement data security 

Skills and attributes for success 

1-5 years of experience on Azure Data Factory. 
1-5 years of experience on Databricks/Synapse. 
Experience on processing real time data. 
Advanced knowledge on processing large amounts of data (billions of records).
1-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. 
Advanced knowledge on data structures, MPP Databases, Blob Storage. 
1-5 years of experience on AZURE storage (Blob, ADLS).
Previous experience as a data engineer or in a similar role. 
Data engineering certification (AZURE Certified Data Engineer) is a plus. 
Flexible and adaptable; able to work in ambiguous situations. 
Able to work effectively at all levels in an organization. 
Must be a team player and able to work collaboratively with and through others. 
Must like to learn. 

 To qualify for the role, you must have 

Bachelor's in technology or engineering or similar. 
Experience working with Azure, Snowflake technologies. 

Ideally, you'll also have 
Familiarity with agile methodologies. 
Familiarity with software such as Jira or ADO. 

What we look for 
A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment.
Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries. 
  What working at EY offers 
  At EY, we're dedicated to helping our clients, from world's top companies — and the work we do with them is as varied as they are. 
You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: 
Support, coaching and feedback from some of the most engaging colleagues around.
Opportunities to develop new skills and progress your career.
The freedom and flexibility to handle your role in a way that's right for you 
  About EY 
  As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make
our ambition to be the best employer by 2020 a reality.   
If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. 
  Join us in building a better working world.  
  Apply now. 

 "
Ingeniero de datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18150330,"Descripción
Empresa líder en telecomunicaciones busca tú talento como: Ingeniero de datos


REQUISITOS:

Ing. Sistemas, Lic. en Informática, Actuaria, Matemáticas aplicadas o carrera a fin.
Ingles intermedio.
Experiencia en diseño de modelos de datos, conocimientos en lenguaje SQL(Intermedio).
Manejo de alguna Herramienta ETL/ELT (ODI, IPC, DBT, Matillion, Data Services, Etc...). 
Experiencia con metodología Agile
Análisis e interpretación de la información.
Deseable contar con 1 -2 años de experiencia en puesto similar.

RESPONSABILIDADES DEL PUESTO:

Desarrollar soluciones escalables que se adapten a nuestro entorno actual teniendo en cuenta los requisitos de crecimiento futuro.
Colaborar con pares(Data Engineers / Data Architects) en diseño de soluciones de información y técnicas de codificación.
Análisis de requerimientos entrantes, planeación y plan de liberación de los mismos.
Colaborar con equipos de negocio y de sistemas para la definición correcta de los modelos de información y/o métricas.


OFRECEMOS:

Sueldo base competitivo.
Prestaciones de ley.
Prestaciones superiores: Seguro de vida, seguro de gastos médicos, vales de despensa, fondo de ahorro, servicio de transporte y comedor, beneficios con la empresa.


Sí cumples con el perfil postúlate por este medio o bien, envía tu CV al correo de contacto colocando en asunto el titulo del puesto."
Quality Assurance Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18148810,"Descripción
NTT DATA esta conformada por un equipo de más de 139,000 profesionistas diversos, operamos en más de 50 países a través del mundo. Los sectores donde tenemos actividades distintas incluyen: Telecomunicaciones, finanzas, energía, administración pública y Salud.

Nos encontramos en la búsqueda de un Quality Assurance Architect 

Conocimientos requeridos:

Licenciatura concluida en sistemas o afín
Profesional de control de calidad con más de 10 años de experiencia en gestión y industria de software
Cinco años de experiencia en automatización de pruebas con un mínimo de tres años en un nivel superior. Demostrado. Experiencia en la selección, diseño e implementación de marcos de automatización de pruebas. Experiencia desarrollando herramientas de automatización internas.
Fuerte experiencia práctica en el uso de Selenium Web Driver con Java, JIRA, Confluencia y Zephyr


OFRECEMOS:

Esquema 100% nómina
Esquema HO
Contrato indeterminado a partir del 4to mes
Plan de Carrera
S. Vida
SGMM
Vales de despensa
Tarjeta digital para pago de servicios
Fondo de ahorro
Plan dental
Prestaciones de Ley"
NetSuite Analytics Warehouse Principal Consultant,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18407052,"Descripción
We are looking for an experienced consultant/developer with significant hands-on experience working with NetSuite SuiteAnalytics Connect, integration, ETL and data warehouse solutions to assist Oracle NetSuite's clients with their data warehouse reporting needs. Knowledge of related solutions such as Oracle Analytics Cloud (OAC), NetSuite SuiteAnalytics Connect, Autonomous Data Warehouse (ADW) and Oracle Fusion Analytics Warehouse (FAW) is greatly desired. Key Responsibilities: Gather customer requirements and collaborate with the customer to define the business challenge the customer is attempting to better understand with data Taking the defined business objective, leveraging the understanding of the data model and producing analytics to provide actionable insights Identify new data and product patterns through data mining and communicate those complex concepts and the results of the analyses in a clear and effective manner through creative visualization directly to company executives Extend the current data warehouse by incorporating data from 3rd party datasets/applications  Build data pipelines from multiple data sources by performing necessary ETL tasks including processing, cleansing, and verifying the integrity of data used for analysis Serve as a technical expert when implementing solutions. Develop solutions that follow product development guidelines and are in-line with established design standards and approved architectures. Transfer product knowledge to customers to reinforce training and ensure adoption. Resolve or escalate client issues as appropriate to support and engineering teams. Develop and maintain up-to-date knowledge of Oracle and NetSuite analytics, data integration products, and service offerings. Work collaboratively with the NetSuite Product Team to influence design, product features, and roadmap. Attend internal meetings and collaborate by sharing knowledge and best practices within the practice including mentoring sessions for junior resources, and other strategic initiatives. Preferred Qualifications/Skills include: At least 5 - 8 years of experience in OBIEE/Hyperion/Oracle Analytics Cloud, Data Warehouse, or SQL experience, ideally with integration to/from Oracle NetSuite Application Solid understanding of Oracle Database, Data Modelling, Oracle SQL Developer, Data Warehouse concepts, advanced analytics concepts, and implementation. Experience querying databases and using statistical computer languages: R, Python, SLQ, etc. Experience with the following Oracle solutions is greatly desired: Autonomous Data Warehouse (ADW), Oracle Analytics Cloud (OAC), NetSuite SuiteAnalytics Connect, Oracle Fusion Analytics Warehouse (FAW), JDBC/ODBC, ADO.net Able to perform complex problem solving and work collaboratively with NetSuite Support and Product Management Experience with one or more of the following or similar business applications: NetSuite, SAP, Siebel, Oracle, QuickBooks, Great Plains, Salesforce.com, MAS 90, PeopleSoft, JD Edwards Experience in data design, data modeling, data mapping, data interrogation, data quality, and master data management is desired Strong interpersonal and communication skills Experience architecting and provisioning/configuring cloud-based data warehouse and/or database solutions is desired Travel Modest to moderate, as appropriate. NetSuite is an Equal Opportunity Employer, and all qualified applicants will receive consideration for employment, as NetSuite does not discriminate on the basis of race, color, religion, sex, age, national origin, disability, veteran status, sexual orientation or any other classification protected by Federal, state, or local law. As a world leader in cloud solutions, Oracle uses tomorrow's technology to tackle today's problems. True innovation starts with diverse perspectives and various abilities and backgrounds. When everyone's voice is heard, we're inspired to go beyond what's been done before. It's why we're committed to expanding our inclusive workforce that promotes diverse insights and perspectives. We've partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer a highly competitive suite of employee benefits designed on the principles of parity and consistency. We put our people first with flexible medical, life insurance and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We're committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by calling +1 888 404 2494, option one. Disclaimer: Oracle is an Equal Employment Opportunity Employer*. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans' status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law. * Which includes being a United States Affirmative Action Employer"
Principal NSAW/OBIEE Consultant,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18406972,"Descripción
Come and join us! At NetSuite, we believe the cloud is here to stay and so do our 20,000+ customers. We believe businesses should not be bogged down by the overhead of bulky data centers and expensive personnel to run it all. Businesses need to be lean, efficient, and agile. NetSuite is simply redefining business around the globe by providing a cloud-based, unified system that delivers outstanding capabilities to drive business forward. Founded in 1998 as THE cloud ERP pioneer, today NetSuite has transformed the business operations of our customers without the high costs and inefficiency of on-premise systems. Transform your career at NetSuite At NetSuite, we work hard, and we work thoughtfully. We hire steadfast competitors. We hire individuals that are daring trail blazers. NetSuite employees take the hill, we prefer action over inaction, we are diligent in our mission, and we pause only to celebrate our success. And we DO celebrate, because if you don't have fun along the way, then what's the point? NetSuite is redefining how its customers do business. Summary: The Shared Services Group within Oracle NetSuite Professional Services is chartered to assist and guide our customers by developing analytic reporting strategies and solutions, creating implementation roadmaps, performing assessments, and full-life cycle implementations of analytics solutions. We are looking for an experienced consultant/developer with significant hands-on experience working with NetSuite SuiteAnalytics Connect, integration, ETL and data warehouse solutions to assist Oracle NetSuite's clients with their data warehouse implementation. Knowledge of related solutions such as Oracle Analytics Cloud (OAC) and NetSuite SuiteAnalytics Connect, and Autonomous Data Warehouse (ADW) and Oracle Fusion Analytics Warehouse (FAW) desired. Key Responsibilities: Consultatively gathering customer requirements and collaborate with the customer to define the business challenge the customer is attempting to better understand with data Taking the defined business objective, using the understanding of the data model and producing analytics to deliver actionable insights Identify new data and product patterns through data mining and communicate those complex concepts and the results of the analyses in a clear and effective manner through creative visualization directly to company executives Extend the data warehouse by incorporating data from 3rd party datasets/applications Build data pipelines from multiple data sources by performing necessary ETL tasks including processing, cleansing, and verifying the integrity of data used for analysis Lead project delivery as a technical expert when implementing solutions. Develop solutions that follow product development guidelines and are in-line with established design standards and approved architectures. Transfer product knowledge to customers to reinforce training and ensure adoption. Resolve or advance client issues as appropriate to support and engineering teams. Develop and maintain up-to-date knowledge of Oracle and NetSuite analytics, data integration products and service offerings. Work closely with the NetSuite Product Team to influence design, product features and roadmap. Attend internal meetings and collaborate by sharing knowledge and standard methodologies within the practice including mentoring sessions for junior resources, and other central initiatives. Support pre-sales efforts and drive technology adoption by positioning Oracle NetSuite Consulting services. Preferred Qualifications/Skills include: At least 8 to 10 years of experience in OBIEE/Hyperion/Oracle Analytics Cloud, Data Warehouse, and SQL experience ideally with integration to/from Oracle NetSuite Application Solid understanding of Oracle Database, Data Modelling, Oracle SQL Developer, Data Warehouse concepts, advanced analytics concepts, and implementation. Experience implementing and using Big Data and visualization techniques, tools, and technologies (Spark, Kafka, Tableau, etc.) Experience querying databases and using statistical computer languages: R, Python, SLQ, etc. Experience with following Oracle solutions is greatly desired: Autonomous Data Warehouse (ADW), Oracle Analytics Cloud (OAC), NetSuite SuiteAnalytics Connect, Oracle Fusion Analytics Warehouse (FAW), JDBC/ODBC, ADO.net Able to perform complex problem solving and to work closely with NetSuite Support and Product Management Experience with one or more of the following business applications: NetSuite, SAP, Siebel, Oracle, QuickBooks, Great Plains, Salesforce.com, MAS 90, PeopleSoft, JD Edwards Experience in data design, data modeling, data mapping, data interrogation, data quality, and master data management is desired Good interpersonal and communication skills Experience architecting and provisioning/configuring cloud-based data warehouse and/or database solutions is desired Travel Modest to moderate, as appropriate. Timings US Timezone If this sounds like you, we hope to meet you! Life at Oracle and Equal Opportunity An Oracle career can span industries, roles, Countries and cultures, giving you the opportunity to flourish in new roles and innovate, while blending work life in. Oracle has thrived through 40+ years of change by innovating and operating with integrity while delivering for the top companies in almost every industry. In order to nurture the talent that makes this happen, we are committed to an inclusive culture that celebrates and values diverse insights and perspectives, a workforce that inspires thought leadership and innovation. Oracle offers a highly competitive suite of Employee Benefits designed on the principles of parity, consistency, and affordability. The overall package includes certain core elements such as Medical, Life Insurance, access to Retirement Planning, and much more. We also encourage our employees to engage in the culture of giving back to the communities where we live and do business. At Oracle, we believe that innovation starts with diversity and inclusion and to create the future we need talent from various backgrounds, perspectives, and abilities. We ensure that individuals with disabilities are provided reasonable accommodation to successfully participate in the job application, interview process, and in potential roles to perform crucial job functions. That's why we're committed to creating a workforce where all individuals can do their best work. It's when everyone's voice is heard and valued that we're inspired to go beyond what's been done before. Disclaimer: Oracle is an Equal Employment Opportunity Employer*. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans' status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law. Which includes being a United States Affirmative Action Employer https://www.oracle.com/corporate/careers/diversity-inclusion/ As a world leader in cloud solutions, Oracle uses tomorrow's technology to tackle today's problems. True innovation starts with diverse perspectives and various abilities and backgrounds. When everyone's voice is heard, we're inspired to go beyond what's been done before. It's why we're committed to expanding our inclusive workforce that promotes diverse insights and perspectives. We've partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity. Oracle careers open the door to global opportunities where work-life balance flourishes. We offer a highly competitive suite of employee benefits designed on the principles of parity and consistency. We put our people first with flexible medical, life insurance and retirement options. We also encourage employees to give back to their communities through our volunteer programs. We're committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by calling +1 888 404 2494, option one. Disclaimer: Oracle is an Equal Employment Opportunity Employer*. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans' status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law. * Which includes being a United States Affirmative Action Employer"
Solution Architect Analyst,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18402833,"Descripción
World Business Lenders (WBL) provides general purpose short-term real estate collateralized commercial loans to a broad customer base comprised of small and medium sized businesses throughout the United States that lack access to traditional funding. WBL is a U.S.-based company with a 100% remote workforce. This is a remote Contract/Consultant position. Working hours will be 9:00am-6:00pm Eastern Time, Monday through Friday. The job requires excellent oral and written command of the English language. Resumes must be submitted in English. About the Job: As a Solution Architect, you will be at the forefront of our data transformation journey, tasked with diagnosing and optimizing our current data architecture. Your role will involve a deep dive into commission and quoting processes, identifying pain points, and devising innovative solutions to enhance efficiency and effectiveness. Additionally, you will play a pivotal role in evaluating existing software and programs, as well as exploring new acquisitions to meet our evolving needs. With a focus on problem evaluation and strategic planning, you will have the opportunity to shape the future of our data ecosystem from the ground up. We are seeking individuals who are not only technically proficient but also possess a keen understanding of business objectives and industry trends. Your ability to create data architectures from scratch, coupled with your expertise in Excel, SQL, and VBA, will be essential in driving impactful change within our organization. This role offers a unique opportunity to leverage your skills and creativity to overcome complex challenges and drive meaningful progress in the lending technology landscape. Responsibilities: Diagnose and evaluate existing data architecture, in commission and quoting processes. Propose innovative solutions to optimize data architecture and improve operational efficiency. Determine suitability of existing software and programs, as well as recommend new acquisitions when necessary. Evaluate problems within our data ecosystem and develop strategic plans to overcome them. Create data architectures from scratch, ensuring scalability and sustainability. Assess the value of current Loan Origination Systems (LOS) and Loan Management Software (LMS) and consider migration strategies Requirements • 100% fluency in English, with exceptional English verbal and written communication skills • Bachelor's degree in computer science or related discipline with a minimum of 2 or more years of work experience in a business environment. • Maintain accurate documentation and have excellent written and communication skills. • Critical thinking and good attention to detail in all aspects of administrative support. • The ability to work with a high degree of accuracy and to manage multiple issues and demands. • Must be dependable by meeting deadlines, working independently, being accountable for work, and having good attendance record management. • A strong sense of urgency and a desire to succeed. • Proficiency in Excel, SQL, and Python • Strong problem evaluation skills with wide vision. • Prior experience in architecting data solutions from scratch or rebuilding existing data architectures. • You must have your own computer/laptop - the company does not supply equipment Benefits CONTRACT/CONSULTANCY POSITION USD Experienced Based Salary (depending on experience). 11 US Holidays paid A 100% Fully remote environments)"
Snowflake Technical Lead,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18402883,"Descripción
At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place to Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Technical Lead. What you'll do:  · Take the responsibility of the Snowflake delivery from Mexico in all aspects. Collaborate with U.S and offshore teams to deliver high quality output. · Developing data management solutions using Snowflake. · Snowflake concepts like setting up Resource monitors, RBAC controls, scalable virtual warehouse, SQL performance tuning, zero copy clone, time travel and automating them. · Migration processes to Snowflake from on-premises database environment. · Handling semi-structured data (JSON, XML), columnar PARQUET using the VARIANT attribute in Snowflake. · DesSnowflake using combination of Python, PySpark, Bash with SnowSQL. Minimum Qualifications: · Experience in Cloud technologies such as AWS – S3, SQS, EC2, Lambda, Redshift, RDS · SnowSQL Experience in developing stored Procedures writing Queries to analyze and transform data. · Certified Snowflake cloud data warehouse Architect (Desirable). · Top Skills: Snowflake (Mandatory), Cloud Data Quality/Informatica Data Quality (Desirable) · 8+ years of experience implementing data management solutions · 6+ years of experience in Snowflake · Experience in designing and building manual or auto ingestion data pipeline using Snowpipe. · Experience in in re-clustering of the data in Snowflake with good understanding on Micro-Partitions. Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture makes us stronger! Join us now! #BeCognizant #IntuitionEngineered Employee Status : Full Time Employee Shift : Day Job Travel : No Job Posting : Feb 21 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant."
Snowflake Technical Lead,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18402755,"Descripción
At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place to Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Technical Lead. What you'll do:  · Take the responsibility of the Snowflake delivery from Mexico in all aspects. Collaborate with U.S and offshore teams to deliver high quality output. · Developing data management solutions using Snowflake. · Snowflake concepts like setting up Resource monitors, RBAC controls, scalable virtual warehouse, SQL performance tuning, zero copy clone, time travel and automating them. · Migration processes to Snowflake from on-premises database environment. · Handling semi-structured data (JSON, XML), columnar PARQUET using the VARIANT attribute in Snowflake. · DesSnowflake using combination of Python, PySpark, Bash with SnowSQL. Minimum Qualifications: · Experience in Cloud technologies such as AWS – S3, SQS, EC2, Lambda, Redshift, RDS · SnowSQL Experience in developing stored Procedures writing Queries to analyze and transform data. · Certified Snowflake cloud data warehouse Architect (Desirable). · Top Skills: Snowflake (Mandatory), Cloud Data Quality/Informatica Data Quality (Desirable) · 8+ years of experience implementing data management solutions · 6+ years of experience in Snowflake · Experience in designing and building manual or auto ingestion data pipeline using Snowpipe. · Experience in in re-clustering of the data in Snowflake with good understanding on Micro-Partitions. Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture makes us stronger! Join us now! #BeCognizant #IntuitionEngineered Employee Status : Full Time Employee Shift : Day Job Travel : No Job Posting : Feb 21 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant."
DnA Consulting - Data Engineer - Senior - EY Global Delivery Services,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18394397,"Descripción
As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. The opportunity We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. Your key responsibilities • Design and Develop batch and streaming data processing • Build data systems and pipelines. • Evaluate business needs and objectives. • Prepare data for prescriptive and predictive modeling. • Build algorithms and prototypes. • Combine raw information from different sources. • Explore ways to enhance data quality and reliability. • Identify opportunities for data acquisition. • Monitor and optimize data storage and data processing • Design and implement data security Skills and attributes for success • 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub • 3-5 years of experience on processing real time data. • Advanced knowledge on processing large amounts of data (billions of records) in minutes. • Deep knowledge on producers (ACK/NACK), consumers, and brokers. • Deep knowledge on topics, partitions, and segments. • 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. • Advanced knowledge on data structures, MPP Databases, Blob Storage. • 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud. • Previous experience as a data engineer or in a similar role. • Data engineering certification (AZURE Certified Data Engineer) is a plus. • Flexible and adaptable; able to work in ambiguous situations. • Able to work effectively at all levels in an organization. • Must be a team player and able to work collaboratively with and through others. • Must like to learn. To qualify for the role, you must have • Bachelor's in technology or engineering or similar. • Experience working with Azure, Snowflake technologies. Ideally, you'll also have • Familiarity with agile methodologies. • Familiarity with software such as Jira or ADO. What we look for • A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment • Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries What working at EY offers At EY, we're dedicated to helping our clients, from world's top companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: • Support, coaching and feedback from some of the most engaging colleagues around • Opportunities to develop new skills and progress your career • The freedom and flexibility to handle your role in a way that's right for you About EY As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make our ambition to be the best employer by 2020 a reality. If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now"
DnA Consulting - Data Engineer - Senior - EY Global Delivery Services,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18394150,"Descripción
As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. The opportunity We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. Your key responsibilities • Design and Develop batch and streaming data processing • Build data systems and pipelines. • Evaluate business needs and objectives. • Prepare data for prescriptive and predictive modeling. • Build algorithms and prototypes. • Combine raw information from different sources. • Explore ways to enhance data quality and reliability. • Identify opportunities for data acquisition. • Monitor and optimize data storage and data processing • Design and implement data security Skills and attributes for success • 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub • 3-5 years of experience on processing real time data. • Advanced knowledge on processing large amounts of data (billions of records) in minutes. • Deep knowledge on producers (ACK/NACK), consumers, and brokers. • Deep knowledge on topics, partitions, and segments. • 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. • Advanced knowledge on data structures, MPP Databases, Blob Storage. • 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud. • Previous experience as a data engineer or in a similar role. • Data engineering certification (AZURE Certified Data Engineer) is a plus. • Flexible and adaptable; able to work in ambiguous situations. • Able to work effectively at all levels in an organization. • Must be a team player and able to work collaboratively with and through others. • Must like to learn. To qualify for the role, you must have • Bachelor's in technology or engineering or similar. • Experience working with Azure, Snowflake technologies. Ideally, you'll also have • Familiarity with agile methodologies. • Familiarity with software such as Jira or ADO. What we look for • A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment • Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries What working at EY offers At EY, we're dedicated to helping our clients, from world's top companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: • Support, coaching and feedback from some of the most engaging colleagues around • Opportunities to develop new skills and progress your career • The freedom and flexibility to handle your role in a way that's right for you About EY As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make our ambition to be the best employer by 2020 a reality. If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now"
DnA Consulting - Data Engineer - Senior - EY Global Delivery Services,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18392533,"Descripción
As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. The opportunity We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. Your key responsibilities • Design and Develop batch and streaming data processing • Build data systems and pipelines. • Evaluate business needs and objectives. • Prepare data for prescriptive and predictive modeling. • Build algorithms and prototypes. • Combine raw information from different sources. • Explore ways to enhance data quality and reliability. • Identify opportunities for data acquisition. • Monitor and optimize data storage and data processing • Design and implement data security Skills and attributes for success • 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub • 3-5 years of experience on processing real time data. • Advanced knowledge on processing large amounts of data (billions of records) in minutes. • Deep knowledge on producers (ACK/NACK), consumers, and brokers. • Deep knowledge on topics, partitions, and segments. • 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. • Advanced knowledge on data structures, MPP Databases, Blob Storage. • 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud. • Previous experience as a data engineer or in a similar role. • Data engineering certification (AZURE Certified Data Engineer) is a plus. • Flexible and adaptable; able to work in ambiguous situations. • Able to work effectively at all levels in an organization. • Must be a team player and able to work collaboratively with and through others. • Must like to learn. To qualify for the role, you must have • Bachelor's in technology or engineering or similar. • Experience working with Azure, Snowflake technologies. Ideally, you'll also have • Familiarity with agile methodologies. • Familiarity with software such as Jira or ADO. What we look for • A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment • Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries What working at EY offers At EY, we're dedicated to helping our clients, from world's top companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: • Support, coaching and feedback from some of the most engaging colleagues around • Opportunities to develop new skills and progress your career • The freedom and flexibility to handle your role in a way that's right for you About EY As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make our ambition to be the best employer by 2020 a reality. If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now"
DnA Consulting - Data Engineer - Senior - EY Global Delivery Services,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18392260,"Descripción
As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. The opportunity We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. Your key responsibilities • Design and Develop batch and streaming data processing • Build data systems and pipelines. • Evaluate business needs and objectives. • Prepare data for prescriptive and predictive modeling. • Build algorithms and prototypes. • Combine raw information from different sources. • Explore ways to enhance data quality and reliability. • Identify opportunities for data acquisition. • Monitor and optimize data storage and data processing • Design and implement data security Skills and attributes for success • 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub • 3-5 years of experience on processing real time data. • Advanced knowledge on processing large amounts of data (billions of records) in minutes. • Deep knowledge on producers (ACK/NACK), consumers, and brokers. • Deep knowledge on topics, partitions, and segments. • 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. • Advanced knowledge on data structures, MPP Databases, Blob Storage. • 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud. • Previous experience as a data engineer or in a similar role. • Data engineering certification (AZURE Certified Data Engineer) is a plus. • Flexible and adaptable; able to work in ambiguous situations. • Able to work effectively at all levels in an organization. • Must be a team player and able to work collaboratively with and through others. • Must like to learn. To qualify for the role, you must have • Bachelor's in technology or engineering or similar. • Experience working with Azure, Snowflake technologies. Ideally, you'll also have • Familiarity with agile methodologies. • Familiarity with software such as Jira or ADO. What we look for • A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment • Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries What working at EY offers At EY, we're dedicated to helping our clients, from world's top companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: • Support, coaching and feedback from some of the most engaging colleagues around • Opportunities to develop new skills and progress your career • The freedom and flexibility to handle your role in a way that's right for you About EY As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make our ambition to be the best employer by 2020 a reality. If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now"
Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18376060,"Descripción
At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place To Work where we look for people who contribute new ideas, experiencing a dynamic and growng environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as Data Architect We are actively searching for a highly competent Data Architect who is strong in Design and Architecting solution for Industrial 4.0 and AWS IOT Cloud and Digital transformation and Integration of ERP SAP and other systems providing solution for On-Prem and Cloud solutions for data transformation, modelling, processing, etc. Required Skills · Must have proven experience of successfully managing complex data solutions using AWS. · Extensive experience in architecting, designing, and implementing the data flow from on- premises application into an AWS Data Lake, S3 and SQL Server, Snowflake database. · Should have strong analytical skills in understanding the un-structured data, raw data, meta data, real-time and event data processing from cloud to cloud and from external systems to AWS cloud or any data platforms and Intelligence infrastructure integration. · Ability to create clear and detailed technical diagrams and documentation, Deep understanding of AWS cost model(s) and cost-conscious design principles, security, performance, availability zones, disaster recovery plans. · Hands on expertise in Data ingestion, integration and ETL architecture, creating data models, contextualization, aggregation, normalizing and processing the data at IoT Edge and IoT Cloud. · Design New Solutions, collaborate with data and engineering architects and development teams to design and build cutting edge AWS data ingestion, enrichment, and accessibility capabilities. · Cost Effective Engineering, engage with key business stakeholders and technical staff to appropriately understand and recommend solutions that balance AWS costs against the resulting technical benefits. · Should have good understanding of ERP systems DB2, SAP ECC, PLC, Sensor, OPC UA data for collecting the data of various data formats and convert into proper JSON, XML structures. · Good to have experience reading excel files data and converting into to data model and storing them in S3. Data engineering on batch job and identifying job or schedule or dependencies. · Should have worked on open source, enterprise collaboration, microservices, serverless, , database management in the cloud, management tools, IoT devices experience in the cloud, experience with private and public cloud architectures, migration considerations. · Data processing using AWS services, VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, Kinesis, Kafka, Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Cloudtrail, CloudWatch, Docker, Lambda, Spark, Glue, Sage Maker, AI/ML, API GW. · Should be able to work on high loads, manage storage, join data across one or more databases in the cluster and use serverless architecture and get insights from data quickly and consistently provide high performance and scalable solution · Involves in choosing appropriate database systems, optimizing data schemas, and ensuring and integrity, handle huge data volumes and ensure fault tolerance. 1. Qualification - Bachelor's degree in information technology or equivalent 2. Experience - 12 – 16 yrs. 3. Demand requires Travel?: No Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture make us stronger! Join us now! #BeCognizant #IntuitionEngineered Employee Status : Full Time Employee Shift : Day Job Travel : No Job Posting : Apr 09 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant."
Project Architect - Data Centers,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18165122,"Descripción
We are currently seeking a highly experienced Project Architect for Data Centres to collaborate with the entire studio and lead teams to develop design solutions and coordinate through all phases of a project. Leverage your industry expertise, design abilities, and technical acumen to drive projects from concept through construction.? You are a seasoned Architect and recognized contributor to high-profile, design driven projects. Our team is highly creative, collaborative, and dedicated to innovative problem solving and design excellence. You demonstrate innovative thinking, balanced with ability to present real-world technical solutions to new design challenges. You thrive with personal responsibility and accountability but embody and embrace open communication and team-oriented success. You will work closely with the entire team, within our collaborative and supportive team environment to develop projects from conceptual design through execution. A well-rounded and thoughtful approach to design forms the foundation of our practice and our clients hire us because they?believe in the transformative?power of design. What You Will Do Manage the design and delivery for a range of project types in a variety of settings, including high-rise, commercial-office building led, or mixed-use. Lead project meetings and presentations; ensure client is adequately briefed on project progress. Develop a comprehensive understanding of clients' program requirements and standards and policies for completion to share with your project teams. Lead the communication between the project team, clients, contractors and consultants. Actively lead a range of project team sizes for successful delivery. Assist in establishing overall project budgets and milestone schedules in coordination with Design Manager and Design Director. Ensure all work is carried out to the requirements of the client, with the design team working to the correct specifications and delivering a high quality and timely product to the client. Anticipate and resolve complex technical and design issues as they arise during document preparation and construction administration. Collaborate with design team, clients, consultants, contractors, fabricators, regulatory agencies and other vendors to meet overall project objectives. Provide design and technical guidance and innovative solutions to resolve design and technical challenges. Lead more junior members of staff: motivate and ensure quality of work; ensure clear communication; understand the skills of the team and wider resources within the office. Be an advocate for Gensler sustainability commitments internally and externally. Make sustainability an integral part of every project. Define project sustainability targets in collaboration with the client and the project team at the start of each project. Understand clients ESG goals and work with project teams towards achieving them. Support and encourage team members to pursue sustainability learning. Involvement in office, regional and sector business development initiatives. Contribute to office activities, initiatives, and learning programs. Your Qualifications Bachelor of Architecture, Interior Architecture, or foreign equivalent 6+ years of project experience in an architectural practice with experience in several practice areas. Extensive portfolio of work, preferably in Data Centers, but also across various practice areas. Demonstrable experience in large projects with complex stakeholders. Ability to maintain and nurture existing client relationships and build new ones. Proficiency in REVIT, Sketch Up, and construction administration softwares. 100% bilingual English/Spanish, well written, with excellent verbal communication skills. Working knowledge of national and international building codes, standards, building construction, and building structures Mid-scale to large construction experience Experience with the entire project lifecycle, through post-occupancy Strong leadership, communication, and relationship management skills Construction documentation and/or design detail development experience Ability to handle difficult situations with tact, grace, and emotional intelligence. Experience leading, managing, and mentoring multiple project teams. Proven fiscal accountability and responsibility on various project types. Must be able to maintain existing client relationships and build new client relationships. Excellent analytical and problem-solving skills Strong organizational skills Life at Gensler At Gensler, we are as committed to enjoying life as we are to delivering best-in-class design. From curated art exhibits to internal design competitions to “Well-being Week,” our offices reflect our people's diverse interests. As part of the firm's commitment to licensure and professional development, Gensler offers reimbursement for certain professional licenses and associated renewals and exam fees. In addition, we reimburse tuition for certain eligible programs or classes. We view our professional development programs as strategic investments in our future."
Associate Architect - Azure Data,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18295976,"Descripción
We build breakthrough software products that power digital businesses. We are an innovative product development partner whose solutions drive rapid revenue, market share, and customer growth for industry leaders in Software and SaaS, Media and publishing, information services, and retail. Our key differentiator is our product mindset. Our development teams focus on building outcomes, and all of our team members around the globe are trained on the product mindset's core values: – time to Value, Solve For Need, and Excel at Change. Our teams apply this mindset to build digital products that are customer-facing and revenue-generating. Our business-minded approach to agile development ensures that we align with client goals from the earliest conceptual stages through market launch and beyond. RESPONSIBILITIES The most competitive candidates will display a strong understanding of 3Pillar Global's objectives, strategy, and values. This individual should maintain a high awareness of industry issues and trends, particularly regarding accessibility, usability, and emerging technologies, and keep team members informed as appropriate with a view to incorporating these in future projects and staying ahead of the market. Assess current state Create a list of non-functional requirements Design new architecture Decide on tools/technologies Create migration plan Create production rollout plan Architecture roadmap. BENEFITS Vacations. According to the law from your first anniversary. Discretionary Time Off (employees are able to take time off when necessary)* 26 days of Christmas bonus Food coupons Major medical insurance Life Insurance (optional) Savings box (optional) Law benefits: IMSS, Afore, Infonavit. Career plan that will let you grow and plan for the future Home Office Internal Trainings Support with external trainings and certifications Referrals bonus #Li-remote"
Pre-sales Architect Data and AI,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18295893,"Descripción
Success at SoftwareOne is not defined by what you do for yourself, but by what you deliver for our customers, the business and for the employees around you. SoftwareOne employees are energized, agile and are laser focused on delivering world class Customer Satisfaction and results. Our leaders motivate and inspire their teams and provide a working environment that delivers incredible levels of Employee Satisfaction. We are Humble. Our leaders operate with a high level of Discipline but can work at Speed manage change in a global economy. We are a leading global provider of end-to-end software and cloud technology solutions, headquartered in Switzerland. Our 8,700 employees support our approximately 65,000 customers in their digital transformation. The role Join our Services Delivery team! We look forward to learning more about you and exploring how, working together, we can build an exceptional team. Solution Architect Data & AIFull Time | Location: Mexico City | Hybrid Model What will your day-to-day look like? Collaborate with stakeholders to understand business objectives and requirements, and translate them into data and AI solution designs. Design and architect end-to-end data pipelines, including data ingestion, storage, processing, and visualization components. Develop and implement machine learning models and algorithms to extract insights and drive decision-making. Work closely with data engineers and data scientists to ensure the reliability, scalability, and performance of data and AI solutions. Evaluate and recommend appropriate technologies, tools, and frameworks to support data and AI initiatives. Provide technical guidance and mentorship to team members on data architecture and AI best practices. Collaborate with cross-functional teams, including software developers, business analysts, and project managers, to ensure successful delivery of data and AI projects. Stay updated on the latest trends and advancements in data science, machine learning, and artificial intelligence, and assess their potential impact on our solutions and services. Communicate effectively with stakeholders, including presenting technical concepts and solution designs to non-technical audiences. What we need to see from you The skills below will make you successful at this job, but we DO NOT expect to find all of them in every candidate. What do we expect from you? Bachelor's degree in Computer Science, Data Science, or related field. 5+ years of demonstrated experience in designing and implementing Data and AI solutions. Deep understanding of data architecture, data management, data integration, and AI technologies. Proficiency in developing scalable and efficient solutions leveraging data analytics, machine learning, and artificial intelligence. Ability to translate business requirements into robust data-driven and AI-powered solutions. Advanced English proficiency. Behavioral Skills: Excellent communication skills with the ability to convey complex technical concepts to non-technical stakeholders. Adaptability to evolving technologies and business needs. Strong teamwork skills to collaborate effectively with cross-functional teams. Leadership capabilities to guide and mentor team members in data and AI initiatives. Desirable Qualifications: Relevant certifications in Data Science, Machine Learning, or Artificial Intelligence. Experience with cloud-based data platforms such as AWS, Azure, or Google Cloud. Advanced knowledge of programming languages such as Python or R. Experience with big data technologies like Hadoop, Spark, or Kafka. __________________________________________________________________________________________________________________________________ Why should you join our team? Experience a unique corporate culture where values are upheld to foster an inclusive and supportive work environment. Participate in employee recognition programs to celebrate achievements and contributions. Access a wide range of training and development opportunities to enhance your skills and expertise. Enjoy a healthy work-life balance with flexible working arrangements. Benefit from our referral bonus program and other employee perks. Engage in multicultural interactions within a diverse team. Contribute to meaningful initiatives that leverage data and AI for societal impact. Participate in corporate events and access the latest technologies to drive innovation. Join a collaborative environment where your ideas and expertise are valued, and career growth is encouraged. At SoftwareOne, we are committed to promoting equal employment opportunities for all individuals, regardless of race, color, religion, gender, sexual orientation, gender identity, age, national origin, disability, or any other characteristic protected by applicable laws. Job Function Software & Cloud Services"
¿Eres nuevo? Regístrate,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18324716,"Descripción
Publicado hoy. ¡En Lumina Software tenemos una oportunidad laboral para ti! Envíanos tu CV actualizado y te contactaremos de inmediato. Perfil: Arquitecto de Datos Requerido: • 3+ años de experiencia como arquitecto/integrador de datos, diseñando e implementando arquitecturas de datos escalables y de alto rendimiento. • 7+ años de experiencia en el uso de herramientas de Integración de Datos. • Amplia experiencia orquestando y gestionando flujos de datos en entornos de nube y on-premise. • Amplia experiencia en la creación de pipelines, su configuración y optimización, integrando APIs, WebServices y Bases de datos. • 3+ años de experiencia con Azure Data Factory, Azure Synapse, Azure Data Lake, SQL Server. • Habilidad para conectar las necesidades del negocio con los requerimientos de información. Deseable: • Experiencia con Azure Analysis Services."
Senior Technical Lead,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18246509,"Descripción
Senior Technical Lead District of Col 9-11 Years USA Job Family Development Job Description (Posting). Skills : Data Architect Key Technology : ADF, Databricks, dbt, Azure Cloud Services Supporting Technology : MS SQL Server ADW/DB, Python, Pyspark, Devops Proven development experience in building complex data pipeline for lakehouse/data warehouses using Agile methodology Experience : 8-10 years Qualification B-Tech No. of Positions 1 Skill (Primary) Data Fabric-Azure-Azure Databricks Employee Group Business Supp FT City District of Columbia Entity CSW Auto req ID 1388066BR Expected Date of Closure 27-May-2024"
Regional Engagement Lead - R&D Technical Centers,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18272452,"Descripción
You provide software and application knowledge to support implementation of the given solutions. How you will contribute You will ensure that delivered services are optimized to meet business demands and the service operations strategy, plan, measure, report and communicate service improvement initiatives, and serve as a consultant on issues and resolutions. You will also recommend actions that can be taken to optimize investments and benefits and to mitigate risks. This role will require you to identify suppliers, evaluate them, on-board new vendors, establish and run vendor governance; collaborate with management and follow-up on requisitions, purchase orders, invoices, and payments; work with project resources to provide design collateral and to configure software components so they are aligned with security policy and governance; and ensure adherence to development and configuration standards and processes. What you will bring A desire to drive your future and accelerate your career. You will bring experience and knowledge in: Working collaboratively with multiple vendors Leading complex projects - project management Stakeholder management and influencing skills Managing infrastructure services delivery, support and excellence Working in global IT function with regional or global responsibilities in an environment like Mondelez International Working with IT outsourcing providers using frameworks such as the IT Infrastructure Library Working with internal and external teams and leading when necessary More about this role Will collaborate with global and regional teams to optimize & integrate data & applications across Mondelez R&D Technical Centers, translating business needs into functional, technical, and data requirements. You will then work with various internal and external partners to implement various strategic initiatives, and manage the applications, infrastructure, and data that resides within the R&D technical centers. What you need to know about this position: Understand the business process areas within the Research & Development (R&D) function, including the business needs and challenges within existing solutions. Work with various stakeholders across R&D and the Mondelez Digital Services (MDS) architects to understand R&D's existing infrastructure and data landscape. Translate R&D's business needs into technical solutions that delivers business value to the function and support the business' connectivity requirements. Work with R&D's Data architect to align initiatives with the R&D data architecture landscape in alignment with business goals. Collaborate with the business to own the prioritization of developments and identify vendors to perform such improvements. Partner internally across various IT groups & externally (e.g., Vendors, Architects or Application Development Factory) to lead the delivery of such solutions. Collaborate with MDS teams to integrate infrastructure, networking, and data components seamlessly into R&D applications. Support various R&D digital & data strategic initiatives and incorporate related data where needed into R&D models and solutions. Work with Mondelez Enterprise Architects to maintain the organization's technical infrastructure architecture, ensuring applications are supported. Manage a portfolio of IT solutions used by the R&D Technical Centers, including the application lifecycle, ongoing cost ownership, and roadmap of future solutions in this space. What extra ingredients you will bring: Degree in IT/IS Computer Science or equivalent. Education / Certifications: Degree in IT/IS Computer Science or equivalent. Job specific requirements: Technical, infrastructure, and data skills and business acumen to support the development of technology and capability changes. IT solution, integration, and data architecture Knowledge of systems and business processes Influencing others based on earned respect and experience. Analytical and problem-solving abilities learning agility, proactive Managing multi-country stakeholders Knowledge of R&D or pre-manufacturing processes and/or applications is a plus. Knowledge of Data & Analytics or Modelling & Simulation solutions is a plus. Travel: 10-25% to selected R&D technical center sites as needed ( United States and Brazil) Work schedule: Full time No Relocation support availableBusiness Unit Summary Mondelez México has been in the country since 1927 and currently employs 6,000 wonderful people. Our diverse portfolio includes iconic and mouth-watering global brands such as Trident, Oreo, Philadelphia, and local jewels like Clorets and Bubbaloo. We are leaders in the making of cream cheese, powdered beverages and confections—in fact, we make seven out of every 10 chewing gums consumed by Mexicans. Our growth is supported by our cutting-edge manufacturing facilities, such as our Puebla Plant and Nuevo León HUB, which are the largest gums, candies and biscuits factories in the world in terms of volume. You can buy are products in 900,000 places in Mexico. We are also home to one of the 11 technology centers Mondelez International has worldwide, a specialized gum and candy facility that places us at the forefront of innovation and development in the country and drives our purpose to lead the future of snacking. We are pioneers in the country in work-life balance practices such as extended maternity leave, open spaces, remote work and flexible working hours. Mondelez International is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation or preference, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. Job Type RegularSoftware & ApplicationsTechnology & Digital"
Business Intelligence Reporting - Lead Specialist,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=3&jobid=18382807,"Descripción
The Finance, Data Management, & Reporting Specialist Senior Business Analyst is responsible for providing business & technical analysis support in the areas of Finance, Data Management, and Reporting. The Senior (BA) Business Analyst is responsible for understanding business needs, facilitating business requirements, documenting business requirements into (BRD) Business Requirements Document, developing current and future state process diagrams, developing prototypes to facilitate/validate business requirements, documenting use-cases required to support business requirements for application development, and developing requirements traceability matrix as input for UAT. The BA will be supporting projects involving cross-offices, business practices, or functions. What is in it for you? A company with a strong Brand and strong results to match Culture of internal mobility, collaboration and valued partnership from the business. Employee Resource Groups which provide access to leaders, relevant volunteer and mentoring opportunities and interactions with counterparts in industry groups and client organizations. Entitled to vacation, floating holidays, time off to give back to your community, sick days, and national holidays (with early dismissal). We will count on you to: Conduct and facilitate business requirement workshops & process walkthrough, with the business stakeholders, and obtain sign-off. Translate business strategies and objectives into business requirements; provide traceability of business requirements to IT Solutions and ensure system testing encompasses existing capabilities of solution as well as future function point requirements. Identify, verify and document functional requirements using requirements management methodology and tools. In addition clearly identify data elements and provide data mappings/dictionaries where required. Analyze, design/redesign, and document as is and to be business processes. Conduct/facilitate final acceptance tests for solutions with the user community. This will include the development of UAT test scenarios and test scripts as required. Develop, deliver, and evaluate training materials; supplement materials when necessary. Conduct systems requirement walk-through with the development & (QA) Quality Assurance teams to ensure clear and complete understanding of the requirements. Provide testing guidance to the QA team, review their quality assurance testing plan & results, and facilitate & support the UAT (User Acceptance Testing) with the business users. Responsible for conducting and analyzing feasibility studies/impact assessments regarding implementation of IT solutions against current state parameters (process, application use-cases, non-functional impact, etc.). Partner with Business and IT to define and manage scope with each release Monitors and controls the production, distribution and maintenance of Management Information and Business Intelligence Analyze reporting specifications and develops/delivers reporting solutions on time and with minimal defects Provides scheduled and special ad-hoc reports Prepares documentation for report specifications or Quality Assurance testing. Provides training to other unit employees on advanced and complex reporting concepts, as needed. Develops complex and customized reports, both on a proactive basis to address client needs as well as in response to user requests. Works in conjunction with data architect & project design team on new and innovative reporting solutions and, as requested, perform business analysis and troubleshooting tasks. What you need to have: . 3+ years of experience in analyzing business problems and designing successful solutions Bachelor's degree Strong Business Process Analysis and documentation skills Ability to elicit and document business requirements In depth technical experience in Oracle database development, Data modelling, Performance tuning , Schema Design and data warehousing, Extract/Transform/Load (ETL) . Capable of initiating business process review sessions in order to optimize an overall outcome both business and technical driven Ability to work with databases and other BI software products to manipulate and transform data that can be used for analysis and decision making. Proficiencies with utilities such as Import, Export , SQL* Loader, External tables, Advanced queuing and Materialized Views. concurrent programs using SQL, PL SQL and UNIX shell scripting. Operated on Informatica Power Center tool - Source Analyzer, Data warehousing designer, Mapping & Mapplet Designer and Transformation Designer. Proficient in implementing projects using Agile and waterfall methodologies. Involvement in Offshore and Onsite model Tools: PL/SQL Developer, SQL Developer, TOAD, SQL advantage , Informatica power Centre Tool, Oracle Forms Programming Languages: Oracle SQL, PL/SQL, Informatica, UNIX Shell Scripting, Fame Time Series and Vector Processing Reporting Tools: Proficiency in Business Object, Qlik, Tableau Web Applications : JAVA, CSS, XML, and HTML, Oracle APEX(front-end) Version Control: VSS, SVN, Clear Case Can effectively participate/lead requirements gathering and review sessions comprised of both IT and business representatives. Ability to articulate Business Requirements to both on shore and off shore development teams. Ability to articulate technical concepts, and design to business users Experience of the complete SDLC Ability to partner with IT and the business teams to management scope of the requirements. Strong track record in collaborating across the organization. Strong (clear and concise) communication skills Good interpersonal skills adequate for dealing and communicating clearly with people from all levels of the organization, and with external customers and suppliers Excellent oral and written skills adequate for documenting complex business requirements clearly and unambiguously What makes you stand out Strong knowledge & experience in the insurance industry Fluency in written & spoken English, French Professional BA certification, either CBAP (Certified Business Analysis Professional) or CCBA (Certification of Competency in Business Analysis), If you are interested, please send your CV in English. Interviews will be hold in English. Marsh McLennan (NYSE: MMC) is the world's leading professional services firm in the areas of risk, strategy and people. The Company's 85,000 colleagues advise clients in 130 countries. With annual revenue of over $20 billion, Marsh McLennan helps clients navigate an increasingly dynamic and complex environment through four market-leading businesses. Marsh provides data-driven risk advisory services and insurance solutions to commercial and consumer clients. Guy Carpenter develops advanced risk, reinsurance and capital strategies that help clients grow profitably and pursue emerging opportunities. Mercer delivers advice and technology-driven solutions that help organizations redefine the world of work, reshape retirement and investment outcomes, and unlock health and well being for a changing workforce. Oliver Wyman s serves as a critical strategic, economic and brand advisor to private sector and governmental clients. For more information, visit marshmclennan.com, or follow us on LinkedIn and Twitter. Marsh McLennan is committed to creating a diverse, inclusive and flexible work environment. We aim to attract and retain the best people and embrace diversity of age, background, disability, ethnic origin, family duties, gender orientation or expression, marital status, nationality, parental status, personal or social status, political affiliation, race, religion and beliefs, sex/gender, sexual orientation or expression, skin color, or any other characteristic protected by applicable law. Marsh McLennan is committed to hybrid work, which includes the flexibility of working remotely and the collaboration, connections and professional development benefits of working together in the office. All Marsh McLennan colleagues are expected to be in their local based teams will identify at least one “anchor day” per week on which their full team will be together in person. office or working onsite with clients at least three days per week. Office-based teams will identify at least one “anchor day” per week on which their full team will be together in person."
Senior Emerging Technology Engineer,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18356722,"Descripción
Join AstraZeneca as a Senior Emerging Technology Engineer, where you'll be at the epicentre of innovation in a role that's anything but routine. We're looking for someone who thrives in an ever-changing environment, eager to master the latest tech trends and drive the adoption of cutting-edge technologies. In this role, you'll bring emerging technologies to life, crafting captivating experiences and presentations to illuminate their potential for our strategic leaders in hands on immersive experiences. Your mission will be to not only identify and test the next big technologies within a 3-5 year horizon, but also to pave the way for their integration into AstraZeneca's future landscape. You'll be at the forefront of a 'show, don't just tell' philosophy, requiring a hands-on approach as you create Proof of Concept projects and collaborate with a diverse network of partners, from academic institutions to tech titans. You'll lean in as needed to deliver, using your own passion for learning as a driver. This role does not come with an instruction manual, you will be shaping and defining that for the rest of the organisation. This gives you a unique vantage point, accessing revolutionary technologies ahead of the curve. More than a creator of prototypes, you'll deliver thought leadership by translating intricate tech concepts into strategic insights, shaping the direction of our investments. When new technologies emerge, you'll be the architect of the capabilities needed to harness their power for our business. We're seeking a curious, tech-savvy professionals with the skills to build proofs of concepts and the boldness to tackle the unknown. If you're ready to dive into a world of exploration and have a direct impact on AstraZeneca's technological journey, step into a role that's as exciting as it is vital. What you will be doing Thought Leadership: Deliver thought-provoking and informative guidance on new and emerging technologies through immersive demonstrations and workshops. Enrich the research arm of the team with your technical expertise, contributing to the development of positioning statements and white papers. Trailblaze New Technologies: Innovate and construct bespoke Proof-of-Concept systems to illustrate the art of the possible. Influence senior strategic leaders with hands-on experiences that go beyond third-party narratives, demonstrating the value proposition of technologies from a foundation of first-hand knowledge. Embrace experimentation, understanding that learning from failed PoCs is an essential step towards success. Labs and Infrastructure Management: Take charge of the Tech Innovation infrastructure, including cloud accounts, sandboxes, source control, license servers, and more. Champion the opportunities that arise from the labs while ensuring the physical lab space and equipment are available, well-maintained, and secure. Strategic Translation: In close collaboration with research colleagues, partner with Business Technology Groups (BTGs) and Enterprise Architects to assess how new technologies can be woven into existing workflows. Where there is no existing capability, you will assist in paving the way for its creation. Technical Expertise: As the Senior Emerging Technology Engineer at AstraZeneca, you will be the bedrock of expertise for new and emerging technological trends. Strategic leaders will depend on your insights and comprehensive understanding of cutting-edge technologies to navigate critical business decisions. You will be tasked with keeping abreast of the latest tech developments and proactively engaging with strategic leaders to ensure technology adoption aligns with business objectives. Skills and competencies Software Engineering Expertise: Proficiency in architecting and programming Proof of Concept (PoC) projects is essential, utilising both familiar tech stacks and exploring new frameworks and libraries that might better mesh with new technologies. The role demands the ability to work independently as well as collaboratively within larger teams. Strategic Storytelling: Storytelling skills are crucial for effectively translating complex technical concepts and visionary ideas into simple, impactful narratives that resonate with senior executives. Influence & Collaboration: Ability to work with external partners to influence outcomes and deliver timely product innovations. The capacity to articulate intricate technical details in a clear manner that is easily understandable by senior strategic leaders as well as your colleagues in teams like Enterprise Architecture. Agility in Ambiguity: The ability to navigate ambiguity, prioritise a demanding workload, and thrive in a dynamic environment. Innovation Enthusiasm: A fervent desire to stay informed about the latest trends and developments in the innovation landscape. A genuine eagerness to engage directly with technologies, coupled with the drive and ability to rapidly learn new skills. Proven Implementation Track Record: Validated experience in delivering and deploying solutions within Continuous Development lifecycles. Curiosity & Initiative: An inquisitive mindset with a proactive approach where you are comfortable being uncomfortable. A willingness to take on new challenges and experiment in areas where you lack experience. Experience and Qualifications We understand that innovation, particularly with emerging technologies, doesn't come from a one-size-fits-all approach. The role of an Emerging Technology Engineer is multifaceted and ever-evolving. While we value technical acumen, we place a greater emphasis on finding the right candidate with a proactive, problem-solving attitude and a willingness to learn and adapt. We encourage applications from those who may not tick every box but are passionate about technology and its potential to drive change.  Programming Proficiency: Strong programming skills with experience with multiple languages including but not limited to C#, Python, and JavaScript. Exposure to additional languages such as C++, Java, Go, Rust, etc., is advantageous. This is a hands-on role and you will be expected to be able to build solutions. Cloud Expertise: Proven knowledge or experience with cloud computing and services such as AWS, GCP, or Azure. Database Experience: Experience with various databases, both relational and NoSQL, as well as newer technologies such as graph databases. Emerging technology exposure: Exposure to or experience in areas such as data science, real-time 3D, AR/VR/XR, computer vision, AI, robotics, quantum computing, etc. Project Experience: Proof of independent project development as well as collaborative team efforts, with a good understanding of source control and project management methodologies. Educational Background: A degree in software engineering, computer science OR equivalent years of relevant professional experience. Certification: AWS Associate or Professional certifications (Architect, Developer) or equivalent GCP/Azure certifications are desirable. Why AstraZeneca? At AstraZeneca when we see an opportunity for change, we seize it and make it happen, because any opportunity no matter how small, can be the start of something big. Delivering life-changing medicines is about being entrepreneurial - finding those moments and recognising their potential. Join us on our journey of building a new kind of organisation to reset expectations of what a bio-pharmaceutical company can be. This means we're opening new ways to work, pioneering cutting edge methods and bringing unexpected teams together. So, what's next! Are you already imagining yourself joining our team? Good, because we can't wait to hear from you. Where can I find out more? Follow AstraZeneca on LinkedIn https://www.linkedin.com/company/1603/ Follow AstraZeneca on Facebook https://www.facebook.com/astrazenecacareers/ Follow AstraZeneca on Instagram https://www.instagram.com/astrazeneca_careers/?hl=en AstraZeneca is an equal opportunity employer. AstraZeneca will consider all qualified applicants for employment without discrimination on grounds of disability, sex or sexual orientation, pregnancy or maternity leave status, race or national or ethnic origin, age, religion or belief, gender identity or re-assignment, marital or civil partnership status, protected veteran status (if applicable) or any other characteristic protected by law. AstraZeneca only employs individuals with the right to work in the country/ies where the role is advertised. Strong English communication skills required. Positions are open to Mexican Citizens and official residents of Mexico. Location: Guadalajara (hybrid - Expectation of working in the office 3 days a week) When we put unexpected teams in the same room, we unleash bold thinking with the power to inspire life-changing medicines. In-person working give us the platform we need to connect, work at pace and challenge perceptions. That's why we work, on average, a minimum of three days per week from the office. But that doesn't mean we're not flexible. We balance the expectation of being in the office while respecting individual flexibility. AstraZeneca embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements."
DnA Consulting - Data Engineer - Senior - EY Global Delivery Services,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18382529,"Descripción
As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. The opportunity We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. Your key responsibilities • Design and Develop batch and streaming data processing • Build data systems and pipelines. • Evaluate business needs and objectives. • Prepare data for prescriptive and predictive modeling. • Build algorithms and prototypes. • Combine raw information from different sources. • Explore ways to enhance data quality and reliability. • Identify opportunities for data acquisition. • Monitor and optimize data storage and data processing • Design and implement data security Skills and attributes for success • 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub • 3-5 years of experience on processing real time data. • Advanced knowledge on processing large amounts of data (billions of records) in minutes. • Deep knowledge on producers (ACK/NACK), consumers, and brokers. • Deep knowledge on topics, partitions, and segments. • 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. • Advanced knowledge on data structures, MPP Databases, Blob Storage. • 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud. • Previous experience as a data engineer or in a similar role. • Data engineering certification (AZURE Certified Data Engineer) is a plus. • Flexible and adaptable; able to work in ambiguous situations. • Able to work effectively at all levels in an organization. • Must be a team player and able to work collaboratively with and through others. • Must like to learn. To qualify for the role, you must have • Bachelor's in technology or engineering or similar. • Experience working with Azure, Snowflake technologies. Ideally, you'll also have • Familiarity with agile methodologies. • Familiarity with software such as Jira or ADO. What we look for • A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment • Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries What working at EY offers At EY, we're dedicated to helping our clients, from world's top companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: • Support, coaching and feedback from some of the most engaging colleagues around • Opportunities to develop new skills and progress your career • The freedom and flexibility to handle your role in a way that's right for you About EY As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make our ambition to be the best employer by 2020 a reality. If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now"
DnA Consulting - Data Engineer - Senior - EY Global Delivery Services,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18382341,"Descripción
As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. The opportunity We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. Your key responsibilities • Design and Develop batch and streaming data processing • Build data systems and pipelines. • Evaluate business needs and objectives. • Prepare data for prescriptive and predictive modeling. • Build algorithms and prototypes. • Combine raw information from different sources. • Explore ways to enhance data quality and reliability. • Identify opportunities for data acquisition. • Monitor and optimize data storage and data processing • Design and implement data security Skills and attributes for success • 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub • 3-5 years of experience on processing real time data. • Advanced knowledge on processing large amounts of data (billions of records) in minutes. • Deep knowledge on producers (ACK/NACK), consumers, and brokers. • Deep knowledge on topics, partitions, and segments. • 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. • Advanced knowledge on data structures, MPP Databases, Blob Storage. • 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud. • Previous experience as a data engineer or in a similar role. • Data engineering certification (AZURE Certified Data Engineer) is a plus. • Flexible and adaptable; able to work in ambiguous situations. • Able to work effectively at all levels in an organization. • Must be a team player and able to work collaboratively with and through others. • Must like to learn. To qualify for the role, you must have • Bachelor's in technology or engineering or similar. • Experience working with Azure, Snowflake technologies. Ideally, you'll also have • Familiarity with agile methodologies. • Familiarity with software such as Jira or ADO. What we look for • A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment • Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries What working at EY offers At EY, we're dedicated to helping our clients, from world's top companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: • Support, coaching and feedback from some of the most engaging colleagues around • Opportunities to develop new skills and progress your career • The freedom and flexibility to handle your role in a way that's right for you About EY As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make our ambition to be the best employer by 2020 a reality. If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now"
Data Modeler,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18366810,"Descripción
At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place to Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Data Modeler What you'll do:  • Demonstrate ability to write new code i.e., well-documented and stored in a version control system (we use GitHub & Bitbucket) • Good to have experience with Cloud Platforms such as AWS, Azure, GCP and Snowflake • Good to have strong programming/ scripting skills (Python, PowerShell, etc.) • Good to know about developing financial models and forecasting to support financial planning and decision-making processes. • Experience around responsibility for analyzing and interpreting financial data to provide valuable insights and support strategic decision-making. • Collaborating with product owners to identify requirements, define desired outcomes and deliver trusted results. • Building processes supporting data transformation, data structures, metadata, dependency and workload management. • In this role, SQL is heavily focused. An ideal candidate must have hands-on experience with SQL database design. Plus, Python. • Demonstrably deep understanding of SQL (level: advanced) and analytical data warehouses (Snowflake preferred). • Demonstrated ability to write new code i.e., well-documented and stored in a version control system (we use GitHub & Bitbucket) • Familiar with JIRA & Confluence. • Must have exposure to technologies such as dbt, Apache airflow and Snowflake. • Desire to continually keep up with advancements in data engineering practices. • Knowledge on AWS cloud, Python is a plus."" Minimum Qualifications: • 5+ years of IT experience with major focus on data warehouse/database related projects • As user, must have exposure to technologies such as dbt, Apache Airflow, Snowflake (para hacer dashboards). • Experience in data platforms: Snowflake, Oracle, SQL Server, MDM etc • Expertise in writing SQL and database objects - Stored procedures, functions, views. Hands on experience in ETL/ELT and data security, SQL performance optimization and job orchestration tools and technologies e.g., dbt, Attunity, Golden Gate, APIs, Apache Airflow, etc. • Experience in data modeling and relational database design Experience working with agile methodologies (Scrum, Kanban) and Meta Scrum with cross-functional teams (Product Owners, Scrum Master, Architects, and data SMEs) • Well-versed in applying SCD, CDC, and DQ/DV framework – NICE TO HAVE. Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture makes us stronger! Join us now! #BeCognizant #IntuitionEngineered Employee Status : Full Time Employee Shift : Day Job Travel : No Job Posting : Apr 08 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant."
Data Engineer Sr,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18322362,"Descripción
Chubb is the world's largest publicly traded P&C insurance company and a leading commercial lines insurer in the United States. With operations in 54 countries and territories, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance, and life insurance to a diverse group of clients. As an underwriting company, we assess, assume, and manage risk with insight and discipline. We service and pay our claims fairly and promptly. We combine the precision of craftsmanship with decades of experience to conceive, craft and deliver the very best insurance coverage and service to individuals and families, and businesses of all sizes. Chubb is also defined by its extensive product and service offerings, broad distribution capabilities, direct-to-consumer platform partnerships, exceptional financial strength and local operations globally. The company serves multinational corporations, mid-size and small businesses with property and casualty insurance and risk engineering services; affluent and high net worth individuals with substantial assets to protect; individuals purchasing life, personal accident, supplemental health, homeowners, automobile and specialty personal insurance coverage; companies and affinity groups providing or offering accident and health insurance programs and life insurance to their employees or members; and insurers managing exposures with reinsurance coverage. Position Overview: We are seeking a highly skilled and experienced lead data engineer to join our dynamic team. The ideal candidate will be responsible for leading the design, development and implementation of scalable data pipelines, and ensuring the effective utilization of data in the business intelligence and decision-making. Position Summary Technical Hands-on role providing direction and thought leadership in implementation of data solutions and related downstream systems including the build of repositories, such as data warehouses, data lakes, using appropriate technologies. This role requires strong technical background, hands-on experience in Informatica IICS, Databricks Python, ADF, snowflake and other Azure technologies along with data analysis skills and leadership abilities. The candidate will work on multiple projects for delivery of data solutions, including new development, maintenance, and enhancements. The candidate will also assist with the daily operations, management, and oversight of team's deliverables. Primary Responsibilities: The candidate will be responsible for design, and implement new solutions for complex data ingestions from multiple sources to enterprise data products with focus on automation, performance, resilience, and scalability, etc. Partner with Lead Architect, Data Product Manager (Product Owner) and Lead Data Integration Engineer to create strategic solutions introducing new technologies. Work with stakeholders including Management, Domain leads, and Teams to assist with data-related technical issues and support their data infrastructure needs. Strong development and programming experience in database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines. Experience in Informatica (IICS), Python, ADF, Azure Synapse, snowflake, Cosmos and Databricks Solid understanding of databases, real-time integration patterns and ETL/ELT best practices. From database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines Defining data retention policies, monitoring performance and advising any necessary infrastructure changes based on functional and non-functional requirements. Responsible for ensuring enterprise data policies, best practices, standards and processes are followed. Write up and maintain technical specifications, design documents and process flow. Mentor a team of onshore and offshore development resources to analyze, design, construct and test software development projects focused on analytics and data integration. Elaborate user stories for technical team and ensure that the team understands the deliverables. Effectively communicate, coordinate & collaborate with business, IT architecture and data teams across multi-functional areas to complete deliverables. Provide direction to the Agile development team and stakeholders throughout the project. Assist in Data Architecture design, tool selection and data flows analysis. Work with large amounts of data, interpret data, analyze results, perform gap analysis and provide ongoing reports. Handle ad-hoc analysis & report generation requests from the business. Respond to data related inquiries to support business and technical teams. Technical Skills / Experience: 7+years of proven working experience in ETL methodologies, Data integration and data migration. Informatica IICS, Databricks/Spark & Python hands-on development skills a must. Clear hands-on experience with database systems - SQL server, Oracle, Azure Synapse, Snowflake and Cosmos, Cloud technologies (e.g., AWS, Azure, Google), and NoSQL databases (e.g., Cosmos, MongoDB, DynamoDB) Skilled in backend technologies (Python, Java, Scala) & Front-end development (JavaScript, React, Angular). Extensive experience developing complex solutions focused on data ecosystem solutions. Extensive knowledge of data and analytics framework supporting data lakes, warehouses, marts, reporting, etc. In depth knowledge of data engineering and architecture disciplines Extensive experience working with Big Data tools and building data solutions for advanced analytics and Machine learning frameworks. Solid understanding of P&C Insurance data Technical expertise regarding data architecture, models and database design development Strong knowledge of and experience with Java, SQL, XML's, Python, ETL frameworks and Databricks Working knowledge/familiarity with Git version control. Strong Knowledge of analyzing datasets using Excel Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Proficient in learning new technologies with the ability to quickly understand capabilities and work with others to guide these into development. Good communication and presentation skills Solid problem solving, decision making and analytical skills. Knowledge & working experience with Duck creek is an added plus. Knowledge & working experience with Insurity Policy Decisions and/or IEV is an added plus. Experience with JIRA Other Skills / Experience: Experience being part of high-performance agile teams in a fast-paced environment. Must understand the system scope and project objectives to achieve project needs through matrix management and collaboration with other enterprise teams. Proven ability to produce results in the analysis, design, testing and deployment of applications. Strong team emphasis and relationship building skills; partners well with business and other IT/Data areas. Strong coaching / mentoring skills Applies technical knowledge to determine solutions and solve complex problems. Ability to be proactive, self-motivated, detail-oriented, creative, inquisitive, and persistent. Excellent communication and negotiation skills. Ability to organize, plan and implement work assignments, juggle competing demands and work under pressure of frequent and tight deadlines."
Sr. Data Engineer,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18322308,"Descripción
Chubb is the world's largest publicly traded P&C insurance company and a leading commercial lines insurer in the United States. With operations in 54 countries and territories, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance, and life insurance to a diverse group of clients. As an underwriting company, we assess, assume, and manage risk with insight and discipline. We service and pay our claims fairly and promptly. We combine the precision of craftsmanship with decades of experience to conceive, craft and deliver the very best insurance coverage and service to individuals and families, and businesses of all sizes. Chubb is also defined by its extensive product and service offerings, broad distribution capabilities, direct-to-consumer platform partnerships, exceptional financial strength and local operations globally. The company serves multinational corporations, mid-size and small businesses with property and casualty insurance and risk engineering services; affluent and high net worth individuals with substantial assets to protect; individuals purchasing life, personal accident, supplemental health, homeowners, automobile and specialty personal insurance coverage; companies and affinity groups providing or offering accident and health insurance programs and life insurance to their employees or members; and insurers managing exposures with reinsurance coverage. Position Overview: We are seeking a highly skilled and experienced lead data engineer to join our dynamic team. The ideal candidate will be responsible for leading the design, development and implementation of scalable data pipelines, and ensuring the effective utilization of data in the business intelligence and decision-making. Position Summary Technical Hands-on role providing direction and thought leadership in implementation of data solutions and related downstream systems including the build of repositories, such as data warehouses, data lakes, using appropriate technologies. This role requires strong technical background, hands-on experience in Informatica IICS, Databricks Python, ADF, snowflake and other Azure technologies along with data analysis skills and leadership abilities. The candidate will work on multiple projects for delivery of data solutions, including new development, maintenance, and enhancements. The candidate will also assist with the daily operations, management, and oversight of team's deliverables. Primary Responsibilities: The candidate will be responsible for design, and implement new solutions for complex data ingestions from multiple sources to enterprise data products with focus on automation, performance, resilience, and scalability, etc. Partner with Lead Architect, Data Product Manager (Product Owner) and Lead Data Integration Engineer to create strategic solutions introducing new technologies. Work with stakeholders including Management, Domain leads, and Teams to assist with data-related technical issues and support their data infrastructure needs. Strong development and programming experience in database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines. Experience in Informatica (IICS), Python, ADF, Azure Synapse, snowflake, Cosmos and Databricks Solid understanding of databases, real-time integration patterns and ETL/ELT best practices. From database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines Defining data retention policies, monitoring performance and advising any necessary infrastructure changes based on functional and non-functional requirements. Responsible for ensuring enterprise data policies, best practices, standards and processes are followed. Write up and maintain technical specifications, design documents and process flow. Mentor a team of onshore and offshore development resources to analyze, design, construct and test software development projects focused on analytics and data integration. Elaborate user stories for technical team and ensure that the team understands the deliverables. Effectively communicate, coordinate & collaborate with business, IT architecture and data teams across multi-functional areas to complete deliverables. Provide direction to the Agile development team and stakeholders throughout the project. Assist in Data Architecture design, tool selection and data flows analysis. Work with large amounts of data, interpret data, analyze results, perform gap analysis and provide ongoing reports. Handle ad-hoc analysis & report generation requests from the business. Respond to data related inquiries to support business and technical teams. Technical Skills / Experience:  7+years of proven working experience in ETL methodologies, Data integration and data migration. Informatica IICS, Databricks/Spark & Python hands-on development skills a must. Clear hands-on experience with database systems - SQL server, Oracle, Azure Synapse, Snowflake and Cosmos, Cloud technologies (e.g., AWS, Azure, Google), and NoSQL databases (e.g., Cosmos, MongoDB, DynamoDB) Skilled in backend technologies (Python, Java, Scala) & Front-end development (JavaScript, React, Angular). Extensive experience developing complex solutions focused on data ecosystem solutions. Extensive knowledge of data and analytics framework supporting data lakes, warehouses, marts, reporting, etc. In depth knowledge of data engineering and architecture disciplines Extensive experience working with Big Data tools and building data solutions for advanced analytics and Machine learning frameworks. Solid understanding of P&C Insurance data Technical expertise regarding data architecture, models and database design development Strong knowledge of and experience with Java, SQL, XML's, Python, ETL frameworks and Databricks Working knowledge/familiarity with Git version control. Strong Knowledge of analyzing datasets using Excel Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Proficient in learning new technologies with the ability to quickly understand capabilities and work with others to guide these into development. Good communication and presentation skills Solid problem solving, decision making and analytical skills. Knowledge & working experience with Duck creek is an added plus. Knowledge & working experience with Insurity Policy Decisions and/or IEV is an added plus. Experience with JIRA Other Skills / Experience: Experience being part of high-performance agile teams in a fast-paced environment. Must understand the system scope and project objectives to achieve project needs through matrix management and collaboration with other enterprise teams. Proven ability to produce results in the analysis, design, testing and deployment of applications. Strong team emphasis and relationship building skills; partners well with business and other IT/Data areas. Strong coaching / mentoring skills Applies technical knowledge to determine solutions and solve complex problems. Ability to be proactive, self-motivated, detail-oriented, creative, inquisitive, and persistent. Excellent communication and negotiation skills. Ability to organize, plan and implement work assignments, juggle competing demands and work under pressure of frequent and tight deadlines."
Sr. Data Engineer,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18322080,"Descripción
Chubb is the world's largest publicly traded P&C insurance company and a leading commercial lines insurer in the United States. With operations in 54 countries and territories, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance, and life insurance to a diverse group of clients. As an underwriting company, we assess, assume, and manage risk with insight and discipline. We service and pay our claims fairly and promptly. We combine the precision of craftsmanship with decades of experience to conceive, craft and deliver the very best insurance coverage and service to individuals and families, and businesses of all sizes. Chubb is also defined by its extensive product and service offerings, broad distribution capabilities, direct-to-consumer platform partnerships, exceptional financial strength and local operations globally. The company serves multinational corporations, mid-size and small businesses with property and casualty insurance and risk engineering services; affluent and high net worth individuals with substantial assets to protect; individuals purchasing life, personal accident, supplemental health, homeowners, automobile and specialty personal insurance coverage; companies and affinity groups providing or offering accident and health insurance programs and life insurance to their employees or members; and insurers managing exposures with reinsurance coverage. Position Overview: We are seeking a highly skilled and experienced lead data engineer to join our dynamic team. The ideal candidate will be responsible for leading the design, development and implementation of scalable data pipelines, and ensuring the effective utilization of data in the business intelligence and decision-making. Position Summary Technical Hands-on role providing direction and thought leadership in implementation of data solutions and related downstream systems including the build of repositories, such as data warehouses, data lakes, using appropriate technologies. This role requires strong technical background, hands-on experience in Informatica IICS, Databricks Python, ADF, snowflake and other Azure technologies along with data analysis skills and leadership abilities. The candidate will work on multiple projects for delivery of data solutions, including new development, maintenance, and enhancements. The candidate will also assist with the daily operations, management, and oversight of team's deliverables. Primary Responsibilities: The candidate will be responsible for design, and implement new solutions for complex data ingestions from multiple sources to enterprise data products with focus on automation, performance, resilience, and scalability, etc. Partner with Lead Architect, Data Product Manager (Product Owner) and Lead Data Integration Engineer to create strategic solutions introducing new technologies. Work with stakeholders including Management, Domain leads, and Teams to assist with data-related technical issues and support their data infrastructure needs. Strong development and programming experience in database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines. Experience in Informatica (IICS), Python, ADF, Azure Synapse, snowflake, Cosmos and Databricks Solid understanding of databases, real-time integration patterns and ETL/ELT best practices. From database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines Defining data retention policies, monitoring performance and advising any necessary infrastructure changes based on functional and non-functional requirements. Responsible for ensuring enterprise data policies, best practices, standards and processes are followed. Write up and maintain technical specifications, design documents and process flow. Mentor a team of onshore and offshore development resources to analyze, design, construct and test software development projects focused on analytics and data integration. Elaborate user stories for technical team and ensure that the team understands the deliverables. Effectively communicate, coordinate & collaborate with business, IT architecture and data teams across multi-functional areas to complete deliverables. Provide direction to the Agile development team and stakeholders throughout the project. Assist in Data Architecture design, tool selection and data flows analysis. Work with large amounts of data, interpret data, analyze results, perform gap analysis and provide ongoing reports. Handle ad-hoc analysis & report generation requests from the business. Respond to data related inquiries to support business and technical teams. Technical Skills / Experience:  7+years of proven working experience in ETL methodologies, Data integration and data migration. Informatica IICS, Databricks/Spark & Python hands-on development skills a must. Clear hands-on experience with database systems - SQL server, Oracle, Azure Synapse, Snowflake and Cosmos, Cloud technologies (e.g., AWS, Azure, Google), and NoSQL databases (e.g., Cosmos, MongoDB, DynamoDB) Skilled in backend technologies (Python, Java, Scala) & Front-end development (JavaScript, React, Angular). Extensive experience developing complex solutions focused on data ecosystem solutions. Extensive knowledge of data and analytics framework supporting data lakes, warehouses, marts, reporting, etc. In depth knowledge of data engineering and architecture disciplines Extensive experience working with Big Data tools and building data solutions for advanced analytics and Machine learning frameworks. Solid understanding of P&C Insurance data Technical expertise regarding data architecture, models and database design development Strong knowledge of and experience with Java, SQL, XML's, Python, ETL frameworks and Databricks Working knowledge/familiarity with Git version control. Strong Knowledge of analyzing datasets using Excel Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Proficient in learning new technologies with the ability to quickly understand capabilities and work with others to guide these into development. Good communication and presentation skills Solid problem solving, decision making and analytical skills. Knowledge & working experience with Duck creek is an added plus. Knowledge & working experience with Insurity Policy Decisions and/or IEV is an added plus. Experience with JIRA Other Skills / Experience: Experience being part of high-performance agile teams in a fast-paced environment. Must understand the system scope and project objectives to achieve project needs through matrix management and collaboration with other enterprise teams. Proven ability to produce results in the analysis, design, testing and deployment of applications. Strong team emphasis and relationship building skills; partners well with business and other IT/Data areas. Strong coaching / mentoring skills Applies technical knowledge to determine solutions and solve complex problems. Ability to be proactive, self-motivated, detail-oriented, creative, inquisitive, and persistent. Excellent communication and negotiation skills. Ability to organize, plan and implement work assignments, juggle competing demands and work under pressure of frequent and tight deadlines."
Snowflake Data Engineer,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18301090,"Descripción
Apexon is a digital-first technology services firm specializing in accelerating business transformation and delivering human-centric digital experiences. We have been meeting customers wherever they are in the digital lifecycle and helping them outperform their competition through speed and innovation.Apexon brings together distinct core competencies – in AI, analytics, app development, cloud, commerce, CX, data, DevOps, IoT, mobile, quality engineering and UX, and our deep expertise in BFSI, healthcare, and life sciences – to help businesses capitalize on the unlimited opportunities digital offers. Our reputation is built on a comprehensive suite of engineering services, a dedication to solving clients' toughest technology problems, and a commitment to continuous improvement. Backed by Goldman Sachs Asset Management and Everstone Capital, Apexon now has a global presence of 15 offices (and 10 delivery centers) across four continents. We enable #HumanFirstDIGITAL  You'll be responsible for (Responsibilities): Snowflake data engineers will be responsible for architecting and implementing very large-scale data intelligence solutions around Snowflake Data Warehouse. A solid experience and understanding of architecting, designing and operationalization of large-scale data and analytics solutions on Snowflake Cloud Data Warehouse is a must. Need to have professional knowledge of AWS Redshift. Responsibilities • Developing ETL pipelines in and out of data warehouse using combination of Python and Snowflakes Snow SQL • Writing SQL queries against Snowflake. • Developing scripts Unix, Python etc. to do Extract, Load and Transform data Working knowledge of AWS Redshift • Provide production support for Data Warehouse issues such data load problems, transformation translation problems. • Translate requirements for BI and Reporting to Database design and reporting design. • Understanding data transformation and translation requirements and which tools to leverage to get the job done. • Understanding data pipelines and modern ways of automating data pipeline using cloud based • Testing and clearly document implementations, so others can easily understand the requirements, implementation, and test conditions. Qualifications • Minimum 1 year of designing and implementing a fully operational production grade large scale data solution on Snowflake Data Warehouse. • 3 years of hands-on experience with building productionized data ingestion and processing pipelines using Java, Spark, Scala, Python • 2 years of hands-on experience designing and implementing production grade data warehousing solutions on large scale data technologies such as Teradata, Oracle or DB2 • Expertise and excellent understanding of Snowflake Internals and integration of Snowflake with other data processing and reporting technologies. • Experience in building data ingestion pipeline using Talend, Informatica • Experience in working with AWS, Azure and Google data services Our Commitment to Diversity & Inclusion:   Did you know that Apexon has been Certified™ by Great Place To Work®, the global authority on workplace culture, in each of the three regions in which it operates: USA (for the fourth time in 2023), India (seven consecutive certifications as of 2023), and the UK.Apexon is committed to being an equal opportunity employer and promoting diversity in the workplace. We take affirmative action to ensure equal employment opportunity for all qualified individuals. Apexon strictly prohibits discrimination and harassment of any kind and provides equal employment opportunities to employees and applicants without regard to gender, race, color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. You can read about our Job Applicant Privacy policy here Job Applicant Privacy Policy (apexon.com)"
Sr. Data Engineer,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18315397,"Descripción
Chubb is the world's largest publicly traded P&C insurance company and a leading commercial lines insurer in the United States. With operations in 54 countries and territories, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance, and life insurance to a diverse group of clients. As an underwriting company, we assess, assume, and manage risk with insight and discipline. We service and pay our claims fairly and promptly. We combine the precision of craftsmanship with decades of experience to conceive, craft and deliver the very best insurance coverage and service to individuals and families, and businesses of all sizes. Chubb is also defined by its extensive product and service offerings, broad distribution capabilities, direct-to-consumer platform partnerships, exceptional financial strength and local operations globally. The company serves multinational corporations, mid-size and small businesses with property and casualty insurance and risk engineering services; affluent and high net worth individuals with substantial assets to protect; individuals purchasing life, personal accident, supplemental health, homeowners, automobile and specialty personal insurance coverage; companies and affinity groups providing or offering accident and health insurance programs and life insurance to their employees or members; and insurers managing exposures with reinsurance coverage. Position Overview: We are seeking a highly skilled and experienced lead data engineer to join our dynamic team. The ideal candidate will be responsible for leading the design, development and implementation of scalable data pipelines, and ensuring the effective utilization of data in the business intelligence and decision-making. Position Summary Technical Hands-on role providing direction and thought leadership in implementation of data solutions and related downstream systems including the build of repositories, such as data warehouses, data lakes, using appropriate technologies. This role requires strong technical background, hands-on experience in Informatica IICS, Databricks Python, ADF, snowflake and other Azure technologies along with data analysis skills and leadership abilities. The candidate will work on multiple projects for delivery of data solutions, including new development, maintenance, and enhancements. The candidate will also assist with the daily operations, management, and oversight of team's deliverables. Primary Responsibilities: The candidate will be responsible for design, and implement new solutions for complex data ingestions from multiple sources to enterprise data products with focus on automation, performance, resilience, and scalability, etc. Partner with Lead Architect, Data Product Manager (Product Owner) and Lead Data Integration Engineer to create strategic solutions introducing new technologies. Work with stakeholders including Management, Domain leads, and Teams to assist with data-related technical issues and support their data infrastructure needs. Strong development and programming experience in database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines. Experience in Informatica (IICS), Python, ADF, Azure Synapse, snowflake, Cosmos and Databricks Solid understanding of databases, real-time integration patterns and ETL/ELT best practices. From database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines Defining data retention policies, monitoring performance and advising any necessary infrastructure changes based on functional and non-functional requirements. Responsible for ensuring enterprise data policies, best practices, standards and processes are followed. Write up and maintain technical specifications, design documents and process flow. Mentor a team of onshore and offshore development resources to analyze, design, construct and test software development projects focused on analytics and data integration. Elaborate user stories for technical team and ensure that the team understands the deliverables. Effectively communicate, coordinate & collaborate with business, IT architecture and data teams across multi-functional areas to complete deliverables. Provide direction to the Agile development team and stakeholders throughout the project. Assist in Data Architecture design, tool selection and data flows analysis. Work with large amounts of data, interpret data, analyze results, perform gap analysis and provide ongoing reports. Handle ad-hoc analysis & report generation requests from the business. Respond to data related inquiries to support business and technical teams. Technical Skills / Experience:  7+years of proven working experience in ETL methodologies, Data integration and data migration. Informatica IICS, Databricks/Spark & Python hands-on development skills a must. Clear hands-on experience with database systems - SQL server, Oracle, Azure Synapse, Snowflake and Cosmos, Cloud technologies (e.g., AWS, Azure, Google), and NoSQL databases (e.g., Cosmos, MongoDB, DynamoDB) Skilled in backend technologies (Python, Java, Scala) & Front-end development (JavaScript, React, Angular). Extensive experience developing complex solutions focused on data ecosystem solutions. Extensive knowledge of data and analytics framework supporting data lakes, warehouses, marts, reporting, etc. In depth knowledge of data engineering and architecture disciplines Extensive experience working with Big Data tools and building data solutions for advanced analytics and Machine learning frameworks. Solid understanding of P&C Insurance data Technical expertise regarding data architecture, models and database design development Strong knowledge of and experience with Java, SQL, XML's, Python, ETL frameworks and Databricks Working knowledge/familiarity with Git version control. Strong Knowledge of analyzing datasets using Excel Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Proficient in learning new technologies with the ability to quickly understand capabilities and work with others to guide these into development. Good communication and presentation skills Solid problem solving, decision making and analytical skills. Knowledge & working experience with Duck creek is an added plus. Knowledge & working experience with Insurity Policy Decisions and/or IEV is an added plus. Experience with JIRA Other Skills / Experience: Experience being part of high-performance agile teams in a fast-paced environment. Must understand the system scope and project objectives to achieve project needs through matrix management and collaboration with other enterprise teams. Proven ability to produce results in the analysis, design, testing and deployment of applications. Strong team emphasis and relationship building skills; partners well with business and other IT/Data areas. Strong coaching / mentoring skills Applies technical knowledge to determine solutions and solve complex problems. Ability to be proactive, self-motivated, detail-oriented, creative, inquisitive, and persistent. Excellent communication and negotiation skills. Ability to organize, plan and implement work assignments, juggle competing demands and work under pressure of frequent and tight deadlines."
Data Engineer Sr,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18315159,"Descripción
Chubb is the world's largest publicly traded P&C insurance company and a leading commercial lines insurer in the United States. With operations in 54 countries and territories, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance, and life insurance to a diverse group of clients. As an underwriting company, we assess, assume, and manage risk with insight and discipline. We service and pay our claims fairly and promptly. We combine the precision of craftsmanship with decades of experience to conceive, craft and deliver the very best insurance coverage and service to individuals and families, and businesses of all sizes. Chubb is also defined by its extensive product and service offerings, broad distribution capabilities, direct-to-consumer platform partnerships, exceptional financial strength and local operations globally. The company serves multinational corporations, mid-size and small businesses with property and casualty insurance and risk engineering services; affluent and high net worth individuals with substantial assets to protect; individuals purchasing life, personal accident, supplemental health, homeowners, automobile and specialty personal insurance coverage; companies and affinity groups providing or offering accident and health insurance programs and life insurance to their employees or members; and insurers managing exposures with reinsurance coverage. Position Overview: We are seeking a highly skilled and experienced lead data engineer to join our dynamic team. The ideal candidate will be responsible for leading the design, development and implementation of scalable data pipelines, and ensuring the effective utilization of data in the business intelligence and decision-making. Position Summary Technical Hands-on role providing direction and thought leadership in implementation of data solutions and related downstream systems including the build of repositories, such as data warehouses, data lakes, using appropriate technologies. This role requires strong technical background, hands-on experience in Informatica IICS, Databricks Python, ADF, snowflake and other Azure technologies along with data analysis skills and leadership abilities. The candidate will work on multiple projects for delivery of data solutions, including new development, maintenance, and enhancements. The candidate will also assist with the daily operations, management, and oversight of team's deliverables. Primary Responsibilities: The candidate will be responsible for design, and implement new solutions for complex data ingestions from multiple sources to enterprise data products with focus on automation, performance, resilience, and scalability, etc. Partner with Lead Architect, Data Product Manager (Product Owner) and Lead Data Integration Engineer to create strategic solutions introducing new technologies. Work with stakeholders including Management, Domain leads, and Teams to assist with data-related technical issues and support their data infrastructure needs. Strong development and programming experience in database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines. Experience in Informatica (IICS), Python, ADF, Azure Synapse, snowflake, Cosmos and Databricks Solid understanding of databases, real-time integration patterns and ETL/ELT best practices. From database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines Defining data retention policies, monitoring performance and advising any necessary infrastructure changes based on functional and non-functional requirements. Responsible for ensuring enterprise data policies, best practices, standards and processes are followed. Write up and maintain technical specifications, design documents and process flow. Mentor a team of onshore and offshore development resources to analyze, design, construct and test software development projects focused on analytics and data integration. Elaborate user stories for technical team and ensure that the team understands the deliverables. Effectively communicate, coordinate & collaborate with business, IT architecture and data teams across multi-functional areas to complete deliverables. Provide direction to the Agile development team and stakeholders throughout the project. Assist in Data Architecture design, tool selection and data flows analysis. Work with large amounts of data, interpret data, analyze results, perform gap analysis and provide ongoing reports. Handle ad-hoc analysis & report generation requests from the business. Respond to data related inquiries to support business and technical teams. Technical Skills / Experience: 7+years of proven working experience in ETL methodologies, Data integration and data migration. Informatica IICS, Databricks/Spark & Python hands-on development skills a must. Clear hands-on experience with database systems - SQL server, Oracle, Azure Synapse, Snowflake and Cosmos, Cloud technologies (e.g., AWS, Azure, Google), and NoSQL databases (e.g., Cosmos, MongoDB, DynamoDB) Skilled in backend technologies (Python, Java, Scala) & Front-end development (JavaScript, React, Angular). Extensive experience developing complex solutions focused on data ecosystem solutions. Extensive knowledge of data and analytics framework supporting data lakes, warehouses, marts, reporting, etc. In depth knowledge of data engineering and architecture disciplines Extensive experience working with Big Data tools and building data solutions for advanced analytics and Machine learning frameworks. Solid understanding of P&C Insurance data Technical expertise regarding data architecture, models and database design development Strong knowledge of and experience with Java, SQL, XML's, Python, ETL frameworks and Databricks Working knowledge/familiarity with Git version control. Strong Knowledge of analyzing datasets using Excel Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Proficient in learning new technologies with the ability to quickly understand capabilities and work with others to guide these into development. Good communication and presentation skills Solid problem solving, decision making and analytical skills. Knowledge & working experience with Duck creek is an added plus. Knowledge & working experience with Insurity Policy Decisions and/or IEV is an added plus. Experience with JIRA Other Skills / Experience: Experience being part of high-performance agile teams in a fast-paced environment. Must understand the system scope and project objectives to achieve project needs through matrix management and collaboration with other enterprise teams. Proven ability to produce results in the analysis, design, testing and deployment of applications. Strong team emphasis and relationship building skills; partners well with business and other IT/Data areas. Strong coaching / mentoring skills Applies technical knowledge to determine solutions and solve complex problems. Ability to be proactive, self-motivated, detail-oriented, creative, inquisitive, and persistent. Excellent communication and negotiation skills. Ability to organize, plan and implement work assignments, juggle competing demands and work under pressure of frequent and tight deadlines."
Sr. Data Engineer,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18314892,"Descripción
Chubb is the world's largest publicly traded P&C insurance company and a leading commercial lines insurer in the United States. With operations in 54 countries and territories, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance, and life insurance to a diverse group of clients. As an underwriting company, we assess, assume, and manage risk with insight and discipline. We service and pay our claims fairly and promptly. We combine the precision of craftsmanship with decades of experience to conceive, craft and deliver the very best insurance coverage and service to individuals and families, and businesses of all sizes. Chubb is also defined by its extensive product and service offerings, broad distribution capabilities, direct-to-consumer platform partnerships, exceptional financial strength and local operations globally. The company serves multinational corporations, mid-size and small businesses with property and casualty insurance and risk engineering services; affluent and high net worth individuals with substantial assets to protect; individuals purchasing life, personal accident, supplemental health, homeowners, automobile and specialty personal insurance coverage; companies and affinity groups providing or offering accident and health insurance programs and life insurance to their employees or members; and insurers managing exposures with reinsurance coverage. Position Overview: We are seeking a highly skilled and experienced lead data engineer to join our dynamic team. The ideal candidate will be responsible for leading the design, development and implementation of scalable data pipelines, and ensuring the effective utilization of data in the business intelligence and decision-making. Position Summary Technical Hands-on role providing direction and thought leadership in implementation of data solutions and related downstream systems including the build of repositories, such as data warehouses, data lakes, using appropriate technologies. This role requires strong technical background, hands-on experience in Informatica IICS, Databricks Python, ADF, snowflake and other Azure technologies along with data analysis skills and leadership abilities. The candidate will work on multiple projects for delivery of data solutions, including new development, maintenance, and enhancements. The candidate will also assist with the daily operations, management, and oversight of team's deliverables. Primary Responsibilities: The candidate will be responsible for design, and implement new solutions for complex data ingestions from multiple sources to enterprise data products with focus on automation, performance, resilience, and scalability, etc. Partner with Lead Architect, Data Product Manager (Product Owner) and Lead Data Integration Engineer to create strategic solutions introducing new technologies. Work with stakeholders including Management, Domain leads, and Teams to assist with data-related technical issues and support their data infrastructure needs. Strong development and programming experience in database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines. Experience in Informatica (IICS), Python, ADF, Azure Synapse, snowflake, Cosmos and Databricks Solid understanding of databases, real-time integration patterns and ETL/ELT best practices. From database management, ETL processes, data modeling, and infrastructure to developing APIs, front-end applications, and automated data pipelines Defining data retention policies, monitoring performance and advising any necessary infrastructure changes based on functional and non-functional requirements. Responsible for ensuring enterprise data policies, best practices, standards and processes are followed. Write up and maintain technical specifications, design documents and process flow. Mentor a team of onshore and offshore development resources to analyze, design, construct and test software development projects focused on analytics and data integration. Elaborate user stories for technical team and ensure that the team understands the deliverables. Effectively communicate, coordinate & collaborate with business, IT architecture and data teams across multi-functional areas to complete deliverables. Provide direction to the Agile development team and stakeholders throughout the project. Assist in Data Architecture design, tool selection and data flows analysis. Work with large amounts of data, interpret data, analyze results, perform gap analysis and provide ongoing reports. Handle ad-hoc analysis & report generation requests from the business. Respond to data related inquiries to support business and technical teams. Technical Skills / Experience:  7+years of proven working experience in ETL methodologies, Data integration and data migration. Informatica IICS, Databricks/Spark & Python hands-on development skills a must. Clear hands-on experience with database systems - SQL server, Oracle, Azure Synapse, Snowflake and Cosmos, Cloud technologies (e.g., AWS, Azure, Google), and NoSQL databases (e.g., Cosmos, MongoDB, DynamoDB) Skilled in backend technologies (Python, Java, Scala) & Front-end development (JavaScript, React, Angular). Extensive experience developing complex solutions focused on data ecosystem solutions. Extensive knowledge of data and analytics framework supporting data lakes, warehouses, marts, reporting, etc. In depth knowledge of data engineering and architecture disciplines Extensive experience working with Big Data tools and building data solutions for advanced analytics and Machine learning frameworks. Solid understanding of P&C Insurance data Technical expertise regarding data architecture, models and database design development Strong knowledge of and experience with Java, SQL, XML's, Python, ETL frameworks and Databricks Working knowledge/familiarity with Git version control. Strong Knowledge of analyzing datasets using Excel Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Proficient in learning new technologies with the ability to quickly understand capabilities and work with others to guide these into development. Good communication and presentation skills Solid problem solving, decision making and analytical skills. Knowledge & working experience with Duck creek is an added plus. Knowledge & working experience with Insurity Policy Decisions and/or IEV is an added plus. Experience with JIRA Other Skills / Experience: Experience being part of high-performance agile teams in a fast-paced environment. Must understand the system scope and project objectives to achieve project needs through matrix management and collaboration with other enterprise teams. Proven ability to produce results in the analysis, design, testing and deployment of applications. Strong team emphasis and relationship building skills; partners well with business and other IT/Data areas. Strong coaching / mentoring skills Applies technical knowledge to determine solutions and solve complex problems. Ability to be proactive, self-motivated, detail-oriented, creative, inquisitive, and persistent. Excellent communication and negotiation skills. Ability to organize, plan and implement work assignments, juggle competing demands and work under pressure of frequent and tight deadlines."
Snowflake Technical Lead,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18304760,"Descripción
At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place to Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Technical Lead. What you'll do:  · Take the responsibility of the Snowflake delivery from Mexico in all aspects. Collaborate with U.S and offshore teams to deliver high quality output. · Developing data management solutions using Snowflake. · Snowflake concepts like setting up Resource monitors, RBAC controls, scalable virtual warehouse, SQL performance tuning, zero copy clone, time travel and automating them. · Migration processes to Snowflake from on-premises database environment. · Handling semi-structured data (JSON, XML), columnar PARQUET using the VARIANT attribute in Snowflake. · DesSnowflake using combination of Python, PySpark, Bash with SnowSQL. Minimum Qualifications: · Experience in Cloud technologies such as AWS – S3, SQS, EC2, Lambda, Redshift, RDS · SnowSQL Experience in developing stored Procedures writing Queries to analyze and transform data. · Certified Snowflake cloud data warehouse Architect (Desirable). · Top Skills: Snowflake (Mandatory), Cloud Data Quality/Informatica Data Quality (Desirable) · 8+ years of experience implementing data management solutions · 6+ years of experience in Snowflake · Experience in designing and building manual or auto ingestion data pipeline using Snowpipe. · Experience in in re-clustering of the data in Snowflake with good understanding on Micro-Partitions. Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture makes us stronger! Join us now! #BeCognizant #IntuitionEngineered Employee Status : Full Time Employee Shift : Day Job Travel : No Job Posting : Feb 21 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant."
Snowflake Technical Lead,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18304741,"Descripción
At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide. A Great Place to Work where we look for people who contribute new ideas, experiencing a dynamic and growing environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant! We have an exciting opportunity for an exceptional individual to work supporting one of our clients as a Technical Lead. What you'll do:  · Take the responsibility of the Snowflake delivery from Mexico in all aspects. Collaborate with U.S and offshore teams to deliver high quality output. · Developing data management solutions using Snowflake. · Snowflake concepts like setting up Resource monitors, RBAC controls, scalable virtual warehouse, SQL performance tuning, zero copy clone, time travel and automating them. · Migration processes to Snowflake from on-premises database environment. · Handling semi-structured data (JSON, XML), columnar PARQUET using the VARIANT attribute in Snowflake. · DesSnowflake using combination of Python, PySpark, Bash with SnowSQL. Minimum Qualifications: · Experience in Cloud technologies such as AWS – S3, SQS, EC2, Lambda, Redshift, RDS · SnowSQL Experience in developing stored Procedures writing Queries to analyze and transform data. · Certified Snowflake cloud data warehouse Architect (Desirable). · Top Skills: Snowflake (Mandatory), Cloud Data Quality/Informatica Data Quality (Desirable) · 8+ years of experience implementing data management solutions · 6+ years of experience in Snowflake · Experience in designing and building manual or auto ingestion data pipeline using Snowpipe. · Experience in in re-clustering of the data in Snowflake with good understanding on Micro-Partitions. Why Cognizant? Improve your career in one of the largest and fastest growing IT services providers worldwide Receive ongoing support and funding with training and development plans Have a highly competitive benefits and salary package Get the opportunity to work for leading global companies We are committed to respecting human rights and build a better future by helping your minds and the environment We invest in people and their wellbeing. We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered. At Cognizant we believe than our culture makes us stronger! Join us now! #BeCognizant #IntuitionEngineered Employee Status : Full Time Employee Shift : Day Job Travel : No Job Posting : Feb 21 2024 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant."
Senior Emerging Technology Engineer,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18279478,"Descripción
Join AstraZeneca as a Senior Emerging Technology Engineer, where you'll be at the epicentre of innovation in a role that's anything but routine. We're looking for someone who thrives in an ever-changing environment, eager to master the latest tech trends and drive the adoption of cutting-edge technologies. In this role, you'll bring emerging technologies to life, crafting captivating experiences and presentations to illuminate their potential for our strategic leaders in hands on immersive experiences. Your mission will be to not only identify and test the next big technologies within a 3-5 year horizon, but also to pave the way for their integration into AstraZeneca's future landscape. You'll be at the forefront of a 'show, don't just tell' philosophy, requiring a hands-on approach as you create Proof of Concept projects and collaborate with a diverse network of partners, from academic institutions to tech titans. You'll lean in as needed to deliver, using your own passion for learning as a driver. This role does not come with an instruction manual, you will be shaping and defining that for the rest of the organisation. This gives you a unique vantage point, accessing revolutionary technologies ahead of the curve. More than a creator of prototypes, you'll deliver thought leadership by translating intricate tech concepts into strategic insights, shaping the direction of our investments. When new technologies emerge, you'll be the architect of the capabilities needed to harness their power for our business. We're seeking a curious, tech-savvy professionals with the skills to build proofs of concepts and the boldness to tackle the unknown. If you're ready to dive into a world of exploration and have a direct impact on AstraZeneca's technological journey, step into a role that's as exciting as it is vital. What you will be doing Thought Leadership: Deliver thought-provoking and informative guidance on new and emerging technologies through immersive demonstrations and workshops. Enrich the research arm of the team with your technical expertise, contributing to the development of positioning statements and white papers. Trailblaze New Technologies: Innovate and construct bespoke Proof-of-Concept systems to illustrate the art of the possible. Influence senior strategic leaders with hands-on experiences that go beyond third-party narratives, demonstrating the value proposition of technologies from a foundation of first-hand knowledge. Embrace experimentation, understanding that learning from failed PoCs is an essential step towards success. Labs and Infrastructure Management: Take charge of the Tech Innovation infrastructure, including cloud accounts, sandboxes, source control, license servers, and more. Champion the opportunities that arise from the labs while ensuring the physical lab space and equipment are available, well-maintained, and secure. Strategic Translation: In close collaboration with research colleagues, partner with Business Technology Groups (BTGs) and Enterprise Architects to assess how new technologies can be woven into existing workflows. Where there is no existing capability, you will assist in paving the way for its creation. Technical Expertise: As the Senior Emerging Technology Engineer at AstraZeneca, you will be the bedrock of expertise for new and emerging technological trends. Strategic leaders will depend on your insights and comprehensive understanding of cutting-edge technologies to navigate critical business decisions. You will be tasked with keeping abreast of the latest tech developments and proactively engaging with strategic leaders to ensure technology adoption aligns with business objectives. Skills and competencies Software Engineering Expertise: Proficiency in architecting and programming Proof of Concept (PoC) projects is essential, utilising both familiar tech stacks and exploring new frameworks and libraries that might better mesh with new technologies. The role demands the ability to work independently as well as collaboratively within larger teams. Strategic Storytelling: Storytelling skills are crucial for effectively translating complex technical concepts and visionary ideas into simple, impactful narratives that resonate with senior executives. Influence & Collaboration: Ability to work with external partners to influence outcomes and deliver timely product innovations. The capacity to articulate intricate technical details in a clear manner that is easily understandable by senior strategic leaders as well as your colleagues in teams like Enterprise Architecture. Agility in Ambiguity: The ability to navigate ambiguity, prioritise a demanding workload, and thrive in a dynamic environment. Innovation Enthusiasm: A fervent desire to stay informed about the latest trends and developments in the innovation landscape. A genuine eagerness to engage directly with technologies, coupled with the drive and ability to rapidly learn new skills. Proven Implementation Track Record: Validated experience in delivering and deploying solutions within Continuous Development lifecycles. Curiosity & Initiative: An inquisitive mindset with a proactive approach where you are comfortable being uncomfortable. A willingness to take on new challenges and experiment in areas where you lack experience. Experience and Qualifications We understand that innovation, particularly with emerging technologies, doesn't come from a one-size-fits-all approach. The role of an Emerging Technology Engineer is multifaceted and ever-evolving. While we value technical acumen, we place a greater emphasis on finding the right candidate with a proactive, problem-solving attitude and a willingness to learn and adapt. We encourage applications from those who may not tick every box but are passionate about technology and its potential to drive change.  Programming Proficiency: Strong programming skills with experience with multiple languages including but not limited to C#, Python, and JavaScript. Exposure to additional languages such as C++, Java, Go, Rust, etc., is advantageous. This is a hands-on role and you will be expected to be able to build solutions. Cloud Expertise: Proven knowledge or experience with cloud computing and services such as AWS, GCP, or Azure. Database Experience: Experience with various databases, both relational and NoSQL, as well as newer technologies such as graph databases. Emerging technology exposure: Exposure to or experience in areas such as data science, real-time 3D, AR/VR/XR, computer vision, AI, robotics, quantum computing, etc. Project Experience: Proof of independent project development as well as collaborative team efforts, with a good understanding of source control and project management methodologies. Educational Background: A degree in software engineering, computer science OR equivalent years of relevant professional experience. Certification: AWS Associate or Professional certifications (Architect, Developer) or equivalent GCP/Azure certifications are desirable. Why AstraZeneca? At AstraZeneca when we see an opportunity for change, we seize it and make it happen, because any opportunity no matter how small, can be the start of something big. Delivering life-changing medicines is about being entrepreneurial - finding those moments and recognising their potential. Join us on our journey of building a new kind of organisation to reset expectations of what a bio-pharmaceutical company can be. This means we're opening new ways to work, pioneering cutting edge methods and bringing unexpected teams together. So, what's next! Are you already imagining yourself joining our team? Good, because we can't wait to hear from you. Where can I find out more? Follow AstraZeneca on LinkedIn https://www.linkedin.com/company/1603/ Follow AstraZeneca on Facebook https://www.facebook.com/astrazenecacareers/ Follow AstraZeneca on Instagram https://www.instagram.com/astrazeneca_careers/?hl=en AstraZeneca is an equal opportunity employer. AstraZeneca will consider all qualified applicants for employment without discrimination on grounds of disability, sex or sexual orientation, pregnancy or maternity leave status, race or national or ethnic origin, age, religion or belief, gender identity or re-assignment, marital or civil partnership status, protected veteran status (if applicable) or any other characteristic protected by law. AstraZeneca only employs individuals with the right to work in the country/ies where the role is advertised. Strong English communication skills required. Positions are open to Mexican Citizens and official residents of Mexico. Location: Guadalajara (hybrid - Expectation of working in the office 3 days a week) When we put unexpected teams in the same room, we unleash bold thinking with the power to inspire life-changing medicines. In-person working give us the platform we need to connect, work at pace and challenge perceptions. That's why we work, on average, a minimum of three days per week from the office. But that doesn't mean we're not flexible. We balance the expectation of being in the office while respecting individual flexibility. AstraZeneca embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements."
Senior Business Intelligence Analyst,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18272894,"Descripción
En Intuitive, estamos unidos detrás de nuestra misión: creemos que la atención mínimamente invasiva es la atención que mejora la vida. Mediante la inventiva y la tecnología inteligente, ampliamos el potencial de los médicos para curar sin limitaciones. Como pioneros y líderes del mercado en cirugía robótica, nos esforzamos por fomentar un equipo inclusivo y diverso, comprometido con marcar la diferencia. Durante más de 25 años, hemos trabajado con hospitales y equipos de atención de todo el mundo para ayudar a resolver algunos de los desafíos más difíciles de la atención médica y avanzar en lo que es posible. Intuitive se ha construido gracias a los esfuerzos de grandes personas de diversos orígenes. Creemos que las grandes ideas pueden provenir de cualquier lugar: nos esforzamos por fomentar una cultura inclusiva basada en la diversidad de pensamientos y en el respeto mutuo. Lideramos con inclusión y capacitamos a los miembros de nuestro equipo para que trabajen de la mejor manera y manifiesten su auténtica personalidad. Las personas apasionadas que quieren marcar la diferencia impulsan nuestra cultura: los miembros de nuestro equipo se basan en la integridad, tienen una sólida capacidad para aprender, la energía para hacer las cosas, y aportan experiencias diversas del mundo real para ayudarnos a pensar de nuevas maneras. Invertimos activamente en los miembros de nuestro equipo para apoyar su crecimiento a largo plazo y así poder continuar avanzando en nuestra misión y alcanzar su máximo potencial. Únase a un equipo comprometido a dar grandes pasos hacia delante para una comunidad global de profesionales de atención médica y sus pacientes. Juntos, avancemos en el mundo de la atención mínimamente invasiva. Job Description The Senior Business Intelligence Analyst will serve as the primary point of contact for all analytics requests from the Global Operations Supply Chain and Manufacturing departments. Minimizing supply chain risk and optimizing our manufacturing operations help surgeons and their associated institutions succeed in providing better patient outcomes. The successful candidate will work closely with department leaders to support and implement high-quality, data-driven decisions. They will leverage advanced data modeling, predictive modeling and analytical techniques to interpret key findings from company data and translate these insights into initiatives that will support business outcomes. The right person for the job will apply their exhaustive knowledge of data analysis to solving real-world problems faced by our company and finding opportunities for improvement across multiple projects, teams and business units. Establish a deep understanding of and partnership with assigned business functions Gather business requirements and determine most effective and efficient reporting methods Analyze/Model data and build comprehensive reports and dashboards that evaluate business effectiveness and impact. Use business data, statistical methods and/or suitable ML techniques to provide insight into business performance and suggest areas and methods of improving operations; Present insights and recommendations to management for decision making and strategic planning; Drive successful completion of data insight initiatives through effective collaboration with stakeholders; Partner with architecture and solution delivery teams to enable reports that maintain long-term value; Critically evaluates information gathered from multiple sources, reconcile and identify gaps, uncover unmet business needs and work with data engineering, solution architect to create a finished solution Support and provide mentorship to varying teams with guidance on how best to analyze data and execute analyses as necessary. Qualifications Demonstrated ability to work in a fast-paced environment and partner cross-functionally at all levels of the organization. Working knowledge of data mining principles: predictive analytics, mapping, collecting data from multiple data systems on premises and cloud-based data sources. Strong Snowflake SQL skills, ability to perform effective querying involving multiple tables and subqueries. Understanding of and experience using analytical concepts and statistical techniques: hypothesis development, designing tests/experiments, analyzing data, drawing conclusions, and developing actionable recommendations for business units; Practical knowledge of Machine Learning techniques and Big Data analysis preferred Experience working with databases and creating dashboards using all relevant data to inform decisions. Experience in Tableau, R/Shiny, Plotly or similar visualization tools Experience using analytics techniques to contribute to company growth efforts, increasing revenue and other key business outcomes. Strong problem solving, quantitative and analytical abilities. Strong ability to plan and manage numerous processes and projects simultaneously. Intellectual curiosity with a desire for continuous improvement. Minimum Bachelor's degree required in quantitative field; Master's / MBA preferred. Minimum 5+ years of experience in a highly analytical role. English 90% Python Airflow Additional Information Intuitive es un empleador que brinda igualdad de oportunidades de empleo. Proporcionamos igualdad de oportunidades de empleo a todos los solicitantes y empleados cualificados, y prohibimos cualquier tipo de discriminación y acoso, independientemente de su raza, sexo, condición de embarazo, orientación sexual, identidad de género, origen nacional, color, edad, religión, condición de veterano protegido o de discapacidad, información genética o cualquier otra condición protegida por las leyes federales, estatales o locales aplicables. Shift: Day Travel: None"
Senior Consultant for Data Management and Landscape Transformation Services (Global Organization),https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18268888,"Descripción
Our company culture is focused on helping our employees enable innovation by building breakthroughs together. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from. Apply now! PURPOSE AND OBJECTIVES SAP Data Management and Landscape Transformation (DMLT) group serves SAP customers in managing their data and transforming their landscapes. Business, market, and technology changes often result in realignment of business processes and structures. This reflects in various business and IT driven activities, such as Fast-track data migration and the move to SAP S/4HANA via selective data transition (SAP S/4HANA SDT) options into SAP Manage business and IT challenges that come with mergers, acquisitions, and divestitures Optimization of processes and data, or organizational restructuring Ensure data harmonization, data restructuring or the consolidation of IT system landscapes Improve data governance, master data management, data quality and information lifecycle management We support and advise our customers globally in strategy definition, conceptual planning, and the realization of their business and digital transformation requirements. In fast pace changing market and business requirements, it is also essential for customers to adopt to the digital platform to drive their business innovation with SAP S/4HANA and SAP S/4HANA cloud. The DMLT service portfolio and solution offerings play a significant role in helping customer to transition to SAP S/4HANA, BW/4, Successfactors, SAP Data Intelligence and more. The DMLT solution offerings are based on three main portfolio items: Transformation solutions helping customers with their transition into the digital economy – on premise and cloud offerings Landscape transformation services including roadmap design, advisory, business blueprinting, execution, and safeguarding for topics like M&A, Divestitures, Unification services and System consolidation (all releases) End-to-end data management solutions with products and technologies for Data Quality, Data Integration, Data Governance process etc. The service portfolio delivery ranges from short term engagements to long-term customer projects. During the upcoming years, the demand for our DMLT will increase significantly in the Latina America Region. EXPECTATIONS AND TASKS The SAP Data Management and Landscape Transformation (DMLT) as part of SAP's Customer Success Board Area is searching for a senior consultant to join the DMLT consulting team in Mexico, Mexico City office. As a DMLT consultant, your job will involve working in a global team focusing on delivering national and international projects mainly in the LAC region but where needed also in all global regions to realize planned changes in productive SAP applications and system landscapes and drive customers transition to SAP S4/H and the Intelligent Enterprise. The DMLT team offers a full solution package encompassing analysis, architecture and service delivery putting the customers in the center of all our activities. Your main tasks are: Identifying customer's holistic business needs and designing and architecting the appropriate solution proposal from the DMLT Portfolio and beyond Leading and facilitating customer's workshops and discussions to validate the best solution design for the customers' requirement and leading a global solution architect team Delivering of DMLT services projects remotely and onsite, in distributed regional and global teams Conducting feasibility studies and system analyses, supported by SAP DMLT products, tools and methodology Contributing to continuously enhance the DMLT solution design according to changing market requirements and identify potential enhancements Closely collaborate with people in different roles and locations, and with different areas and levels of expertise (for example, customer engagement lead, developers, product owners, solution architects, sales teams) Establish and maintaining trustful relationships with people on all levels of both externally on customer side and SAP internally Drive customer opportunities throughout all engagement phases (presales, sales and delivery) We expect: Continuous learning about new technologies, products, solutions and from project delivery experience Strong team player attitude: actively establish relationships and motivate through inspiration Show passion on the job: act as a role model, show authentic behavior, pride and enthusiasm in what you do Thinking outside the box, be aware of trends in the changing workforce and changing concepts of customer communication and engagement (i.e. Design Thinking Methods; lot size of one etc.) Understands the as-is situation and goals of a customer holistically, can translate it into an adequate technology roadmap design (processes, applications, systems) as well as the appropriate operating concept based on SAP's offerings, with a clear focus on customer success. Clarifies existing expectations with customer's technology/ operations experts and stakeholders; creates an approach which integrates diverse points of views and which drives success from a technology / operation perspective. Collaborates with customer / SAP teams for the best possible implementation. Drives knowledge management and innovation activities based on this experience with customers. Documents successful approaches, tools etc. and makes them available to colleagues at SAP. Collaborates and co-innovates with the respective development teams Defines IT strategies, -governance and –architecture based on state-of-the art technology; creates buy-in with the customer and works with other SAP-experts within the MaxAttention / Premium Engagements Defines the strategic, conceptual and technological boundaries for the design of the SAP-centric IT landscape as well as their financial impact. Can address the organization as well as the procedures of customers' IT-departments with a focus on high efficiency, stability and performance. Helps customers to conceptualize a state-of-the-art Technology-Innovation Roadmap. Knows solutions to address the need for cost sensitive IT operations versus supporting innovation in the age of digital transformation Stays abreast with newest technological developments driving the Digital Transformation as well as the top technology trends; uses this knowledge to drive the SAP innovation story with customer engagements. EDUCATION AND QUALIFICATIONS / SKILLS AND COMPETENCIES Required Skills: Master's degree or equivalent Fluent Portuguese - Excellent written/spoken English language skills – Good written/spoken Spanish skills Specific skills and experiences in the following functional and technical areas ABAP knowledge Knowledge and implementation experience in at least two SAP ERP or SAP S4/H Solution and modules (i.e. FI/CO, LO; SD/MM) Knowledge and experience in executing data transformation and data transition projects (i.e. migration and conversion), various data migration techniques and approaches (i.e. DMLT methods, standard transactional migration methods) Specific skills and experience in at least ONE of the following areas/solutions: Technology background with some Functional expertise ERP Functional background (Finance or Logistics) with ABAP expertise Excellent communication skills across all hierarchy levels, both internally and externally Advanced presentation and facilitation skills are a strong asset (e.g. visualization techniques, Design Thinking, etc.) Excellent Solution design skills, knowledge about data architecting / system architecting is a strong asset. ABAP Programming skills and understanding of the SAP Data Models and technical structures. Very good analytical skills combined with the ability to condense and visualize results. Experience in international customer projects Team player, proactive networking attributes, results and execution focus Proactive and interested in learning new solutions and business practices. Willingness to become an expert in DMLT migration, conversion and transformation approach and technology. Strong interpersonal skills and the ability to effectively communicate with internal and external customers to understand the specific data needs and to be able to translate those requirements into a comprehensive DMLT solution. Ability to drive execution within area of responsibility and experience in aligning cross-topic objectives & approaches. Experience in working in an international environment and experience in managing difficult client situations Experience acting as a coach for colleagues, community lead, stream lead or topic owner High customer focus and strong business acumen Experience in coordinating teams and activities, managing scope changes in complex projects WORK EXPERIENCE Minimum of 7 to 10 years' work experience in one or more SAP ERP Solution or module (e.g. as a functional consultant with technical skills (SAP data model, ABAP)) and experience in Data Transformation, Data Migration projects and solutions (SAP LT, DMLT Services or SAP EIM Solutions). Knowledge and experience in executing data migration and conversion projects, various data migration techniques and approaches Additional experience in SAP S4/H, BW/BW4, CRM, SRM, HCM/ Successfactors, Hybris, MDG, C4C or SAP Industry Solutions is a benefit Experience and proven track in long term customer C Level interaction and running international consulting projects Soft skills in communication, scope management, change management We build breakthroughs together SAP innovations help more than 400,000 customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with 200 million users and more than 100,000 employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, we build breakthroughs, together. We win with inclusion SAP's culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world. SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training. EOE AA M/F/Vet/Disability: Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability. Successful candidates might be required to undergo a background verification with an external vendor. Requisition ID: 389929 | Work Area: Consulting and Professional Services | Expected Travel: 0 - 10% | Career Status: Professional | Employment Type: Regular Full Time | Additional Locations: #LI-Hybrid. Job Segment: Data Conversion, Data Management, Cloud, Consulting, ABAP, Data, Technology"
DnA Consulting - Data Engineer - Senior - EY Global Delivery Services,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18218615,"Descripción
As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. The opportunity We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. Your key responsibilities • Design and Develop batch and streaming data processing • Build data systems and pipelines. • Evaluate business needs and objectives. • Prepare data for prescriptive and predictive modeling. • Build algorithms and prototypes. • Combine raw information from different sources. • Explore ways to enhance data quality and reliability. • Identify opportunities for data acquisition. • Monitor and optimize data storage and data processing • Design and implement data security Skills and attributes for success • 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub • 3-5 years of experience on processing real time data. • Advanced knowledge on processing large amounts of data (billions of records) in minutes. • Deep knowledge on producers (ACK/NACK), consumers, and brokers. • Deep knowledge on topics, partitions, and segments. • 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. • Advanced knowledge on data structures, MPP Databases, Blob Storage. • 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud. • Previous experience as a data engineer or in a similar role. • Data engineering certification (AZURE Certified Data Engineer) is a plus. • Flexible and adaptable; able to work in ambiguous situations. • Able to work effectively at all levels in an organization. • Must be a team player and able to work collaboratively with and through others. • Must like to learn. To qualify for the role, you must have • Bachelor's in technology or engineering or similar. • Experience working with Azure, Snowflake technologies. Ideally, you'll also have • Familiarity with agile methodologies. • Familiarity with software such as Jira or ADO. What we look for • A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment • Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries What working at EY offers At EY, we're dedicated to helping our clients, from world's top companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: • Support, coaching and feedback from some of the most engaging colleagues around • Opportunities to develop new skills and progress your career • The freedom and flexibility to handle your role in a way that's right for you About EY As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make our ambition to be the best employer by 2020 a reality. If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now"
DnA Consulting - Data Engineer - Senior - EY Global Delivery Services,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18218232,"Descripción
As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries. The opportunity We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering. Your key responsibilities • Design and Develop batch and streaming data processing • Build data systems and pipelines. • Evaluate business needs and objectives. • Prepare data for prescriptive and predictive modeling. • Build algorithms and prototypes. • Combine raw information from different sources. • Explore ways to enhance data quality and reliability. • Identify opportunities for data acquisition. • Monitor and optimize data storage and data processing • Design and implement data security Skills and attributes for success • 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub • 3-5 years of experience on processing real time data. • Advanced knowledge on processing large amounts of data (billions of records) in minutes. • Deep knowledge on producers (ACK/NACK), consumers, and brokers. • Deep knowledge on topics, partitions, and segments. • 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process. • Advanced knowledge on data structures, MPP Databases, Blob Storage. • 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud. • Previous experience as a data engineer or in a similar role. • Data engineering certification (AZURE Certified Data Engineer) is a plus. • Flexible and adaptable; able to work in ambiguous situations. • Able to work effectively at all levels in an organization. • Must be a team player and able to work collaboratively with and through others. • Must like to learn. To qualify for the role, you must have • Bachelor's in technology or engineering or similar. • Experience working with Azure, Snowflake technologies. Ideally, you'll also have • Familiarity with agile methodologies. • Familiarity with software such as Jira or ADO. What we look for • A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment • Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries What working at EY offers At EY, we're dedicated to helping our clients, from world's top companies — and the work we do with them is as varied as they are. You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer: • Support, coaching and feedback from some of the most engaging colleagues around • Opportunities to develop new skills and progress your career • The freedom and flexibility to handle your role in a way that's right for you About EY As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make our ambition to be the best employer by 2020 a reality. If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now"
Integration Engineer – Warehouse Automation,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18166653,"Descripción
A.P. Moller - Maersk is an integrated container logistics company and member of the A.P. Moller Group. Connecting and simplifying trade to help our customers grow and thrive. With a dedicated team of over 80,000, operating in 130 countries; we go all the way to enable global trade for a growing world. From the farm to your refrigerator, or the factory to your wardrobe, A.P. Moller - Maersk is developing solutions that meet customer needs from one end of the supply chain to the other. It is an amazing time to join Maersk IoT and Automation platform team as we are accelerating our ambitious journey of modernizing our terminal infrastructure across the globe. To support this exciting endeavour, we are currently looking for an Integration Engineer to join our Automation platform team - based in Mexico City. Key Responsibilities Listed below are some of the key responsibilities our Senior Data Architects take on. However, we work in an Agile environment, making this a superb opportunity for you to carve this role for yourself: Be a part of a team that provides products and platform services based on defined automation engineering specifications, warehouse operations requirements, and automation industry best practices in a timely manner. Utilize you transport and logistics, automation engineering competencies within the function to ensure support of projects and services. Focusing on warehouse and distribution modernization/automation initiatives, products, and deployments. Engages in dialogue with external stakeholders such as suppliers, consultants, and relevant peers in warehouse operation management teams as the team develop new service areas in close collaboration with, Maersk Logistics and Services Business Product Owners, Functional Product Owners and Solutions Engineers, Delivery, Innovation and Growth. Has responsibility for automation solution/product design, automation requirements definition and automation integration for automation projects and tenders. Work with partners, product owners, scrum masters, and the scrum team do release and sprint planning and provide team commitments accordingly Who are we are looking for While reading the following list, please consider that we value your whole skill set and expertise more than a list of “must haves”. If you believe you can aspire to this role, get in touch, even if you don't currently have everything listed – let's talk! And of course, reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Approximately 5 years of warehouse automation industry experience with good experience in automation / Integration / architecting or developing and delivering end-to-end products/solutions for ports and container terminals. Experience in technical and technology design and implementation of automated sortation systems, AGV, and ASRS solutions. Experience in building/integrating solutions as part of a team that can be horizontally scalable, distributed, resilient, fault-tolerant, and monitored. Experience in building software integrated solutions in an agile/DevOps environment. Excellent communication and cross-functional cooperation capabilities – a team player with positive Can-Do, result-oriented attitude Understand product lifecycle implementation of OT/Automation architecture solutions and associated industry (IT/OT) industrial automation standards We Offer Being part of a fast-growing, dynamic, and impactful team, you, as Senior Engineering Manager, will be entrusted with the unique opportunity to build, manage, focus, and develop an engineering team that meets the needs of the business and works well within the overall automation technology landscape. You draw from a deep and broad technical expertise to mentor engineers, complete hands-on technical work, and provide leadership on complex technology issues in the company. While deploying your solid skills in automation engineering, product design, and product deployment/delivery/integration, you focus on building and nurturing great automation engineering talent and making a difference on a global level. This is a big moment for us – we have a clear vision for the future of global trade and there's never been a more exciting time to take part. Are you ready? Maersk is committed to a diverse and inclusive workplace, and we embrace different styles of thinking. Maersk is an equal opportunities employer and welcomes applicants without regard to race, colour, gender, sex, age, religion, creed, national origin, ancestry, citizenship, marital status, sexual orientation, physical or mental disability, medical condition, pregnancy or parental leave, veteran status, gender identity, genetic information, or any other characteristic protected by applicable law. We will consider qualified applicants with criminal histories in a manner consistent with all legal requirements. We are happy to support your need for any adjustments during the application and hiring process. If you need special assistance or an accommodation to use our website, apply for a position, or to perform a job, please contact us by emailing accommodationrequests@maersk.com."
Solution Architect Analyst,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=4&jobid=18408166,"Descripción
About World Business Lenders (www.wbl.com)

World Business Lenders (WBL) provides general purpose short-term real estate collateralized commercial loans to a broad customer base comprised of small and medium sized businesses throughout the United States that lack access to traditional funding.

WBL is a U.S.-based company with a 100% remote workforce.

This is a remote Contract/Consultant position. Working hours will be 9:00am-6:00pm Eastern Time, Monday through Friday. The job requires excellent oral and written command of the English language. Resumes must be submitted in English.

About the Job:

As a Solution Architect, you will be at the forefront of our data transformation journey, tasked with diagnosing and optimizing our current data architecture. Your role will involve a deep dive into commission and quoting processes, identifying pain points, and devising innovative solutions to enhance efficiency and effectiveness. Additionally, you will play a pivotal role in evaluating existing software and programs, as well as exploring new acquisitions to meet our evolving needs. With a focus on problem evaluation and strategic planning, you will have the opportunity to shape the future of our data ecosystem from the ground up.

We are seeking individuals who are not only technically proficient but also possess a keen understanding of business objectives and industry trends. Your ability to create data architectures from scratch, coupled with your expertise in Excel, SQL, and VBA, will be essential in driving impactful change within our organization. This role offers a unique opportunity to leverage your skills and creativity to overcome complex challenges and drive meaningful progress in the lending technology landscape.

Responsibilities:
Diagnose and evaluate existing data architecture, in commission and quoting processes.
Propose innovative solutions to optimize data architecture and improve operational efficiency.
Determine suitability of existing software and programs, as well as recommend new acquisitions when necessary.
Evaluate problems within our data ecosystem and develop strategic plans to overcome them.
Create data architectures from scratch, ensuring scalability and sustainability.
Assess the value of current Loan Origination Systems (LOS) and Loan Management Software (LMS) and consider migration strategies


Requirements
100% fluency in English, with exceptional English verbal and written communication skills
Bachelor's degree in computer science or related discipline with a minimum of 2 or more years of work experience in a business environment.
Maintain accurate documentation and have excellent written and communication skills.
Critical thinking and good attention to detail in all aspects of administrative support.
The ability to work with a high degree of accuracy and to manage multiple issues and demands.
Must be dependable by meeting deadlines, working independently, being accountable for work, and having good attendance record management.
A strong sense of urgency and a desire to succeed.
Proficiency in Excel, SQL, and Python
Strong problem evaluation skills with wide vision.
Prior experience in architecting data solutions from scratch or rebuilding existing data architectures.
You must have your own computer/laptop - the company does not supply equipment


Benefits
CONTRACT/CONSULTANCY POSITION
USD Experienced Based Salary (depending on experience).
11 US Holidays paid
A 100% Fully remote environments)"
DnA Consulting - Data Engineer - Senior - EY Global Delivery Services,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18398729,"Descripción
EY-GDS- DnA Consulting - Data Engineer Azure-Snowflake (Batch)

As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries.

The opportunity

We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering.

Your key responsibilities
• Design and Develop batch and streaming data processing
• Build data systems and pipelines.
• Evaluate business needs and objectives.
• Prepare data for prescriptive and predictive modeling.
• Build algorithms and prototypes.
• Combine raw information from different sources.
• Explore ways to enhance data quality and reliability.
• Identify opportunities for data acquisition.
• Monitor and optimize data storage and data processing
• Design and implement data security

Skills and attributes for success
• 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub
• 3-5 years of experience on processing real time data.
• Advanced knowledge on processing large amounts of data (billions of records) in minutes.
• Deep knowledge on producers (ACK/NACK), consumers, and brokers.
• Deep knowledge on topics, partitions, and segments.
• 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process.
• Advanced knowledge on data structures, MPP Databases, Blob Storage.
• 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud.
• Previous experience as a data engineer or in a similar role.
• Data engineering certification (AZURE Certified Data Engineer) is a plus.
• Flexible and adaptable; able to work in ambiguous situations.
• Able to work effectively at all levels in an organization.
• Must be a team player and able to work collaboratively with and through others.
• Must like to learn.

To qualify for the role, you must have
• Bachelor's in technology or engineering or similar.
• Experience working with Azure, Snowflake technologies.

Ideally, you'll also have
• Familiarity with agile methodologies.
• Familiarity with software such as Jira or ADO.

What we look for
• A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment
• Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries

What working at EY offers

At EY, we're dedicated to helping our clients, from world's top companies - and the work we do with them is as varied as they are.
You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer:
• Support, coaching and feedback from some of the most engaging colleagues around
• Opportunities to develop new skills and progress your career
• The freedom and flexibility to handle your role in a way that's right for you

About EY

As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make our ambition to be the best employer by 2020 a reality.

If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible.

Join us in building a better working world.
Apply now"
DnA Consulting - Data Engineer - Senior - EY Global Delivery Services,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18398730,"Descripción
EY-GDS- DnA Consulting - Data Engineer Azure-Snowflake (Batch)

As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries.

The opportunity

We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering.

Your key responsibilities
• Design and Develop batch and streaming data processing
• Build data systems and pipelines.
• Evaluate business needs and objectives.
• Prepare data for prescriptive and predictive modeling.
• Build algorithms and prototypes.
• Combine raw information from different sources.
• Explore ways to enhance data quality and reliability.
• Identify opportunities for data acquisition.
• Monitor and optimize data storage and data processing
• Design and implement data security

Skills and attributes for success
• 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub
• 3-5 years of experience on processing real time data.
• Advanced knowledge on processing large amounts of data (billions of records) in minutes.
• Deep knowledge on producers (ACK/NACK), consumers, and brokers.
• Deep knowledge on topics, partitions, and segments.
• 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process.
• Advanced knowledge on data structures, MPP Databases, Blob Storage.
• 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud.
• Previous experience as a data engineer or in a similar role.
• Data engineering certification (AZURE Certified Data Engineer) is a plus.
• Flexible and adaptable; able to work in ambiguous situations.
• Able to work effectively at all levels in an organization.
• Must be a team player and able to work collaboratively with and through others.
• Must like to learn.

To qualify for the role, you must have
• Bachelor's in technology or engineering or similar.
• Experience working with Azure, Snowflake technologies.

Ideally, you'll also have
• Familiarity with agile methodologies.
• Familiarity with software such as Jira or ADO.

What we look for
• A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment
• Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries

What working at EY offers

At EY, we're dedicated to helping our clients, from world's top companies - and the work we do with them is as varied as they are.
You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer:
• Support, coaching and feedback from some of the most engaging colleagues around
• Opportunities to develop new skills and progress your career
• The freedom and flexibility to handle your role in a way that's right for you

About EY

As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make our ambition to be the best employer by 2020 a reality.

If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible.

Join us in building a better working world.
Apply now"
DnA Consulting - Data Engineer - Senior - EY Global Delivery Services,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18392747,"Descripción
EY-GDS- DnA Consulting - Data Engineer Azure-Snowflake (Batch)

As part of our EY- GDS-DnA Consulting team, you will help clients use various methods to transform raw data into useful data systems. You will align data systems with business goals. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The ideal candidate should have 3-5 years of experience, Data Engineering, KAFKA, Advanced SQL, Advanced Phyton programming, Spark, ETL and ELT Process knowledge, Data structures knowledge, MPP Databases (Teradata, Snowflake), Blob Storage, Azure Data Lake Storage, AZURE cloud. The Data Engineer will interact with different members of the team such as database architects, data analysts, and data scientists on data initiatives and ensure optimal data delivery architecture is consistent with business strategy. Our clients usually have theirs headquarters on USA, however they span across multiple industries, regions, and countries.

The opportunity

We are looking for Senior Data Engineer with expertise in developing and managing Kafka based data pipelines, implementing complex stored procedures and best practices with data warehouse and ETL concepts, deploy fully operational data warehouse solutions into production on Snowflake to join our GDS Mexico team. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of a new service offering.

Your key responsibilities
• Design and Develop batch and streaming data processing
• Build data systems and pipelines.
• Evaluate business needs and objectives.
• Prepare data for prescriptive and predictive modeling.
• Build algorithms and prototypes.
• Combine raw information from different sources.
• Explore ways to enhance data quality and reliability.
• Identify opportunities for data acquisition.
• Monitor and optimize data storage and data processing
• Design and implement data security

Skills and attributes for success
• 3-5 years of experience on Apache Kafka, Kafka stream, AZURE Event Hub
• 3-5 years of experience on processing real time data.
• Advanced knowledge on processing large amounts of data (billions of records) in minutes.
• Deep knowledge on producers (ACK/NACK), consumers, and brokers.
• Deep knowledge on topics, partitions, and segments.
• 3-5 years of advanced knowledge on SQL, phyton programming, ETL and ELT Process.
• Advanced knowledge on data structures, MPP Databases, Blob Storage.
• 3-5 years of experience on AZURE data lake Storage (Teradata, Snowflake), AZURE cloud.
• Previous experience as a data engineer or in a similar role.
• Data engineering certification (AZURE Certified Data Engineer) is a plus.
• Flexible and adaptable; able to work in ambiguous situations.
• Able to work effectively at all levels in an organization.
• Must be a team player and able to work collaboratively with and through others.
• Must like to learn.

To qualify for the role, you must have
• Bachelor's in technology or engineering or similar.
• Experience working with Azure, Snowflake technologies.

Ideally, you'll also have
• Familiarity with agile methodologies.
• Familiarity with software such as Jira or ADO.

What we look for
• A Team of people with technical experience and enthusiasm to learn new things in this fast-moving environment
• Opportunities to work with EY GDS DnA Consulting practice globally with leading businesses across a range of industries

What working at EY offers

At EY, we're dedicated to helping our clients, from world's top companies - and the work we do with them is as varied as they are.
You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees, and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer:
• Support, coaching and feedback from some of the most engaging colleagues around
• Opportunities to develop new skills and progress your career
• The freedom and flexibility to handle your role in a way that's right for you

About EY

As a global leader in assurance, tax, transaction, and advisory services, we're using the finance products, expertise, and systems we've developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities, and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we'll make our ambition to be the best employer by 2020 a reality.

If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible.

Join us in building a better working world.
Apply now"
Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18357216,"Descripción
Caylent is a cloud native services company that helps organizations bring the best out of their people and technology using Amazon Web Services (AWS). We provide a full-range of AWS services including: workload migrations & modernization, cloud native application development, DevOps, data engineering, security & compliance and everything in between. At Caylent, our people always come first.

We are a fully remote global company with employees in Canada, the United States and Latin America. We celebrate the culture of each of our team members and foster a community of technological curiosity. Come talk to us to learn more about what it means to be a Caylien!

The Mission

At Caylent, a Data Architect works as an integral part of a cross-functional delivery team to design and implement data management solutions on the AWS cloud for our customers. You will design and document the data architecture, data transformations and schema design, and provide guidance to the engineers performing the hands-on implementation of your design. You will participate in daily standup meetings with your team and bi-weekly agile ceremonies with the customer. Your manager will have a weekly 1:1 with you to help guide you in your career and make the most of your time at Caylent.

Your Assignment
Work with a team to deliver top-quality data solutions on AWS for customers
Participate in daily standup meetings and address technical issues
Design, optimization and migration of relational databases
Be able to write code whenever needed and possible
Lead and help engineers without any direct supervision
Your Qualifications
Design and implementation of at least two of these:
ETL, Orchestration and CI/CD pipelines
SQL databases, Stored Procedures and Query optimization
Analytics and visualization
MDM and Data Governance
Design and implementation of at least two of these on AWS:
High Availability (HA) solutions, read/write replicas and optimization
RDS and Aurora performance tuning
Large scale application migration and modernization with a heavy focus on DB
Security, access controls and governance on cloud
Expert-level understanding of Data Warehouses, and RDBMSs like Redshift, Snowflake, Postgres, Oracle, SQL Server
Experience with IaC tools such as CloudFormation, CDK, Terraform
Experience with AWS Glue, Lambda, SDK
Experience with CI/CD tools
Excellent written and verbal communication skills


Benefits
100% remote work
Medical Insurance for you and eligible dependents
Generous holidays and flexible PTO
Competitive phantom equity
Paid for exams and certifications
Peer bonus awards
State of the art laptop and tools
Equipment & Office Stipend
Individual professional development plan
Annual stipend for Learning and Development
Work with an amazing worldwide team and in an incredible corporate culture

Caylent is a place where everyone belongs. We celebrate diversity and are committed to creating an inclusive environment for all employees. Our approach helps us to build a winning team that represents a variety of backgrounds, perspectives, and abilities. So, regardless of how your diversity expresses itself, you can find a home here at Caylent.

We are proud to be an equal opportunity employer. We prohibit discrimination and harassment of any kind based on race, color, religion, national origin, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, veteran status, genetic information, disability, or other applicable legally protected characteristics. If you would like to request an accommodation due to a disability, please contact us at hr@caylent.com."
DATA ARCHITECT,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18287278,"Descripción
Desarrolla tu carrera en Zurich

Zurich, aseguradora líder a nivel internacional te invita a ser parte de su equipo:

Data Architect

Tus habilidades y experiencia:
Escolaridad: Licenciatura o ingeniería en Sistemas o afín
Experiencia mínima de 2 años en Data Analysis, Data Science y/o Data Architecture, Lenguajes de programación. Big data en Azure,
Experiencia lidereando y gestionando soluciones de Big Data en Azure, con un enfoque específico en Delta Lake. Familiaridad con tecnologías como Hadoop Core, Hive, Spark, Kafka, Sqoop, Ambari, Zeppelin y Databricks es esencial.
Experiencia en el diseño y gestión de bases de datos, incluyendo PostgreSQL, DB2, Redis, Cassandra y Neo4j.
Familiaridad con herramientas de orquestación como Apache Airflow y plataformas de seguimiento y gestión de modelos como MLflow.
Experiencia y conocimiento del sector financiero y/o Seguros
Inglés: Intermedio


Conocimientos técnicos:

Más de 4 años de experiencia en roles relacionados con ingeniería de datos, big data, ciencia de datos y analítica.
1 a 2 mínimo como gerente o responsable de proyecto interdisciplinarios y multidisciplinarios para la creación de productos de datos.
Experiencia en arquitecturas distribuidas y en entornos cloud, con un enfoque particular en Azure.
Experiencia en gestión de protección y calidad de datos.
Conocimiento de la arquitectura de datos y soluciones tecnológicas.
Conocimiento de las prácticas de gobierno de datos, cuestiones comerciales y tecnológicas relacionadas con la gestión de activos de información empresarial y enfoques relacionados con la protección de datos.
Conocimiento de los requisitos regulatorios gubernamentales relacionados con los datos y las tendencias y problemas emergentes


Objetivo de la posición:

Experto digital enfocado en ejecutar la estrategia de datos de la empresa, basado en estándares de calidad, el tratamiento del flujo de datos y la seguridad de los mismos.

Extraer información que pueda transformar el negocio, desarrollo e implementación de estrategias de datos, diseños de modelos de datos, estándares de desarrollo de bases, así como implementación y gestión de almacenes de datos

Responsabilidades clave

Liderar la implementación y gestión de soluciones de Big Data en Azure, con un enfoque específico en Delta Lake. Familiaridad con tecnologías como Hadoop Core, Hive, Spark, Kafka, Sqoop, Ambari, Zeppelin y Databricks es esencial.
Supervisar el ciclo completo de desarrollo de proyectos, desde la concepción hasta la implementación, garantizando la eficiencia y calidad en todas las fases.
Desarrollar e implementar estrategias de gobernanza de datos, asegurando la calidad y seguridad de los datos en todo momento.
Establecer y gestionar una hoja de ruta para la implementación del gobierno de datos empresariales que incluya prioridades estratégicas para el desarrollo de capacidades basadas en información.
Implementar un marco de gobierno de datos en toda la empresa, con un enfoque en la mejora de la calidad de los datos y la protección de datos confidenciales mediante modificaciones a las políticas y estándares de comportamiento de la organización, principios, métricas de gobierno, procesos, herramientas relacionadas y arquitectura de datos.
Definir roles y responsabilidades relacionados con el gobierno de datos y garantizar una responsabilidad clara para la administración de los principales activos de información de la empresa.
Servir como enlace entre las áreas comerciales y funcionales y la tecnología para garantizar que los requisitos comerciales relacionados con los datos para proteger los datos confidenciales estén claramente definidos, comunicados y bien comprendidos y considerados como parte de la priorización y planificación operativa.
Liderar equipos ágiles, fomentando la colaboración y la entrega continua. Experiencia en NodeJS (Express), C# y Python (Pandas, Scikit-learn, Seaborn, Flask, Fast-API, Django) es fundamental.
Experiencia en el diseño y gestión de bases de datos, incluyendo PostgreSQL, DB2, Redis, Cassandra y Neo4j.
Familiaridad con herramientas de orquestación como Apache Airflow y plataformas de seguimiento y gestión de modelos como MLflow.
Experiencia práctica con Databricks para la implementación y optimización de flujos de trabajo de big data y análisis.


Ofertamos:

Para los internos CEO de tu carrera
Plataforma de beneficios flexibles, MYPDC
Esquema de ayudas


Zurich reconoce la diversidad de nuestra fuerza laboral como una fortaleza, por lo que contamos con políticas y programas de diversidad e inclusión, donde buscamos igualdad de oportunidades sin importar la edad, etnia, sexo, orientación sexual, identidad o expresión de género, discapacidades, etc. Como empleador inclusivo, queremos asegurarnos de que todos los candidatos se sientan cómodos y puedan rendir al máximo durante la entrevista.

Por qué elegir Zurich

En Zurich, nos gusta pensar con originalidad y desafiar el statu quo. Adoptamos un enfoque optimista centrándonos en los aspectos positivos y preguntándonos constantemente ¿Qué puede salir bien?

Somos un empleador que ofrece igualdad de oportunidades y que sabe que cada colaborador es único ¡lo que hace que nuestro equipo sea el mejor!

Colabora con nosotros mientras exploramos constantemente nuevas formas de proteger a nuestros clientes y al planeta."
Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18137662,"Descripción
Every day, Global Payments makes it possible for millions of people to move money between buyers and sellers using our payments solutions for credit, debit, prepaid and merchant services. Our worldwide team helps over 3 million companies, more than 1,300 financial institutions and over 600 million cardholders grow with confidence and achieve amazing results. We are driven by our passion for success and we are proud to deliver best-in-class payment technology and software solutions. Join our dynamic team and make your mark on the payments technology landscape of tomorrow.

Purpose
Data Architects are senior visionaries who translate business requirements into technology requirements and define data standards and principles, often in support of data or digital transformations. The Data Architect is responsible for visualizing and designing an organization's enterprise data management framework. This framework describes the processes used to plan, specify, enable, create, execute, acquire, maintain, use, archive, retrieve, control, and purge data.

The Data Architect also ""provides a standard common business vocabulary, expresses strategic requirements, outlines high-level integrated designs to meet those requirements, and aligns with enterprise strategy and related business architecture.""

The engineer part is all about executing these strategies in real product life-cycle situations, while understanding the product requirements and data needs.

Essential Duties
Translating business requirements to technical specifications, including state diagrams and transitions, integrating transformations, data security and lifecycle consistent with PCI and PII standards.
Defining the data architecture framework, standards, and principles. This includes modeling, metadata security, reference data, and performance characteristics and analysis.
Defining Data patterns or reference architecture which limit data complexity and manageability.
Support the data development needs of several teams which currently work on our product.
Commonly work with Microsoft SQL tools for analysis, incident forensics, and stored procedures in support of development efforts.
Review data access and models used by development teams when implementing solutions reliant on data.


Other Duties
Being an active member and good communicator when working with stakeholders, partners, vendors, development teams, and upper management.
Typical work is standard shifts, but the occasional incident of critical business events may require weekend or after-hour work.
Ability to generate reports concerning data when requested.


Required Qualifications
College degree in data science or strongly related field
5-8 years of experience in data related field
Experience with Microsoft SQL, SSRS, and Service Broker servers.
Advanced skills in SQL
Experience in stored procedures and performance tuning, high concurrency OLTP
Good verbal and written, and produce technical documentation.


Preferred Qualifications
Experience with large data related products and applications
Experience with cloud data models and solutions
Expert skill area in any of the base skills listed in Job requirements


Career Path

Sr. Software Architect -> Principal Architect

Competencies

*determined by Talent Management

Global Payments Inc. is an equal opportunity employer.

Global Payments provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex (including pregnancy), national origin, ancestry, age, marital status, sexual orientation, gender identity or expression, disability, veteran status, genetic information or any other basis protected by law. Those applicants requiring reasonable accommodation to the application and/or interview process should notify a representative of the Human Resources Department."
Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18383303,"Descripción
Description
We're hiring!

At Cognizant we have an ideal opportunity for you to be part of one of the largest companies in the digital sector worldwide.A Great Place To Work where we look for people who contribute new ideas, experiencing a dynamic and growng environment. At Cognizant we promote an inclusive culture, where we value different perspectives providing career growth and development opportunities. #WelcomeToCognizant!

We have an exciting opportunity for an exceptional individual to work supporting one of our clients as Data Architect

We are actively searching for a highly competent Data Architect who is strong in Design and Architecting solution for Industrial 4.0 and AWS IOT Cloud and Digital transformation and Integration of ERP SAP and other systems providing solution for On-Prem and Cloud solutions for data transformation, modelling, processing, etc.

Required Skills
• Must have proven experience of successfully managing complex data solutions using AWS.
• Extensive experience in architecting, designing, and implementing the data flow from on- premises application into an AWS Data Lake, S3 and SQL Server, Snowflake database.
• Should have strong analytical skills in understanding the un-structured data, raw data, meta data, real-time and event data processing from cloud to cloud and from external systems to AWS cloud or any data platforms and Intelligence infrastructure integration.
• Ability to create clear and detailed technical diagrams and documentation, Deep understanding of AWS cost model(s) and cost-conscious design principles, security, performance, availability zones, disaster recovery plans.
• Hands on expertise in Data ingestion, integration and ETL architecture, creating data models, contextualization, aggregation, normalizing and processing the data at IoT Edge and IoT Cloud.
• Design New Solutions, collaborate with data and engineering architects and development teams to design and build cutting edge AWS data ingestion, enrichment, and accessibility capabilities.
• Cost Effective Engineering, engage with key business stakeholders and technical staff to appropriately understand and recommend solutions that balance AWS costs against the resulting technical benefits.
• Should have good understanding of ERP systems DB2, SAP ECC, PLC, Sensor, OPC UA data for collecting the data of various data formats and convert into proper JSON, XML structures.
• Good to have experience reading excel files data and converting into to data model and storing them in S3. Data engineering on batch job and identifying job or schedule or dependencies.
• Should have worked on open source, enterprise collaboration, microservices, serverless, , database management in the cloud, management tools, IoT devices experience in the cloud, experience with private and public cloud architectures, migration considerations.
• Data processing using AWS services, VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, Kinesis, Kafka, Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Cloudtrail, CloudWatch, Docker, Lambda, Spark, Glue, Sage Maker, AI/ML, API GW.
• Should be able to work on high loads, manage storage, join data across one or more databases in the cluster and use serverless architecture and get insights from data quickly and consistently provide high performance and scalable solution
• Involves in choosing appropriate database systems, optimizing data schemas, and ensuring data quality and integrity, handle huge data volumes and ensure fault tolerance.

1. Qualification - Bachelor's degree in information technology or equivalent

2. Experience - 12 - 16 yrs.

3. Demand requires Travel?: No

Why Cognizant?

Improve your career in one of the largest and fastest growing IT services providers worldwide
Receive ongoing support and funding with training and development plans
Have a highly competitive benefits and salary package
Get the opportunity to work for leading global companies
We are committed to respecting human rights and build a better future by helping your minds and the environment
We invest in people and their wellbeing.

We create conditions for everyone to thrive. We do not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered.

At Cognizant we believe than our culture make us stronger!
Join us now!

#BeCognizant #IntuitionEngineered

Qualifications
Technical Skills

SNo

Primary Skill

Proficiency Level *

Rqrd./Dsrd.

1

AWS IoT

PL1

Required

Domain Skills

SNo

Primary Skill

Proficiency Level *

Rqrd./Dsrd.

1

Engineering & Design

NA

Required

* Proficiency Legends

Proficiency Level

Generic Reference

PL1

The associate has basic awareness and comprehension of the skill and is in the process of acquiring this skill through various channels.

PL2

The associate possesses working knowledge of the skill, and can actively and independently apply this skill in engagements and projects.

PL3

The associate has comprehensive, in-depth and specialized knowledge of the skill. She / he has extensively demonstrated successful application of the skill in engagements or projects.

PL4

The associate can function as a subject matter expert for this skill. The associate is capable of analyzing, evaluating and synthesizing solutions using the skill."
Sr. Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18144145,"Descripción
Take a step forward and let Edenred surprise you.

Every day, we deliver innovative solutions to improve the life of millions of people, connecting employees, companies, and merchants all around the world.

We know there are hundred ways for you to grow. With us, you will expand your skills in a multicultural, challenging, and dynamic environment.

Dare to join Edenred and get ready to thrive in a global company that will offer you endless opportunities.

Edenred is all about meritocracy. You come as you are, and you contribute. Indeed, the Edenred Group recognizes, recruits and develops all talents and singularities.

We are committed to preventing all forms of discrimination and to providing all our candidates with equal opportunities regardless of their gender and gender expression, disability, origin, religious belief and sexual orientation or any other criteria.

Definition of business standards, data management processes and data architecture frameworks.
Develop the company's conceptual and logical data models for analytical, operational and data structures according to industry best practice models.
Oversee the organization's overall data architecture, define the data architecture strategy; design and implement architectures such as for Data Warehouse, master data/reference data, data integration, and transaction processing.
Work with database management teams/data architects and analysts to help establish standards and strategies.
Help maintain assessment and inventory of the existing data environment at the enterprise level.
Design and develop a strategy for data storage both in on-prem and cloud-based solutions.
Determine the feasibility of a Data-as-as-Service model for diverse projects.
Assist with the review and approval of major projects and business solution deliverables from a data architecture standpoint.
Document data pipeline procedures or queries for metadata and reference data cases
Familiarity with commercial CMBDs for issue tracking and deliverable documentation.
Use programming languages (like Python, C#, etc) to code, test, and troubleshoot data architecture applications.


Apply now and Vibe with Us!"
Data Architec,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18250468,"Descripción
Job Description

We are looking for a Data Architect to join our team and help us build a world-class data
infrastructure. The ideal candidate will have a strong understanding of data modelling, data
migration, cloud computing, master data management, and golden record creation.

Responsibilities

Design and implement data architectures that meet the needs of our business users.
Lead data migration projects to the cloud
Set up semantic layers for analytics engines.
Create and manage master data sets.
Create golden records for key data entities.
Work with data engineers and data scientists to build and maintain data pipelines.
Stay up to date on the latest data technologies.

Qualifications

Bachelor's degree in computer science, or a related field
5+ years of experience in data architecture
Experience with cloud computing (AWS, Azure, GCP)
Experience with data modelling and data migration
Experience with setting up semantic layers for analytics engines.
Experience with master data management
Experience with golden record creation
Strong understanding of data warehousing and data marts
Excellent communication and problem-solving skills"
Data Architect with AWS,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18124370,"Descripción
DARE TO BE A PART OF THE CHALLENGE! COME AND JOIN OUR TEAM TOGETHER WE CAN MAKE THE DIFFERENCE!

Did you know that Accenture is leading the digital transformation in the World?

Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Our main purpose is to collaborate with our clients, so they can become high-performance businesses. Accenture is present in more than 200 cities, 49 countries and approximately 743,000 employees worldwide.

Offer
Career development according to your profile and interests.
Work in one of the best companies and feel proud.
Access to an innovative methodology and tools.
Direct contact with experts worldwide.
Use of work schemes and cutting-edge technologies.
Constant training.
Work environment based on teamwork and collaboration.
Participation in International Projects


#LI-LATAM

Job Description

-Experience working in AWS environment.
-Works with the data engineering teams, providing oversight and direction to deliver and ensure on time, on scope and high quality data architecture design and implementation plan as well as end to end delivery.
Ensures architecture is sound and can deliver to the business requirements.
Responsible to participate in architecture assessments and evaluations as required for the project.
-Manages the data engineering architecture projects providing direction on scope and leading the team throughout requirements, design, development, and validation phase to deliver high quality products deliverables.
-Support the delivery of data engineering programs by managing specific projects and workstreams.
-Work with business teams to capture business requirements and translate into conceptual technical architecture and design.

Skills:

1. Data Access
2. Data Architecture Principles
3. Data Taxonomy
4. PostgreSQL
5. MySQL

Accenture does not discriminate based on race, religion, color, sex, age, disability, nationality, sexual orientation, gender identity or expression, or for any other reason covered by local law.

Oportunidad Laboral Equitativa
Todas las decisiones del empleador deben tomarse sin tomar en cuenta la edad, raza, creencias, color, religión, sexo, nacionalidad de origen, discapacidades, orientación sexual, identidad o expresión de género, información genética, estado civil, estado de ciudadanía u otra base protegida por la federación, estado, o leyes locales.

Los candidatos no estarán obligados a revelar registros sellados o cancelados de condena o arresto como parte del proceso de contratación. Accenture se compromete a proporcionar oportunidades de empleo para veteranos a nuestros hombres y mujeres de servicio."
Lead Enterprise Data Architect,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18224394,"Descripción
Excellence In Everything We Touch

Position Summary

Full-time role, remote position at Crawford and Company. Looking for a candidate with deep understanding of Enterprise Data Architecture, Data Lake, Data Warehousing, Master Data Management, Data Catalogs and Lineage, Data Governance and Data Quality. Data Architect should help formulate the organizational data strategy, including standards of data quality, the flow of data within the organization, and security and governance of data. This role will work in close collaboration with data engineers and architects to build a sound data architecture and help support our continued growth at the forefront of technology innovation and data modernization efforts.

Responsibilities

The Enterprise/Principal Data Architect at Crawford and Company will be responsible for architecture, design and delivery of data solutions and infrastructure.
This position will help develop and implement an overall organizational data strategy (data model designs, data practices, data related tooling, data governance standards, implementation and management of cloud data warehouses, data lakes, data marts and data analytics systems) that is in line with business processes.
Lead Data Architect will work directly with business and technology partners to scope, socialize, prioritize, sequence, and implement data solutions to meet business priorities in keeping with the technology strategy and standards
Data Architect will analyze structural requirements for new software and applications.
This position will act as subject matter expert (SME) for data management and integration technology; and guide delivery teams on implementing data solutions
This position will be responsible for working out a plan for data management that is aligned with organizational data strategy
Data architect will oversee and will take continual measures to improve and monitor data privacy protection.
Data Architect will manage end-to-end data architecture, from selecting the platform, designing the technical architecture, and developing the application to finally testing and implementing the proposed solution.
Coordinate and collaborate with cross-functional teams, stakeholders, and vendors for the smooth functioning of the enterprise data system.
Data Architect will ensure that data flows and data migration requirements are duly analyzed and documented to achieve data integrity.
Data Architect will work with relevant internal and external subject matter experts to ensure that the solution fulfills business requirements and is successfully implemented within the agreed-upon timeline and budget, in line with the company's standards and best practices.
Data Architect will conduct a continuous audit of data management system performance, refine whenever required, and report immediately any breach or loopholes to the stakeholders.


Requirements

Education:
Bachelor's degree or equivalent, and significant technology related experience.
Master's degree or strong experience equivalent a plus.


Knowledge and Skills:
Architecture and Engineering data leader proficient in modern cloud computing, advanced analytics, architectures, and patterns.
Experienced in introducing and integrating new technologies at scale.
Knowledge of systems development, including system development life cycle, project management approaches and requirements, design and testing techniques
Proficiency in data modeling and design, including SQL development and database administration
Knowledge about MDM tools and Data Governance tools
Knowledge of Collibra, Data Anonymization tools like PKProtect is a plus
Working understanding of the usage of data for data science and machine learning.
Experience with Master Data Management
Experience in Physical and Logical Data Modeling
Experience with DataOps and DevOps
Experience in Metadata capture, management, cataloging and profiling
Experience with ETL /ELT technologies
Experience with catalog data pipeline tools such as AWS Glue.
Experience with products like DBT, Coalesce, Fivetran etc
Experience in implementing data solutions in the cloud. Specific AWS experience is a strong plus.
Knowledge of major cloud based datawarehouse such as Snowflake or AWS redshift
Experience in leading and mentoring data development teams (BI, Data Integration, Data Quality)
Experience in leading Data Governance transformations
Strong knowledge of data related programming.
Some experience with application and middle tier related programming
Conversant with reporting engines such as, for ex., Power BI, SSRS etc. is a plus.
Able to interact with structured and unstructured data and both SQL and NOSQL databases.


Experience:
5 or more years of experience in Enterprise Data Architecture or similar roles with an in-depth understanding of data management, database structure principles, application design, cloud technologies and systems analysis.


Decision Making/Interaction:
The data architect is always solving a problem at both the micro and macro levels to ensure that enormous systems and bulk data is safe, secured and organized.
Data architect will communicate across the enterprise with all relevant stakeholders to understand the scope of the organization's data needs. Data Architect will help formulate data strategy based on discovery of these needs.


Special Requirements:
Applicants for employment in the Mexico must be authorized to work in Mexico and do not need a visa sponsorship now or in future.


About Us

Why Crawford?

Because a claim is more than a number - it's a person, a child, a friend. It's anyone who looks to Crawford on their worst days. And by helping to restore their lives, we are helping to restore our community - one claim at a time.

At Crawford, employees are empowered to grow, emboldened to act and inspired to innovate. Our industry-leading team pioneers new solutions for the industries and customers we serve. We're looking for the next generation of leaders to take this journey with us.

We hail from more than 70 countries and speak dozens of languages, reflecting the global fabric of the audience we serve. Though our reach is vast, we proudly operate as One Crawford: united in purpose, vision and values. Learn more at www.crawco.com.

When you accept a job with Crawford, you become a part of the One Crawford family.

Our total compensation plans provide each of our employees with far more than just a great salary
Pay and incentive plans that recognize performance excellence
Benefit programs that empower financial, physical, and mental wellness
Training programs that promote continuous learning and career progression while enhancing job performance
Sustainability programs that give back to the communities in which we live and work
A culture of respect, collaboration, entrepreneurial spirit and inclusion


Crawford & Company participates in E-Verify and is an Equal Opportunity Employer. M/F/D/V Crawford & Company is not accepting unsolicited assistance from search firms for this employment opportunity. All resumes submitted by search firms to any employee at Crawford via-email, the Internet or in any form and/or method without a valid written Statement of Work in place for this position from Crawford HR/Recruitment will be deemed the sole property of Crawford. No fee will be paid in the event the candidate is hired by Crawford as a result of the referral or through other means."
Oliver Wyman - Sr Data Architect - Mexico City,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18132981,"Descripción
Company:
Oliver Wyman

Description:

About Oliver Wyman

Oliver Wyman is a global leader in management consulting. With offices in more than 70 cities across 30 countries, Oliver Wyman combines deep industry knowledge with specialized expertise in strategy, operations, risk management, and organization transformation. The firm has more than 5,700 professionals around the world who work with clients to optimize their business, improve their operations and risk profile, and accelerate their organizational performance to seize the most attractive opportunities. Oliver Wyman is a business of Marsh McLennan [NYSE: MMC]. For more information, visit www.oliverwyman.com. Follow Oliver Wyman on Twitter @OliverWyman.

Job Overview:

The OWG Tech department is looking to hire a Senior Data Architect with hands-on expertise in Data Lakehouse Architectures. The successful candidate will spearhead the delivery of top-tier solutions while influencing pivotal design choices across the data architecture spectrum. From ingestion and storage to virtualization, data models, performance, and security, your expertise will be instrumental in aligning solutions with Enterprise Architecture principles. Collaboration with cross-functional teams within MMC will be paramount, and your commitment to integrity, ethics, and service excellence will set the standard.

Key Responsibilities:
Design and implement Data Lakehouse architectures that meet business requirements and are scalable, reliable, and secure.
Gather and document Master Data Management (MDM) requirements, liaising with various business stakeholders to develop MDM strategy & architecture patterns.
Analyzing the business requirements, design and develop highly efficient highly scalable Data Ingestion processes.
Design and build modern data pipelines including ETL mappings, being well versed in writing complex SQL queries.
Develop and maintain data models, data dictionaries, and data flow diagrams.
Hands-on working with virtualization, performance tuning, optimization, and scaling solutions from a storage/processing perspective.
Maintain batch processing jobs and respond to critical production issues communicate well with stakeholders on their proposal recommendations.
Conduct research focused on identifying emerging technology solutions that reduce costs, increase efficiencies, provide more value, provide more capabilities, reduce risks, and increase security.
Implement and maintain data security and access controls.
Support the Lead Data Architect by contributing improvements to the Data Architecture strategy, evolving best-practices, templates and processes.
Work collaboratively with Solution Architects, Developers, Testers and other Data Analytics team members to understand constraints and opportunities that may shape and influence Data Architecture deliverables.


Experience:
Bachelor's degree in computer science, computer engineering, electrical engineering, systems analysis or a related field of study, or equivalent job experience.
Significant experience in Data Architecture, with a deep understanding of data models, standards and tools used across architecture and engineering.
At least 2 years' experience designing and implementation Data Lakehouse architectures in Azure or AWS, hands-on experience with Databricks is desirable.
Experience of transforming traditional Data Warehousing approaches to Big Data based approaches.
Demonstrated experience using ETL tools such as IICS/ADF/AWS Glue and SSIS using traditional approaches, experience with more modern real time data pipeline solutions is desirable.
Demonstrated effectiveness in executive presentation and escalation management.
Demonstrated Data modelling and data mapping experience.
Experience with Data virtualization & catalogue is a desirable
Experienced with Agile methodologies.


Skills and Attributes:
Language Fluency: Must possess 100% fluency in English.
Robust Data Solutions: Ability to manage complex data requirements and develop robust code that ensures data availability, integrity, quality, and security.
Holistic Technology Understanding: Strong grasp of enterprise web application development, services-oriented architecture, cloud-based models (SaaS, PaaS, IaaS), and supporting technologies.
Interpersonal Excellence: Outstanding interpersonal skills, teamwork, and facilitation capabilities to effectively collaborate across diverse teams.
Effective Communication: Proficient communicator, adept at conveying concepts and ideas, breaking through barriers, and engaging individuals under pressure.
Stakeholder Management: Skillfully establish credibility with various technical stakeholders, from executives to engineering, operations, security, and quality assurance.
Goal-Oriented Planning: Capable of aligning short-term and long-term goals, both independently and within the team, integrating strategic objectives seamlessly.
Effective Leadership: Set clear goals, prioritize activities, manage risks, and consistently drive projects to completion.
Technology Neutrality: Unbiased towards technology, vendor, or product preferences; prioritize results over personal choices.
Resilience: Unwavering commitment to architectural ideals even in the face of opposition.


Marsh & McLennan Companies is a global professional services firm providing advice and solutions in the areas of risk, strategy and human capital. It is the parent company of a number of the world's leading risk experts and specialty consultants, including Marsh, the insurance broker and risk advisor; Guy Carpenter, the risk and reinsurance specialist; Mercer, the provider of HR and related financial advice and services; and Oliver Wyman, the management consultancy. With over 81,000 colleagues advise clients in 130 countries and annual revenue of nearly $19 billion, Marsh & McLennan Companies provides analysis, advice and transactional capabilities to clients in more than 130 countries. Its stock (ticker symbol: MMC) is listed on the New York, Chicago and London stock exchanges.

Marsh & McLennan Companies offers competitive salaries and comprehensive benefits and programs, career mobility, employee network groups, volunteer opportunities, and other programs. For more information about our company, please visit us at: www.mmc.com. We are committed to embracing a diverse, inclusive and flexible work environment. We aim to attract and retain the best people regardless of their sex/gender, marital or parental status, ethnic origin, nationality, age, background, disability, sexual orientation, gender identity, gender expression or any other characteristic protected by applicable law."
Project Architect - Data Centers,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18168252,"Descripción
Your Role

We are currently seeking a highly experienced Project Architect for Data Centres to collaborate with the entire studio and lead teams to develop design solutions and coordinate through all phases of a project. Leverage your industry expertise, design abilities, and technical acumen to drive projects from concept through construction.

You are a seasoned Architect and recognized contributor to high-profile, design driven projects. Our team is highly creative, collaborative, and dedicated to innovative problem solving and design excellence. You demonstrate innovative thinking, balanced with ability to present real-world technical solutions to new design challenges. You thrive with personal responsibility and accountability but embody and embrace open communication and team-oriented success.

You will work closely with the entire team, within our collaborative and supportive team environment to develop projects from conceptual design through execution. A well-rounded and thoughtful approach to design forms the foundation of our practice and our clients hire us because they believe in the transformative power of design.

What You Will Do

Manage the design and delivery for a range of project types in a variety of settings, including high-rise, commercial-office building led, or mixed-use.
Lead project meetings and presentations; ensure client is adequately briefed on project progress.
Develop a comprehensive understanding of clients' program requirements and standards and policies for completion to share with your project teams.
Lead the communication between the project team, clients, contractors and consultants.
Actively lead a range of project team sizes for successful delivery.
Assist in establishing overall project budgets and milestone schedules in coordination with Design Manager and Design Director.
Ensure all work is carried out to the requirements of the client, with the design team working to the correct specifications and delivering a high quality and timely product to the client.
Anticipate and resolve complex technical and design issues as they arise during document preparation and construction administration.
Collaborate with design team, clients, consultants, contractors, fabricators, regulatory agencies and other vendors to meet overall project objectives.
Provide design and technical guidance and innovative solutions to resolve design and technical challenges.
Lead more junior members of staff: motivate and ensure quality of work; ensure clear communication; understand the skills of the team and wider resources within the office.
Be an advocate for Gensler sustainability commitments internally and externally.
Make sustainability an integral part of every project.
Define project sustainability targets in collaboration with the client and the project team at the start of each project.
Understand clients ESG goals and work with project teams towards achieving them.
Support and encourage team members to pursue sustainability learning.
Involvement in office, regional and sector business development initiatives.
Contribute to office activities, initiatives, and learning programs.


Your Qualifications
Bachelor of Architecture, Interior Architecture, or foreign equivalent
6+ years of project experience in an architectural practice with experience in several practice areas.
Extensive portfolio of work, preferably in Data Centers, but also across various practice areas.
Demonstrable experience in large projects with complex stakeholders.
Ability to maintain and nurture existing client relationships and build new ones.
Proficiency in REVIT, Sketch Up, and construction administration softwares.
100% bilingual English/Spanish, well written, with excellent verbal communication skills.
Working knowledge of national and international building codes, standards, building construction, and building structures
Mid-scale to large construction experience
Experience with the entire project lifecycle, through post-occupancy
Strong leadership, communication, and relationship management skills
Construction documentation and/or design detail development experience
Ability to handle difficult situations with tact, grace, and emotional intelligence.
Experience leading, managing, and mentoring multiple project teams.
Proven fiscal accountability and responsibility on various project types.
Must be able to maintain existing client relationships and build new client relationships.
Excellent analytical and problem-solving skills
Strong organizational skills


Life at Gensler

At Gensler, we are as committed to enjoying life as we are to delivering best-in-class design. From curated art exhibits to internal design competitions to ""Well-being Week,"" our offices reflect our people's diverse interests.

As part of the firm's commitment to licensure and professional development, Gensler offers reimbursement for certain professional licenses and associated renewals and exam fees. In addition, we reimburse tuition for certain eligible programs or classes. We view our professional development programs as strategic investments in our future."
Architect - Azure Data,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18362545,"Descripción
We are 3PILLAR GLOBAL

Position within México.

We build breakthrough software products that power digital businesses. We are an innovative product development partner whose solutions drive rapid revenue, market share, and customer growth for industry leaders in Software and SaaS, Media and publishing, information services, and retail.

Our key differentiator is our product mindset. Our development teams focus on building outcomes, and all of our team members around the globe are trained on the product mindset's core values: - time to Value, Solve For Need, and Excel at Change. Our teams apply this mindset to build digital products that are customer-facing and revenue-generating. Our business-minded approach to agile development ensures that we align with client goals from the earliest conceptual stages through market launch and beyond.

RESPONSIBILITIES
Help the client to define the Products Architecture to support Tech Stack and Roadmap.
Creation of a Large Language Model from historical forms, prior due-dilegence reports, business entity research content from internal and external sources, and potentially other structured and un-structured content sources.
Experience with Microsoft Fabric (Azure Data Services or alternative platform equivalent services) to injest (streaming and pipelines), process, enhance, and persist data.
Experience with data stream analytics tools.


REQUIREMENTS
Experience in process automation.
Business workflow automation systems (especially multi-vendor B2B interfaces).
Data processing.
ETL.
Data nomraliation/standardization.
Data analytics and BI platforms, Azure cloud hosting, Azure Synapse Analytics (and/or other data/analytics/BI offerings).

Nice to have:
Platform modernization (especially data processing platforms in complex heterogenous tech environments).
Healthcare business domain knowledge (especially in Revenue Cycle Management (RCM)).


BENEFITS
Vacations. According to the law from your first anniversary.
Discretionary Time Off (employees are able to take time off when necessary)*
26 days of Christmas bonus
Food coupons
Major medical insurance
Life Insurance (optional)
Savings box (optional)
Law benefits: IMSS, Afore, Infonavit.
Career plan that will let you grow and plan for the future
Home Office
Internal Trainings
Support with external trainings and certifications
Referrals bonus


#Li-remote
>"
Pre-sales Architect Data and AI,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18221523,"Descripción
Why SoftwareOne?

Success at SoftwareOne is not defined by what you do for yourself, but by what you deliver for our customers, the business and for the employees around you. SoftwareOne employees are energized, agile and are laser focused on delivering world class Customer Satisfaction and results. Our leaders motivate and inspire their teams and provide a working environment that delivers incredible levels of Employee Satisfaction. We are Humble. Our leaders operate with a high level of Discipline but can work at Speed manage change in a global economy. We are a leading global provider of end-to-end software and cloud technology solutions, headquartered in Switzerland. Our 8,700 employees support our approximately 65,000 customers in their digital transformation.

The role

Join our Services Delivery team! We look forward to learning more about you and exploring how, working together, we can build an exceptional team.

Pre-sales Architect

Data & AIFull Time | Location: Mexico City | Hybrid Model

What will your day-to-day look like?
Collaborate with stakeholders to understand business objectives and requirements, and translate them into data and AI solution designs.
Design and architect end-to-end data pipelines, including data ingestion, storage, processing, and visualization components.
Develop and implement machine learning models and algorithms to extract insights and drive decision-making.
Work closely with data engineers and data scientists to ensure the reliability, scalability, and performance of data and AI solutions.
Evaluate and recommend appropriate technologies, tools, and frameworks to support data and AI initiatives.
Provide technical guidance and mentorship to team members on data architecture and AI best practices.
Collaborate with cross-functional teams, including software developers, business analysts, and project managers, to ensure successful delivery of data and AI projects.
Stay updated on the latest trends and advancements in data science, machine learning, and artificial intelligence, and assess their potential impact on our solutions and services.
Communicate effectively with stakeholders, including presenting technical concepts and solution designs to non-technical audiences.

#LI-GR1

What we need to see from you

The skills below will make you successful at this job, but we DO NOT expect to find all of them in every candidate.

What do we expect from you?
Bachelor's degree in Computer Science, Software Engineering, or related field.
Minimum of 5 years of proven experience.
At least 3 years of experience working in software development within cloud platforms and minimum 2 years of experience working in Pre-sales architecture.
Proficiency in designing architectures focused on APIs and application integration.
Advanced knowledge of cloud computing services, particularly AWS and Azure.
Experience in defining architectures within AWS, leveraging AWS Data Services such as Amazon EMR, Amazon RedShift, Amazon Quicksight, and Amazon Glue DataBrew.
Expertise in designing and implementing Data Warehouses, Datamarts, and Datalakes.
In-depth understanding of both relational and non-relational databases.
Competence in data integration, automation, and monitoring.
Ability to translate business requirements into scalable and efficient technical solutions.

Behavioral Skills:
Effective communication skills to interact with clients and team members.
Strong problem-solving abilities to address complex technical challenges.
Adaptability to work in a dynamic and fast-paced environment.
Collaboration skills to work effectively within cross-functional teams.
Attention to detail to ensure accuracy and quality in architectural designs.

Desirable Qualifications:
Advanced English Proficiency: B2 level minimum.
Experience in architecture modernization and familiarity with DevOps and DevSecOps practices.
Relevant certifications in Data Science, Machine Learning, or Artificial Intelligence.
Experience with cloud-based data platforms such as AWS, Azure, or Google Cloud.
Advanced knowledge of programming languages such as Python or R.
Experience with big data technologies like Hadoop, Spark, or Kafka.
Work experience with containers and basic infrastructure knowledge.
Proficiency in consuming services from AWS and Azure, including the ability to work with cloud calculators.
Familiarity with Serverless computing and continuous monitoring of applications.


Why should you join our team?
Experience a unique corporate culture where values are upheld to foster an
inclusive and supportive work environment.
Participate in employee recognition programs to celebrate achievements and contributions.
Access a wide range of training and development opportunities to enhance your skills and expertise.
Enjoy a healthy work-life balance with flexible working arrangements.
Benefit from our referral bonus program and other employee perks.
Engage in multicultural interactions within a diverse team.
Contribute to meaningful initiatives that leverage data and AI for societal impact.
Participate in corporate events and access the latest technologies to drive innovation.
Join a collaborative environment where your ideas and expertise are valued, and career growth is encouraged.

At SoftwareOne, we are committed to promoting equal employment opportunities for all individuals, regardless of race, color, religion, gender, sexual orientation, gender identity, age, national origin, disability, or any other characteristic protected by applicable laws.

Job Function

Software & Cloud Services"
"Solution Architect, Data - Analytics, Tech Consulting",https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18125538,"Descripción
RH: Marisol Zavala
Position: Solution Architect
Location: Mexico City
Industry - Sector: Capgemini

What you'll do?
+15 years of experience in consulting and Cloud technologies, Data, Big Data, data storage, data analysis projects and/or any project related to information management.
Previous experience building large-scale enterprise data architectures using commercial and/or open-source data analytics technologies.
Strong knowledge of data manipulation languages such as Spark, Scala, SQL, PySpark to create and maintain complex queries, streaming and real-time data pipelines.
Experience interacting with both technical and non-technical stakeholders.
Solid consulting experience, including direct interaction with clients.
Demonstrable cloud experience with Azure, GCP or AWS.
Good knowledge in DevOps and/or MLOps engineering.

What you'll bring:
Ability to estimate complexity, effort and cost.
Ability to produce customer-ready solution architecture, understandable business presentations and good communication skills to lead and execute workshops.
Data modeling and architecture skills, including a solid foundation in data warehousing concepts, data normalization, and modeling.
A deep understanding of cloud solutions (Azure and/or GCP) and experience integrating into traditional hosting/delivery models.
Solid knowledge in data governance & management, data mesh, data vault 2.0, delta lake, DWH.
Good fundamentals on security integration, including Kerberos authentication, SAML, and data security and privacy, such as data masking and tokenization techniques.
Soft Skills: Work under pressure, quality at work and results-oriented


What can YOU expect in a career with Capgemini?
Working in a team environment, Consultants will focus on the analysis, design and development of technology-based solutions for Capgemini's clients.
You will work alongside technical, functional and industry specialists to assist with the development, implementation and integration of innovative system solutions including methods, techniques and tools.
You will contribute to client satisfaction by providing timely and responsive value-added services and work products.
Capgemini offers a competitive compensation and benefits package.
Headquartered in Paris, France, Capgemini has a presence of more than 340 thousand professionals in Mexico distributed among 3 sites located in Mexico City, Monterrey and Aguascalientes. A deeply multicultural organization.
Capgemini has developed its own way of working, the Collaborative Business ExperienceTM, and draws on Rightshore, its worldwide delivery model.


You will love this job because
Capgemini focuses on giving each new hire a YOU-nique experience through our recruitment process and on-boarding program, as well as by helping you to build your own career and professional skills foundation.
Capgemini provides a collaborative environment that embodies and holds the following stated values close to heart: Honesty, Boldness, Trust, Freedom, Team Spirit, Modesty, and Fun.
Capgemini cultivates an atmosphere for development that enables YOU to be hands-on, planning for your growth, both horizontally and vertically.

""At Capgemini Mexico, we aim to attract the best talent and are committed to creating a diverse and inclusive work environment, so there is no discrimination based on race, sex, sexual orientation, gender identity or expression, or any other characteristic of a person. All applications welcome and will be considered based on merit against the job and/or experience for the position.""

Ref: 1666266

Fecha: 13 feb 2024

Instalación: Experiencia profesional

Tipo de puesto: Contrato por tiempo indeterminado - full time

Ubicación:"
Sr. Staff Architect - Enterprise Data (Remote/Flexible),https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18352055,"Descripción
Insulet started in 2000 with an idea and a mission to enable our customers to enjoy simplicity, freedom and healthier lives through the use of our Omnipod® product platform. In the last two decades we have improved the lives of hundreds of thousands of patients by using innovative technology that is wearable, waterproof, and lifestyle accommodating.

We are looking for highly motivated, performance driven individuals to be a part of our expanding team. We do this by hiring amazing people guided by shared values who exceed customer expectations. Our continued success depends on it!

Job Title: Sr. Staff Architect - Enterprise Data

Department: Enterprise Architecture

FLSA Status: Exempt

Insulet Corporation (NASDAQ: PODD) is an innovative medical device company dedicated to simplifying life for people with diabetes and other conditions through its Omnipod product platform. The Omnipod® Insulin Management System provides a unique alternative to traditional insulin delivery methods. With its simple, wearable design, the disposable and waterproof Pod provides up to three days of non-stop insulin delivery, without the need to see or handle a needle. Insulet's latest innovation, the Omnipod® 5 Automated Insulin Delivery System, is a tubeless automated insulin delivery system, integrated with a continuous glucose monitor to manage blood sugar with no multiple daily injections, zero finger sticks, and is fully controlled by a compatible personal smartphone. Insulet also leverages the unique design of its Pod by tailoring its Omnipod technology platform for the delivery of non-insulin subcutaneous drugs across other therapeutic areas.

Studies have demonstrated the clinical and lifestyle advantages of insulin pump therapy over multiple daily insulin injections (MDI). However, many people still choose MDI therapy largely due to the complexity, cost, and inconvenience of conventional pump technology. The Omnipod is a discreet and easy-to-use system that eliminates many of the issues associated with conventional pumps. By breaking down the barriers to insulin pump therapy, Insulet hopes to provide both a superior treatment option and life-long health benefits for people with insulin-requiring diabetes

Insulet was founded in 2000 with the mission to improve the lives of people with diabetes and enable customers to enjoy simplicity, freedom, and healthier lives through innovative technology. The Company's world headquarters and state-of-the-art automated manufacturing facility are located in Acton, Massachusetts with global offices in the U.K., France, Germany, Netherlands, Canada, Mexico, Australia, and the United Arab Emirates. Omnipod products are available in 24 countries around the world.

Insulet recently concluded its seventh consecutive year of 20% or more revenue growth, and more than doubled its intellectual property portfolio over the last year. Insulet is proud to be recognized as a 2022 Top Workplace USA; awarded Top Workplaces Cultural Excellence Award for remote work; recognized as a Great Place to Work® in four international locations in 2023; and ranked as one of America's most responsible companies by Newsweek.

For more information, visit: insulet.com and omnipod.com.

Position Overview:

The Sr. Staff Architect - Enterprise data will be responsible for establishing and owning Insulet's overall data and data integration strategies and roadmaps. This is a full-time exempt position reporting to the Vice President of Enterprise Architecture.

Responsibilities
Define data strategy by identifying the business needs for data, defining the data's capabilities, and developing a roadmap for the development of data management systems
Design and implement data architecture
Ensure that operations is properly monitoring the data's performance and resolving issues
Advocate for data-driven decision making includes educating business users on the value of data, and providing them with the tools and resources they need to make data-driven decisions.
Ensure data security and compliance with all applicable regulations
Drive data innovation by identifying new technologies and solutions that can be used to improve the data's value
Collaborate with stakeholders throughout the data's development and lifecycle includes working with business users, technical architects, and other stakeholders to ensure that the data meets the needs of all stakeholders


Key Decision Rights (if applicable)
Data and Data Integration Architectures


Required Skills and Competencies
Deep understanding and strong development experience with distributed data processing frameworks such as Hadoop, Spark, Storm, and others
Expert knowledge and deep hands on experience with data warehouse, data lake, and delta lake / lake house
Excellent design and development experience with SQL and NoSQL databases, OLTP and OLAP databases
Significant experience with data replication and real-time data ingestion technologies such as MS CDC, GoldenGate, Kafka, Flink, Kinesis, etc.
Experience in design and development of custom ETL pipelines using SQL, scripting languages (Python/Shell/Golang) and well defined API's
Experience with the needs of data science teams performing AI/ML model development and deployment
Experience with popular BI/Reporting tools and the integration necessary to support them
Experience in leading or being a lead contributor in data governance teams and processes
Proficient in dimensional modeling concepts and techniques
Good programming skills in Java, Scala or Python
Excellent verbal and written communication skills


Required Leadership Skills & Behaviors:
A passionate, inspirational leader who leads with an enterprise mindset, challenges the status quo, and can align their organization behind a clear vision and strategy
Has strong emotional intelligence and ability to engage and influence others through change to advance new ways of working


Education and Experience
Engineering Bachelor's Degree or equivalent experience
10+ years of relevant IT or product development experience
Experience in MedTech, Life Sciences, or other regulated industry a plus


Additional Information
The position can be remote, hybrid or in-person at our Tijuana Mexico office.
Travel is estimated at 10% but will flex depending on business need.


NOTE: This position is eligible for 100% remote working arrangements (may work from home/virtually 100%; may also work hybrid on-site/virtual as desired). #LI-Remote

Additional Information:
The US base salary range for this full-time position is $0.00 - $0.00. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position in the primary work location in the US. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your Talent Acquisition Specialist can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits.

At Insulet Corporation all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

(Know Your Rights)"
"Arquitecto/a de datos AI Factory (Miguel Hidalgo, Ciudad de México)",https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18352893,"Descripción
Área:
ENGINEERING

Inscríbete hasta:
4/14/2024

Sociedad:
243

¿Qué estamos buscando?

Talento STEM en el grupo BBVA ¿Que te ofrecemos?
Formarás parte de un equipo de más de 22.000 expertos en Tecnología, en 25 países, cuyo propósito es llevar al banco más allá gracias a la tecnología.
Participarás en alguno de los aprox.1.800 proyectos punteros de tecnología que realizamos anualmente y que tienen un impacto positivo en 85 millones de personas.
Trabajarás con un abanico muy amplio de tecnologías, desde las más experimentadas, hasta las más disruptivas: 46 lenguajes de programación diferentes, 201 plataformas de desarrollo,etc.
Colaborarás con nuestros socios tecnológicos -Microsoft, Google, AWS, Salesforce, IBM, RedHat, Telefónica, Cisco, Genesys, etc.
Desarrollarás proyectos innovadores de Desarrollo, Arquitectura, Seguridad, Infraestructura, Data. Más información.
Aprenderás en tu proyecto, trabajarás con referentes y podrás acceder a toda la oferta formativa de BBVA y a Ninja project, plataforma formativa gamificada con una comunidad de más de 11.000 participantes con más de 2.000 charlas, 1300 talleres y 48 hackathones organizados.


Si te interesa formar parte de un equipo cuya principal responsabilidad reside en desarrollar y operar soluciones tecnológicas y procesos seguros para mejorar la experiencia de nuestros clientes, ofrecer mejores productos y servicios y garantizar la continuidad operativa de nuestro banco, ¡esta oportunidad es para ti!

La vacante tiene un esquema laboral de asistencia híbrida, con sede en el Corporativo Parques Polanco, Ciudad de México.

Buscamos a personas que cumplan los siguientes requisitos:

Conocimientos:

- Diseño y desarrollo de aplicativos basados en activos de datos:
- BigData
- DataWarehouse
- ODS
- Business Intelligence
- Data Mining
- Desarrollo de Soluciones de Datos en la nube
- Gobierno de Datos

Escolaridad:

- Licenciatura-Ingenieria en: Sistemas / Matemáticas / Ciencia de Datos / Informática

- Postgrado y/o Maestria en Ciencias de Datos / Machine Learning / Maestría en Administración de Negocios / Maestría en BigData / Maestría en Análisis de datos y estadística

Competencias:
Toma de decisiones basada en datos.
Capacidad de análisis para plantear soluciones.
Trabajo en equipo.
Proactividad.
Adaptación al cambio.
Trabajo bajo presión.
Aprendizaje continuo.

Si te encuentras interesado/a, postúlate dando clic en ""Solicitar ahora"". No olvides adjuntar tu CV actualizado.

Aspectos generales

En BBVA llevamos más de 80 años trabajando para nuestros clientes.
Nuestro propósito es poner al alcance de todos las oportunidades de esta nueva era.
Este propósito refleja nuestro papel facilitador para ofrecer a nuestros clientes las mejores soluciones bancarias, ayudarles a tomar las mejores decisiones financieras e impactar positivamente en su vida.

La Dirección General de Engineering es pieza fundamental dentro de la organización del Grupo BBVA México. Participamos como un solo equipo con las demás direcciones generales, aportando valor en la transformación de nuestro banco y de nuestro grupo, nuestra principal responsabilidad reside en desarrollar y operar soluciones tecnológicas y procesos seguros para mejorar la experiencia de nuestros clientes, ofrecer mejores productos y servicios y garantizar la continuidad operativa de nuestro banco.

Uno de los puestos clave para el alcance de nuestras metas es el de data de soluciones tecnológicas. Te contamos más sobre las actividades de esta vacante:

Principales responsabilidades

- Colaborar con científicos de datos y otros profesionales de IA para aumentar los esfuerzos de transformación digital al identificar y probar casos de uso analizando la viabilidad de los casos de uso junto con el diseño arquitectónico con los equipos de negocio y traduciendo la visión de los líderes de negocio en una implementación técnica realista.

- Alinear la implementación técnica de los requerimientos existentes y futuros traduciendo múltiples ideas de las partes interesadas o usuarios (usuarios de negocio, científicos de datos, seguridad de la información, ingenieros y analistas de datos, y aquellos en operaciones de TI) para el desarrollo de procesos de extracción, transformación y carga de datos para su explotación en terminos de Inteligencia Artificial y productos basados en las necesidades de negocio.

- Auditar las herramientas y prácticas de IA a través de datos, modelos e ingeniería de software con un enfoque en la mejora continua garantizando un mecanismo de retroalimentación para evaluar los servicios de Inteligencia Artificial y apoyar a la recalibración del modelo para participar en el entrenamiento de los modelos y algoritmos correspondientes

- Evaluar el apego de la Arquitectura de Inteligencia Artificial con base a las modelos implementados para su evolución o madurez dentro de la organización asegurando su valor a los usuarios y robustenciendo la arquitectura de Inteligencia Artificial para la organización asegurando el valor que da al banco mediante la vigencia de la arquitectura de Inteligencia Artificial con respecto a las necesidades establecidas

Retos del puesto

Analiza distintas fuentes de información para crear productos sostenibles, proporcionar servicios o realizar predicciones de futuro que permiten a la organización anticiparse. Crea una cultura de toma de decisiones basada en datos.

Si quieres saber más sobre qué es lo que hacemos en BBVA en Tecnología, pulsa aquí: https://bbva.csod.com/ux/ats/careersite/27/home?c=bbva

Trabajar en BBVA

BBVA es una empresa global con más de 160 años de historia que opera en más de 25 países en los que damos servicio a más de 81 millones de clientes. Somos más de 110.000 profesionales que trabajamos en equipos multidisciplinares y diversos.

En BBVA estamos a la cabeza de la transformación que se está produciendo en el sector bancario, cuestionando lo establecido, para hacer la vida más fácil a nuestros clientes.

Formar parte de BBVA significa desarrollar tu carrera en la empresa que lidera la transformación del sector financiero.

Banca responsable

Nuestro modelo de banca responsable aspira a lograr una sociedad más inclusiva y sostenible. Porque el futuro de las finanzas es financiar el futuro.

Empezamos con el espíritu de ayudar a otros a tomar las mejores decisiones financieras. Ese espíritu permanece hoy en día y nos anima a seguir avanzando, dando prioridad a la innovación y a la transformación digital y poner al alcance de todos las oportunidades de esta nueva era.

Diversidad

En BBVA creemos que contar con un equipo diverso, nos hace ser un mejor banco.

Por este motivo apoyamos activamente la diversidad, la inclusión y la igualdad de oportunidades sin importar raza, sexo, edad, religión, orientación sexual, identidad de género, expresión de género, entre otras. Cultivamos un ambiente de trabajo colaborativo e inclusivo que nos permita mostrar lo mejor de cada persona.

Nuestros valores

Nuestros valores definen nuestra identidad y son la palanca que nos impulsan a hacer realidad nuestro propósito y nos guían en todas nuestras acciones y decisiones.

El cliente es lo primero

Pensamos en grande

Somos un solo equipo"
Arquitecto de Datos,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18347616,"Descripción
¿Quiénes somos?

Somos una empresa líder de gestión de capital humano y servicios tecnológicos con más de 15 años en el mercado nacional y Centro América, ofreciendo un valor agregado y solución a los procesos de consultoría de TI, atracción de talento, pruebas de Software y centro de desarrollo.

Candidatura
En Getecsa nos encontramos en búsqueda de un Arquitecto de Datospara laborar con uno de nuestros clientes.

Requisitos:
Fundamentos en Big Data, Data Lakes.
Arquitectura Data Driven.
Tecnologías para el procesamiento y Almacenamiento de Datos: Cloudera, Hadoop,
Spark, Kafka, Hive, Impala, Base de Datos NoSQL .
Patrones de Arquitectura (LAMBDA y KAPPA)
Metodologías de desarrollo para DWH y Data Lake
Conocimiento de Estándares: DAMMA, TOGAF
Amplia experiencia en modelado de datos (Lógico y físico)
Diseño físico y funcional en CRM (Outbound + Inbound)
Implementación de integraciones con Redes sociales Ingesta y publicación (Google ADS, Facebook)
Experiencia en programación: Java, Scala , Python .
Adicional en software: Conocimiento en plataforma y Tecnología de datos Cloud (Azure Data Bricks, GCP) Patrones de arquitectura de datos.
Experiencia en ETL Tradicionales (ODI, SSIS, IBM)
Diseño y experiencia en herramientas de BI Open y Mercado.
Ofrecemos:
¡SUELDO COMPETITIVO! ¡Prestaciones de ley!.
Seguimiento, claridad y honestidad en los procesos.
Amabilidad y empatía."
Sr. Data Modeler - EY Global Delivery service,https://www.occ.com.mx/empleos/de-data-architect/en-Mexico/?page=5&jobid=18124150,"Descripción
At EY, you'll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we're counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.

We are looking a talented data modeler to assist with the analysis, design, and implementation of information solutions. As a data modeler, you will be working closely with data stewards, data architects, business architects, and solution architects, to capture business requirements in logical data models. You will work with DBA's to ensure corresponding physical data models map to the logical data models.

To ensure success as a data modeler, you should have in-depth knowledge of 3NF and dimensional logical data modeling methods as well as excellent communication skills. Ultimately, the data modeler should be able to detail logical models that align with physical data models produced based on those models and work to reduce data redundancy, streamline data movements, and improve enterprise information management.

Responsibilities:
Analyze and translate business requirements into conceptual and fully detailed logical data models.
Create logical data models based on existing applications and databases.
Contribute to ongoing updates to data modeling standards and guidelines.
Work with business architects, data architect, and data stewards to capture business requirements in a Logical Data Model.
Contribute to assessing the appropriate data platform(s) for solutioning efforts.
Evaluate implemented application databases for variances from our modeling standards.
Evaluate physical data models to ensure they align to the corresponding logical data models.

Requirements:
Must have a minimum of 5 years of hands-on experience with 3NF logical, dimensional, and physical data modeling.
Bachelor's degree preferred.
Knowledge of:
Metadata management and related tools.
Relational and document database technologies.
Business process modeling preferred.
Physical data modeling for document stores preferred.
ERWIN preferred.
Strong interpersonal skills and excellent communication and presentation skills.

What we offer

We offer a competitive compensation package where you will be rewarded based on your performance and recognized for the value you bring to our business. In addition, our rewards package includes a range of programs and benefits designed to support your physical, financial and social well-being. Plus, we offer:
Continuous learning: You'll develop the mindset and skills to navigate whatever comes next.
Success as defined by you: We'll provide the tools and flexibility, so you can make a meaningful impact, your way.
Transformative leadership: We'll give you the insights, coaching and confidence to be the leader the world needs.
Diverse and inclusive culture: You'll be embraced for who you are and empowered to use your voice to help others find theirs.


The exceptional EY experience. It's yours to build.

EY | Building a better working world

EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.

Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.

Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today."
