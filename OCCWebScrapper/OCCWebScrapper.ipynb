{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from selenium import webdriver\n",
    "\n",
    "# Starting/Stopping Driver: can specify ports or location but not remote access\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "\n",
    "# Manages Binaries needed for WebDriver without installing anything directly\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Allows searchs similar to beautiful soup: find_all\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Try to establish wait times for the page to load\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# Wait for specific condition based on defined task: web elements, boolean are examples\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Used for keyboard movements, up/down, left/right,delete, etc\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Locate elements on page and throw error if they do not exist\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup chrome options\n",
    "\n",
    "# Create service\n",
    "webdriver_service = Service(ChromeDriverManager().install())\n",
    "option= webdriver.ChromeOptions()\n",
    "driver=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to make the search, the link and the job location\n",
    "pagination_url = \"https://www.occ.com.mx/empleos/de-{}/en-{}/?page={}\"\n",
    "pagination_url_id = \"https://www.occ.com.mx/empleos/de-{}/en-{}/?page={}&jobid={}\"\n",
    "location='Mexico'\n",
    "\n",
    "# Selenium selectors: used to find an element in the web page, xpath selector, css selector, class name selector\n",
    "xpath_resultados1 = \"/html/body/main/div[4]/aside/div/div[1]/p\"\n",
    "xpath_resultados2 = \"/html/body/div[1]/div[1]/div[7]/div/div[1]/div[1]/div[1]/p\"\n",
    "xpath_noresuultados = \"/html/body/main/div[3]/div/div/div[1]/h1\"\n",
    "cssSelector_Jobcard = \"div[id^=jobcard]\"\n",
    "cssSelector_jobinfo = \"body > main > div.sm\\:container.sm\\:mx-auto.grid.grid-cols-12 > div > div > div.mb-8.break-words\"\n",
    "cssSelector_jobinfo2= \"#jobbody\"\n",
    "cssSelector_JobcardCompany = \"div[class=\\\"fresnel-container fresnel-greaterThanOrEqual-sm\\\"][class=\\\"fresnel-greaterThanOrEqual-sm\\\"]\"\n",
    "className_JobcardCompany2 = \"fresnel-container fresnel-greaterThanOrEqual-sm\"\n",
    "className_JobcardCompany3 = \"\\\"fresnel-greaterThanOrEqual-sm\\\"\"\n",
    "cssSelector_jobcardTitle = \"#{} > div > h2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occupations to search\n",
    "joblist_infocomm = [\n",
    "    \"ict sales professional\",\n",
    "    \"marketing manager\",\n",
    "    \"product analyst\",\n",
    "    \"product manager\",\n",
    "    \"product designer\",\n",
    "    \"business intelligence professional\",\n",
    "    \"infrastructure engineer\",\n",
    "    \"computer systems analyst\",\n",
    "    \"software infrastructure architect\",\n",
    "    \"web developer\",\n",
    "    \"software developer\",\n",
    "    \"app developer\",\n",
    "    \"user interface designer\",\n",
    "    \"software engineer\",\n",
    "    \"software architect\",\n",
    "    \"software quality assurance analysts and testers\",\n",
    "    \"embedded systems engineer\",\n",
    "    \"web and digital interface designers\",\n",
    "    \"database infrastructure engineer\",\n",
    "    \"network architect\",\n",
    "    \"database administrator\",\n",
    "    \"database architect\",\n",
    "    \"network and computer systems administrator\",\n",
    "    \"artificial intelligence engineer\",\n",
    "    \"machine learning engineer\",\n",
    "    \"data science engineer\",\n",
    "    \"data analyst\",\n",
    "    \"data scientist\",\n",
    "    \"artificial intelligence scientist\",\n",
    "    \"data architect\",\n",
    "    \"ict security specialist\",\n",
    "    \"it security operations\",\n",
    "    \"information security analyst\",\n",
    "    \"product security and it security integration specialist\",\n",
    "    \"product risk specialist\",\n",
    "    \"security architect\",\n",
    "    \"database support engineer\",\n",
    "    \"data center operations engineer\",\n",
    "    \"support systems engineer\",\n",
    "    \"computer network support specialist\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findJobElements: recibe the h2 element, save the text to jobTitleList, clicks the\n",
    "# job card to find the description, if the description is found using the first selector, saves all the text in decriptionList\n",
    "# if its not found with the first selector it will search the element with the selector and do the same to save the text\n",
    "# returns: decriptionList,jobTitleList,jobUrlList\n",
    "def findJobElements(h2,decriptionList,jobTitleList,jobUrlList):\n",
    "    titulo = h2[0].text\n",
    "    jobTitleList.append(titulo)\n",
    "    try:\n",
    "        h2[0].click()\n",
    "        jobUrl = driver.current_url #obtain the current url of the page and save it to jobUrlList\n",
    "        jobUrlList.append(jobUrl)\n",
    "        time.sleep(1.3)\n",
    "        #encuentra info de jobs\n",
    "        descripcion = driver.find_elements(by=By.CSS_SELECTOR, value = cssSelector_jobinfo)\n",
    "        if len(descripcion) > 0:\n",
    "            for descripText in descripcion:\n",
    "                decriptionList.append(descripText.text)\n",
    "        else:\n",
    "            time.sleep(0.5)\n",
    "            descripcion = driver.find_elements(by=By.CSS_SELECTOR, value = cssSelector_jobinfo2)\n",
    "            if len(descripcion) > 0:\n",
    "                for descripText in descripcion:\n",
    "                    decriptionList.append(descripText.text)\n",
    "            else:#NoDesciptionFound\n",
    "                decriptionList.append(\"\")#If no description is found it will add an emtpy string to the list\n",
    "    except ElementClickInterceptedException:\n",
    "        print(\"Error: ElementClickInterceptedException\") # Handling the exception if the click fails \n",
    "        jobUrlList.append(\"error\")\n",
    "        decriptionList.append(\"error\")\n",
    "    return decriptionList,jobTitleList,jobUrlList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain_descriptions: search the h2 with the job title with the ids if not found search the h2 by the tag name \"h2\": return 3 list, titlesList, urlList and descriptionList\n",
    "def obtain_descriptions(jobsFoundList,jobsIds):\n",
    "    #Lists to save the jobs information\n",
    "    decriptionList = []\n",
    "    jobTitleList = []\n",
    "    jobUrlList = []\n",
    "    # For each job card it will find the title in the job card by id, if found calls the function findJobElements, if not found search the h2 by the tag name \"h2\"\n",
    "    for jobcard,id_html in zip(jobsFoundList,jobsIds):\n",
    "        soloId = id_html.split(\"-\")[1]\n",
    "        soloId=soloId.strip()\n",
    "        titulo = \"\"\n",
    "        cssSelector = cssSelector_jobcardTitle.format(id_html)\n",
    "        h2 = jobcard.find_elements(by=By.CSS_SELECTOR,value=cssSelector)\n",
    "        if len(h2) > 0:\n",
    "            decriptionList,jobTitleList,jobUrlList = findJobElements(h2,decriptionList,jobTitleList,jobUrlList)\n",
    "        else:\n",
    "            time.sleep(0.5)\n",
    "            h2 = jobcard.find_elements(by=By.TAG_NAME,value=\"h2\")\n",
    "            if len(h2) > 0:\n",
    "                decriptionList,jobTitleList,jobUrlList = findJobElements(h2,decriptionList,jobTitleList,jobUrlList)\n",
    "            else:\n",
    "                print(\"No Job Title to click\")\n",
    "    return jobTitleList, decriptionList, jobUrlList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prepareDataFrame function is given the urls, titles and jobs descriptions to create a pandas df and save it to a CSV file\n",
    "# the csv title will be the occpation and the date of the search, example: web-developer-2024-04-16.csv\n",
    "def prepareDataFrame(titlesList,urlsList,descriptionsList, occup):\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    csvRoute = \"CSVInfo2V2/\"\n",
    "    csvFileName = csvRoute + occup + \"-\" + str(current_date) +\".csv\"\n",
    "    df = pd.DataFrame({'Job_Title': titlesList, 'Job_Description': descriptionsList, 'Job_Url': urlsList})\n",
    "    df.to_csv(csvFileName, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_npags, given the number of results found by the search it will calculate how many pages the scrapper will search\n",
    "def calculate_npags(num_resultados, max_resultados=100):\n",
    "    total_pages = math.ceil(num_resultados / 20)\n",
    "    total_pages = min(total_pages, math.ceil(max_resultados / 20))\n",
    "    return total_pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap_job_infos, given the occupation, the scrapper visit the url with de occupation an the location given\n",
    "# try to find the number or results of the search and then calculate tje pages\n",
    "# if the number of pages is 1 try to find the job cards, to obtain the descriptions, titles and urls, to prepare the df\n",
    "# if nPags > 1 it will iterate through pages saving the job cards and obtaining the job information and saves it to the respective list\n",
    "# to create the df\n",
    "def scrap_job_infos(job_):\n",
    "    #print(f\"EMPLEO: {job_}\")\n",
    "    driver.get(pagination_url.format(job_,location,1))\n",
    "    time.sleep(1.5)\n",
    "    resultados = driver.find_elements(by=By.XPATH, value=xpath_resultados1)\n",
    "    if len(resultados) == 0:\n",
    "        resultados = driver.find_elements(by=By.XPATH, value=xpath_resultados2)\n",
    "    total=0\n",
    "    nResultados = int((resultados[0].text.split(\" \")[0]).replace(\",\",\"\")) if resultados else int(\"0\")\n",
    "\n",
    "    #print(f\"Resultados encontrados: {nResultados}\\n\")\n",
    "    nPags = calculate_npags(nResultados, max_resultados=100)\n",
    "    if(nPags==1):\n",
    "        descriptionsList=[]\n",
    "        jobsIDs = []\n",
    "        jobsFoundList = driver.find_elements(by=By.CSS_SELECTOR, value=cssSelector_Jobcard)\n",
    "        for i in jobsFoundList:\n",
    "            try:\n",
    "                id_html = i.get_attribute(\"id\")\n",
    "                jobsIDs.append(id_html)\n",
    "                #print(f\"ID encontrado: {id_html}\")\n",
    "            except StaleElementReferenceException:\n",
    "                print(\"ID No encontrado\")\n",
    "        if len(jobsFoundList)>0:\n",
    "            listOfTitlesList, descriptionsList, listOfUrlsList = obtain_descriptions(jobsFoundList,jobsIDs)\n",
    "            total = total + len(descriptionsList)\n",
    "            prepareDataFrame(listOfTitlesList, descriptionsList, listOfUrlsList,job_)\n",
    "            \n",
    "    elif (nPags>1):\n",
    "        titlesListConca = []\n",
    "        descriptionsListConca = []\n",
    "        urlsListConca= []\n",
    "        for i in range(1,nPags+1):\n",
    "            descriptionsList=[]\n",
    "            jobsIDs = []\n",
    "            driver.get(pagination_url.format(job_,location,i))\n",
    "            time.sleep(0.5)\n",
    "            jobsFoundList = driver.find_elements(by=By.CSS_SELECTOR, value=cssSelector_Jobcard)\n",
    "            for i in jobsFoundList:\n",
    "                try:\n",
    "                    id_html = i.get_attribute(\"id\")\n",
    "                    jobsIDs.append(id_html)\n",
    "                except StaleElementReferenceException:\n",
    "                    print(\"ID No encontrado\")\n",
    "            listOfTitles, descriptionsList, listOfUrls = obtain_descriptions(jobsFoundList,jobsIDs)\n",
    "            descriptionsListConca.extend(descriptionsList)\n",
    "            titlesListConca.extend(listOfTitles)\n",
    "            urlsListConca.extend(listOfUrls)\n",
    "        total = total + len(descriptionsListConca)\n",
    "        for l in descriptionsListConca:\n",
    "            l = l.replace(\",\",\" \")\n",
    "        prepareDataFrame(titlesListConca, descriptionsListConca, urlsListConca,job_)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n",
      "Error: ElementClickInterceptedException\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: Unable to receive message from renderer\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=124.0.6367.61)\nStacktrace:\n0   chromedriver                        0x0000000104956934 chromedriver + 4368692\n1   chromedriver                        0x000000010494edc8 chromedriver + 4337096\n2   chromedriver                        0x0000000104572c04 chromedriver + 289796\n3   chromedriver                        0x000000010455d230 chromedriver + 201264\n4   chromedriver                        0x000000010455cf5c chromedriver + 200540\n5   chromedriver                        0x000000010455ad20 chromedriver + 191776\n6   chromedriver                        0x000000010455b6bc chromedriver + 194236\n7   chromedriver                        0x000000010457516c chromedriver + 299372\n8   chromedriver                        0x00000001045edc08 chromedriver + 793608\n9   chromedriver                        0x00000001045ed5ec chromedriver + 792044\n10  chromedriver                        0x00000001045a9ab4 chromedriver + 514740\n11  chromedriver                        0x00000001045aa50c chromedriver + 517388\n12  chromedriver                        0x000000010491ae50 chromedriver + 4124240\n13  chromedriver                        0x000000010491fc40 chromedriver + 4144192\n14  chromedriver                        0x0000000104900818 chromedriver + 4016152\n15  chromedriver                        0x0000000104920570 chromedriver + 4146544\n16  chromedriver                        0x00000001048f22cc chromedriver + 3957452\n17  chromedriver                        0x000000010493feb8 chromedriver + 4275896\n18  chromedriver                        0x0000000104940034 chromedriver + 4276276\n19  chromedriver                        0x000000010494ea28 chromedriver + 4336168\n20  libsystem_pthread.dylib             0x0000000186d4a034 _pthread_start + 136\n21  libsystem_pthread.dylib             0x0000000186d44e3c thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job_ \u001b[38;5;129;01min\u001b[39;00m joblist_infocomm:\n\u001b[1;32m      6\u001b[0m     job_ \u001b[38;5;241m=\u001b[39m job_\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     total \u001b[38;5;241m=\u001b[39m \u001b[43mscrap_job_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     totalJobs \u001b[38;5;241m=\u001b[39m totalJobs \u001b[38;5;241m+\u001b[39m total\n\u001b[1;32m      9\u001b[0m driver\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m, in \u001b[0;36mscrap_job_infos\u001b[0;34m(job_)\u001b[0m\n\u001b[1;32m     39\u001b[0m descriptionsList\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     40\u001b[0m jobsIDs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 41\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpagination_url\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     43\u001b[0m jobsFoundList \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(by\u001b[38;5;241m=\u001b[39mBy\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, value\u001b[38;5;241m=\u001b[39mcssSelector_Jobcard)\n",
      "File \u001b[0;32m~/Documents/TEC-DE-MTY/SCRAPING/Job-web-scrapper-2024/.devbox/virtenv/python/.venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/TEC-DE-MTY/SCRAPING/Job-web-scrapper-2024/.devbox/virtenv/python/.venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/TEC-DE-MTY/SCRAPING/Job-web-scrapper-2024/.devbox/virtenv/python/.venv/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: disconnected: Unable to receive message from renderer\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=124.0.6367.61)\nStacktrace:\n0   chromedriver                        0x0000000104956934 chromedriver + 4368692\n1   chromedriver                        0x000000010494edc8 chromedriver + 4337096\n2   chromedriver                        0x0000000104572c04 chromedriver + 289796\n3   chromedriver                        0x000000010455d230 chromedriver + 201264\n4   chromedriver                        0x000000010455cf5c chromedriver + 200540\n5   chromedriver                        0x000000010455ad20 chromedriver + 191776\n6   chromedriver                        0x000000010455b6bc chromedriver + 194236\n7   chromedriver                        0x000000010457516c chromedriver + 299372\n8   chromedriver                        0x00000001045edc08 chromedriver + 793608\n9   chromedriver                        0x00000001045ed5ec chromedriver + 792044\n10  chromedriver                        0x00000001045a9ab4 chromedriver + 514740\n11  chromedriver                        0x00000001045aa50c chromedriver + 517388\n12  chromedriver                        0x000000010491ae50 chromedriver + 4124240\n13  chromedriver                        0x000000010491fc40 chromedriver + 4144192\n14  chromedriver                        0x0000000104900818 chromedriver + 4016152\n15  chromedriver                        0x0000000104920570 chromedriver + 4146544\n16  chromedriver                        0x00000001048f22cc chromedriver + 3957452\n17  chromedriver                        0x000000010493feb8 chromedriver + 4275896\n18  chromedriver                        0x0000000104940034 chromedriver + 4276276\n19  chromedriver                        0x000000010494ea28 chromedriver + 4336168\n20  libsystem_pthread.dylib             0x0000000186d4a034 _pthread_start + 136\n21  libsystem_pthread.dylib             0x0000000186d44e3c thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "# the web driver its initialized, then for each job(occupation) in the joblist will scrap the needed information\n",
    "# then close the explorer window and quit the driver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),options=option)\n",
    "totalJobs = 0\n",
    "for job_ in joblist_infocomm:\n",
    "    job_ = job_.replace(\" \",\"-\")\n",
    "    total = scrap_job_infos(job_)\n",
    "    totalJobs = totalJobs + total\n",
    "driver.close()\n",
    "driver.quit()\n",
    "print(\"\\n\")\n",
    "print(f\"\\nTotal Job posts extracted: {totalJobs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
