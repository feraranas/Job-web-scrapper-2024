{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from selenium import webdriver\n",
    "\n",
    "# Starting/Stopping Driver: can specify ports or location but not remote access\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "\n",
    "# Manages Binaries needed for WebDriver without installing anything directly\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Allows searchs similar to beautiful soup: find_all\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Try to establish wait times for the page to load\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# Wait for specific condition based on defined task: web elements, boolean are examples\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Used for keyboard movements, up/down, left/right,delete, etc\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Locate elements on page and throw error if they do not exist\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup chrome options\n",
    "\n",
    "# Create service\n",
    "webdriver_service = Service(ChromeDriverManager().install())\n",
    "option= webdriver.ChromeOptions()\n",
    "driver=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to make the search, the link and the job location\n",
    "pagination_url = \"https://www.occ.com.mx/empleos/de-{}/en-{}/?page={}\"\n",
    "pagination_url_id = \"https://www.occ.com.mx/empleos/de-{}/en-{}/?page={}&jobid={}\"\n",
    "location='Mexico'\n",
    "\n",
    "# Selenium selectors: used to find an element in the web page, xpath selector, css selector, class name selector\n",
    "xpath_resultados1 = \"/html/body/main/div[4]/aside/div/div[1]/p\"\n",
    "xpath_resultados2 = \"/html/body/div[1]/div[1]/div[7]/div/div[1]/div[1]/div[1]/p\"\n",
    "xpath_noresuultados = \"/html/body/main/div[3]/div/div/div[1]/h1\"\n",
    "cssSelector_Jobcard = \"div[id^=jobcard]\"\n",
    "cssSelector_jobinfo = \"body > main > div.sm\\:container.sm\\:mx-auto.grid.grid-cols-12 > div > div > div.mb-8.break-words\"\n",
    "cssSelector_jobinfo2= \"#jobbody\"\n",
    "cssSelector_JobcardCompany = \"div[class=\\\"fresnel-container fresnel-greaterThanOrEqual-sm\\\"][class=\\\"fresnel-greaterThanOrEqual-sm\\\"]\"\n",
    "className_JobcardCompany2 = \"fresnel-container fresnel-greaterThanOrEqual-sm\"\n",
    "className_JobcardCompany3 = \"\\\"fresnel-greaterThanOrEqual-sm\\\"\"\n",
    "cssSelector_jobcardTitle = \"#{} > div > h2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu_1 = \"https://www.linkedin.com/jobs/search?\"\n",
    "\n",
    "pu_2 = \"https://www.linkedin.com/jobs/search?keywords=Software%20Engineer&location=United%20States&geoId=103644278&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\"\n",
    "pu_2_1 = \"https://www.linkedin.com/jobs/search?keywords={}&location={}&geoId={}&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\"\n",
    "pu_2_2 = \"https://www.linkedin.com/jobs/search?keywords=Software%20Engineer&location=Mexico&geoId=103323778&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\"\n",
    "\n",
    "pu_3 = \"https://www.linkedin.com/jobs/search/?currentJobId=3876969581&geoId=103323778&keywords=Software%20Engineer&location=Mexico\"\n",
    "pu_3_1 = \"https://www.linkedin.com/jobs/search/?currentJobId={}&geoId={}&keywords={}&location=Mexico\"\n",
    "\n",
    "pu_4 = \"https://www.linkedin.com/jobs/search?trk=guest_homepage-basic_guest_nav_menu_job\"\n",
    "pu_5 = \"https://www.linkedin.com/jobs/search?trk=guest_homepage-basic_guest_nav_menu_job&position=1&pageNum=0\"\n",
    "\n",
    "# Job by ID\n",
    "jobId = \"3876969581\" # Software Engineer\n",
    "\n",
    "# Job by NAME: [keywords=Software%20Engineer]\n",
    "keywords = \"Software%20Engineer\" # Composed jobs must be separated by '%20'\n",
    "\n",
    "# Location (geographically) by ID: [geoId=103644278]\n",
    "mexicoGeoId = \"103323778\"\n",
    "unitedStatesGeoId = \"103644278\"\n",
    "\n",
    "# Location by NAME: [location=Mexico, location=United%20States]\n",
    "location=\"Mexico\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occupations to search\n",
    "joblist_infocomm = [\n",
    "    \"ict sales professional\",\n",
    "    \"marketing manager\",\n",
    "    \"product analyst\",\n",
    "    \"product manager\",\n",
    "    \"product designer\",\n",
    "    \"business intelligence professional\",\n",
    "    \"infrastructure engineer\",\n",
    "    \"computer systems analyst\",\n",
    "    \"software infrastructure architect\",\n",
    "    \"web developer\",\n",
    "    \"software developer\",\n",
    "    \"app developer\",\n",
    "    \"user interface designer\",\n",
    "    \"software engineer\",\n",
    "    \"software architect\",\n",
    "    \"software quality assurance analysts and testers\",\n",
    "    \"embedded systems engineer\",\n",
    "    \"web and digital interface designers\",\n",
    "    \"database infrastructure engineer\",\n",
    "    \"network architect\",\n",
    "    \"database administrator\",\n",
    "    \"database architect\",\n",
    "    \"network and computer systems administrator\",\n",
    "    \"artificial intelligence engineer\",\n",
    "    \"machine learning engineer\",\n",
    "    \"data science engineer\",\n",
    "    \"data analyst\",\n",
    "    \"data scientist\",\n",
    "    \"artificial intelligence scientist\",\n",
    "    \"data architect\",\n",
    "    \"ict security specialist\",\n",
    "    \"it security operations\",\n",
    "    \"information security analyst\",\n",
    "    \"product security and it security integration specialist\",\n",
    "    \"product risk specialist\",\n",
    "    \"security architect\",\n",
    "    \"database support engineer\",\n",
    "    \"data center operations engineer\",\n",
    "    \"support systems engineer\",\n",
    "    \"computer network support specialist\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findJobElements: recibe the h2 element, save the text to jobTitleList, clicks the\n",
    "# job card to find the description, if the description is found using the first selector, saves all the text in decriptionList\n",
    "# if its not found with the first selector it will search the element with the selector and do the same to save the text\n",
    "# returns: decriptionList,jobTitleList,jobUrlList\n",
    "def findJobElements(h2,decriptionList,jobTitleList,jobUrlList):\n",
    "    titulo = h2[0].text\n",
    "    jobTitleList.append(titulo)\n",
    "    try:\n",
    "        h2[0].click()\n",
    "        jobUrl = driver.current_url #obtain the current url of the page and save it to jobUrlList\n",
    "        jobUrlList.append(jobUrl)\n",
    "        time.sleep(1.3)\n",
    "        #encuentra info de jobs\n",
    "        descripcion = driver.find_elements(by=By.CSS_SELECTOR, value = cssSelector_jobinfo)\n",
    "        if len(descripcion) > 0:\n",
    "            for descripText in descripcion:\n",
    "                decriptionList.append(descripText.text)\n",
    "        else:\n",
    "            time.sleep(0.5)\n",
    "            descripcion = driver.find_elements(by=By.CSS_SELECTOR, value = cssSelector_jobinfo2)\n",
    "            if len(descripcion) > 0:\n",
    "                for descripText in descripcion:\n",
    "                    decriptionList.append(descripText.text)\n",
    "            else:#NoDesciptionFound\n",
    "                decriptionList.append(\"\")#If no description is found it will add an emtpy string to the list\n",
    "    except ElementClickInterceptedException:\n",
    "        print(\"Error: ElementClickInterceptedException\") # Handling the exception if the click fails \n",
    "        jobUrlList.append(\"error\")\n",
    "        decriptionList.append(\"error\")\n",
    "    return decriptionList,jobTitleList,jobUrlList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain_descriptions: search the h2 with the job title with the ids if not found search the h2 by the tag name \"h2\": return 3 list, titlesList, urlList and descriptionList\n",
    "def obtain_descriptions(jobsFoundList,jobsIds):\n",
    "    #Lists to save the jobs information\n",
    "    decriptionList = []\n",
    "    jobTitleList = []\n",
    "    jobUrlList = []\n",
    "    # For each job card it will find the title in the job card by id, if found calls the function findJobElements, if not found search the h2 by the tag name \"h2\"\n",
    "    for jobcard,id_html in zip(jobsFoundList,jobsIds):\n",
    "        soloId = id_html.split(\"-\")[1]\n",
    "        soloId=soloId.strip()\n",
    "        titulo = \"\"\n",
    "        cssSelector = cssSelector_jobcardTitle.format(id_html)\n",
    "        h2 = jobcard.find_elements(by=By.CSS_SELECTOR,value=cssSelector)\n",
    "        if len(h2) > 0:\n",
    "            decriptionList,jobTitleList,jobUrlList = findJobElements(h2,decriptionList,jobTitleList,jobUrlList)\n",
    "        else:\n",
    "            time.sleep(0.5)\n",
    "            h2 = jobcard.find_elements(by=By.TAG_NAME,value=\"h2\")\n",
    "            if len(h2) > 0:\n",
    "                decriptionList,jobTitleList,jobUrlList = findJobElements(h2,decriptionList,jobTitleList,jobUrlList)\n",
    "            else:\n",
    "                print(\"No Job Title to click\")\n",
    "    return jobTitleList, decriptionList, jobUrlList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prepareDataFrame function is given the urls, titles and jobs descriptions to create a pandas df and save it to a CSV file\n",
    "# the csv title will be the occpation and the date of the search, example: web-developer-2024-04-16.csv\n",
    "def prepareDataFrame(titlesList,urlsList,descriptionsList, occup):\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    csvRoute = \"CSVInfo2V2/\"\n",
    "    csvFileName = csvRoute + occup + \"-\" + str(current_date) +\".csv\"\n",
    "    df = pd.DataFrame({'Job_Title': titlesList, 'Job_Description': descriptionsList, 'Job_Url': urlsList})\n",
    "    df.to_csv(csvFileName, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_npags, given the number of results found by the search it will calculate how many pages the scrapper will search\n",
    "def calculate_npags(num_resultados, max_resultados=100):\n",
    "    total_pages = math.ceil(num_resultados / 20)\n",
    "    total_pages = min(total_pages, math.ceil(max_resultados / 20))\n",
    "    return total_pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap_job_infos, given the occupation, the scrapper visit the url with de occupation an the location given\n",
    "# try to find the number or results of the search and then calculate tje pages\n",
    "# if the number of pages is 1 try to find the job cards, to obtain the descriptions, titles and urls, to prepare the df\n",
    "# if nPags > 1 it will iterate through pages saving the job cards and obtaining the job information and saves it to the respective list\n",
    "# to create the df\n",
    "def scrap_job_infos(job_):\n",
    "    #print(f\"EMPLEO: {job_}\")\n",
    "    driver.get(pagination_url.format(job_,location,1))\n",
    "    time.sleep(1.5)\n",
    "    resultados = driver.find_elements(by=By.XPATH, value=xpath_resultados1)\n",
    "    if len(resultados) == 0:\n",
    "        resultados = driver.find_elements(by=By.XPATH, value=xpath_resultados2)\n",
    "    total=0\n",
    "    nResultados = int((resultados[0].text.split(\" \")[0]).replace(\",\",\"\")) if resultados else int(\"0\")\n",
    "\n",
    "    #print(f\"Resultados encontrados: {nResultados}\\n\")\n",
    "    nPags = calculate_npags(nResultados, max_resultados=100)\n",
    "    if(nPags==1):\n",
    "        descriptionsList=[]\n",
    "        jobsIDs = []\n",
    "        jobsFoundList = driver.find_elements(by=By.CSS_SELECTOR, value=cssSelector_Jobcard)\n",
    "        for i in jobsFoundList:\n",
    "            try:\n",
    "                id_html = i.get_attribute(\"id\")\n",
    "                jobsIDs.append(id_html)\n",
    "                #print(f\"ID encontrado: {id_html}\")\n",
    "            except StaleElementReferenceException:\n",
    "                print(\"ID No encontrado\")\n",
    "        if len(jobsFoundList)>0:\n",
    "            listOfTitlesList, descriptionsList, listOfUrlsList = obtain_descriptions(jobsFoundList,jobsIDs)\n",
    "            total = total + len(descriptionsList)\n",
    "            prepareDataFrame(listOfTitlesList, descriptionsList, listOfUrlsList,job_)\n",
    "            \n",
    "    elif (nPags>1):\n",
    "        titlesListConca = []\n",
    "        descriptionsListConca = []\n",
    "        urlsListConca= []\n",
    "        for i in range(1,nPags+1):\n",
    "            descriptionsList=[]\n",
    "            jobsIDs = []\n",
    "            driver.get(pagination_url.format(job_,location,i))\n",
    "            time.sleep(0.5)\n",
    "            jobsFoundList = driver.find_elements(by=By.CSS_SELECTOR, value=cssSelector_Jobcard)\n",
    "            for i in jobsFoundList:\n",
    "                try:\n",
    "                    id_html = i.get_attribute(\"id\")\n",
    "                    jobsIDs.append(id_html)\n",
    "                except StaleElementReferenceException:\n",
    "                    print(\"ID No encontrado\")\n",
    "            listOfTitles, descriptionsList, listOfUrls = obtain_descriptions(jobsFoundList,jobsIDs)\n",
    "            descriptionsListConca.extend(descriptionsList)\n",
    "            titlesListConca.extend(listOfTitles)\n",
    "            urlsListConca.extend(listOfUrls)\n",
    "        total = total + len(descriptionsListConca)\n",
    "        for l in descriptionsListConca:\n",
    "            l = l.replace(\",\",\" \")\n",
    "        prepareDataFrame(titlesListConca, descriptionsListConca, urlsListConca,job_)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMPLEO: ict-sales-professional\n",
      "Resultados encontrados: 26\n",
      "\n",
      "EMPLEO: marketing-manager\n",
      "Resultados encontrados: 443\n",
      "\n",
      "EMPLEO: product-analyst\n",
      "Resultados encontrados: 99\n",
      "\n",
      "EMPLEO: product-manager\n",
      "Resultados encontrados: 485\n",
      "\n",
      "EMPLEO: product-designer\n",
      "Resultados encontrados: 38\n",
      "\n",
      "EMPLEO: business-intelligence-professional\n",
      "Resultados encontrados: 25240\n",
      "\n",
      "EMPLEO: infrastructure-engineer\n",
      "Resultados encontrados: 65\n",
      "\n",
      "EMPLEO: computer-systems-analyst\n",
      "Resultados encontrados: 1\n",
      "\n",
      "EMPLEO: software-infrastructure-architect\n",
      "Resultados encontrados: 13\n",
      "\n",
      "EMPLEO: web-developer\n",
      "Resultados encontrados: 970\n",
      "\n",
      "EMPLEO: software-developer\n",
      "Resultados encontrados: 6200\n",
      "\n",
      "EMPLEO: app-developer\n",
      "Resultados encontrados: 183\n",
      "\n",
      "EMPLEO: user-interface-designer\n",
      "Resultados encontrados: 37\n",
      "\n",
      "EMPLEO: software-engineer\n",
      "Resultados encontrados: 1708\n",
      "\n",
      "EMPLEO: software-architect\n",
      "Resultados encontrados: 108\n",
      "\n",
      "EMPLEO: software-quality-assurance-analysts-and-testers\n",
      "Resultados encontrados: 155\n",
      "\n",
      "EMPLEO: embedded-systems-engineer\n",
      "Resultados encontrados: 4670\n",
      "\n",
      "EMPLEO: web-and-digital-interface-designers\n",
      "Resultados encontrados: 5385\n",
      "\n",
      "EMPLEO: database-infrastructure-engineer\n",
      "Resultados encontrados: 19\n",
      "\n",
      "EMPLEO: network-architect\n",
      "Resultados encontrados: 22\n",
      "\n",
      "EMPLEO: database-administrator\n",
      "Resultados encontrados: 260\n",
      "\n",
      "EMPLEO: database-architect\n",
      "Resultados encontrados: 26\n",
      "\n",
      "EMPLEO: network-and-computer-systems-administrator\n",
      "Resultados encontrados: 287\n",
      "\n",
      "EMPLEO: artificial-intelligence-engineer\n",
      "Resultados encontrados: 179\n",
      "\n",
      "EMPLEO: machine-learning-engineer\n",
      "Resultados encontrados: 45\n",
      "\n",
      "EMPLEO: data-science-engineer\n",
      "Resultados encontrados: 262\n",
      "\n",
      "EMPLEO: data-analyst\n",
      "Resultados encontrados: 588\n",
      "\n",
      "EMPLEO: data-scientist\n",
      "Resultados encontrados: 306\n",
      "\n",
      "EMPLEO: artificial-intelligence-scientist\n",
      "Resultados encontrados: 32\n",
      "\n",
      "EMPLEO: data-architect\n",
      "Resultados encontrados: 126\n",
      "\n",
      "EMPLEO: ict-security-specialist\n",
      "Resultados encontrados: 2\n",
      "\n",
      "EMPLEO: it-security-operations\n",
      "Resultados encontrados: 25\n",
      "\n",
      "EMPLEO: information-security-analyst\n",
      "Resultados encontrados: 19\n",
      "\n",
      "EMPLEO: product-security-and-it-security-integration-specialist\n",
      "Resultados encontrados: 11656\n",
      "\n",
      "EMPLEO: product-risk-specialist\n",
      "Resultados encontrados: 7\n",
      "\n",
      "EMPLEO: security-architect\n",
      "Resultados encontrados: 74\n",
      "\n",
      "EMPLEO: database-support-engineer\n",
      "Resultados encontrados: 155\n",
      "\n",
      "EMPLEO: data-center-operations-engineer\n",
      "Resultados encontrados: 13\n",
      "\n",
      "EMPLEO: support-systems-engineer\n",
      "Resultados encontrados: 329\n",
      "\n",
      "EMPLEO: computer-network-support-specialist\n",
      "Resultados encontrados: 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total Job posts extracted: 2674\n"
     ]
    }
   ],
   "source": [
    "# the web driver its initialized, then for each job(occupation) in the joblist will scrap the needed information\n",
    "# then close the explorer window and quit the driver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),options=option)\n",
    "totalJobs = 0\n",
    "for job_ in joblist_infocomm:\n",
    "    job_ = job_.replace(\" \",\"-\")\n",
    "    total = scrap_job_infos(job_)\n",
    "    totalJobs = totalJobs + total\n",
    "driver.close()\n",
    "driver.quit()\n",
    "print(\"\\n\")\n",
    "print(f\"\\nTotal Job posts extracted: {totalJobs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
